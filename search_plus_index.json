{"./":{"url":"./","title":"Linux","keywords":"","body":"XCQ DAILY LEARNING NOTES Xiechengqi            最新修订时间： 2019-12-06 21:05:16 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/APT-剖析详解.html":{"url":"Linux/APT-剖析详解.html","title":"APT-剖析详解","keywords":"","body":"APT 原理剖析、详解 APT - Advanced Packaging Tool 软件安装方法历程图 /etc/apt/sources.list 只会告知系统可以访问的镜像站点地址，这时每当系统执行一次 sudo apt install xxx 都要链接镜像站检索出对应的软件地址，这样是很浪费时间的，所以在本地 /var/lib/apt/lists/ 会缓存一份镜像站里的所有软件源信息，这样每次执行 sudo apt install xxx 直接在本地缓冲里检索，在连接网络下载文件。所以 sudo apt install 会先访问 /var/lib/apt/lists/；而且 sudo apt update 更新的是 /var/lib/apt/lists/ 里的软件源 每当执行命令进行软件的安装或着更新，或者软件源的更新时，apt 会访问 /etc/apt/sources.list 内的地址，并在该网站中找到对应系统的包信息例如我的操作系统是 ubuntu，网站是 deb http://mirrors.163.com/ubuntu/ precise main restricted universe multiverse 网易的，那么当我们执行安装的命令时，他就会对应的访问 http://mirrors.163.com/ubuntu/dists/lucid/main/binary-i386/ 的 packages.gz，这个文件是服务器上软件包及其依赖关系的清单，并且用 gzip 压缩过了。apt-get update使用这个清单来确定能够获得哪些补充的软件包且他的内容会被保存在 /var/lib/apt/lists 内，通过访问这个 lists 确定该软件是否已安装，是否是最新版本，依赖关系是否满足，从而确定要更新内容，并进行更新，其安装过程主要是由 dpkg 来完成 一、 背景知识 1. PPA 源 - Personal Package Archives - 个人软件包集 源和软件仓库实际上是一个意思，厂商将编译后的二进制文件和软件信息存放至服务器，用户需要安装软件时，包管理器自动分析本机和容器（repository）内的信息，下载需要的包并自动安装，安装后将新安装的软件信息存放至本地 添加、删除 PPA 软件源# 添加 PPA 软件源的命令 $ sudo add-apt-repository ppa:user/ppa-name # 删除 PPA 软件源的命令 $ sudo add-apt-repository --remove ppa:user/ppa-name 例如，我们想要添加一个 Wireshark 软件的 PPA 源，我们可以根据它官网上提供的命令来进行添加，如下图所示： 当我们添加完 PPA 源之后，系统就会在 /etc/apt/sources.list.d/ 文件夹里创建了两个文件，一个 .list 文件和一个带有 .save 后缀的备份文件： $ cd /etc/apt/sources.list.d $ ls | grep wireshark wireshark-dev-stable-trusty.list wireshark-dev-stable-trusty.list.save 我们再来打开一下 wireshark-dev-stable-trusty.list 文件看看里面的内容是什么： deb http://ppa.launchpad.net/wireshark-dev/stable/ubuntu trusty main # deb-src http://ppa.launchpad.net/wireshark-dev/stable/ubuntu trusty main 原来文件里就是添加了一个跟软件源一模一样的东西，他们的作用殊途同归啊。我想这其实是 Ubuntu 为了分辨官方的源和第三方的源才设计成在 sources.list 和 sources.list.d/ 这两个地方中存储软件源信息。因为第三方的源毕竟不太可信，如果随便更新的话可是会出事情的。 2. deb http://site.example.com/debian distribution component 格式详解 deb http://site.example.com/debian distribution component1 component2 component3 deb-src http://site.example.com/debian distribution component1 component2 component3 # 例如 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted deb-src http://mirrors.aliyun.com/ubuntu/ bionic restricted universe multiverse main 档案类型 - Archive type 条目的第一个词 deb 或是 deb-src 表明了所获取的软件包档案类型 deb - 档案类型为二进制预编译软件包，一般我们所用的档案类型 deb-src - 档案类型为用于编译二进制软件包的源代码 每行的第一个单词 deb 或 deb-src，描述了文件类型，目录中包含的是二进制软件包（ deb ），即我们通常使用的已编译好的软件包；或包含的是源码包（ deb-src ），源码包包含源程序编码、Debian 管理文件（ .dsc ）和 “Debian 化” 该程序所做更改的记录文件 diff.gz 仓库地址 - Repository URL 条目的第二个词则是软件包所在仓库的地址，我们可以更换仓库地址为其他地理位置更靠近自己的镜像来提高下载速度 Ubuntu 软件源的源列表：国内开源镜像站点汇总 仓库地址可以是多种类型：http、ftp、file（ 本地文件，例如：一个加载了 ISO9600 文件系统的目录 ） 或 ssh 发行版 - Distribution 跟在仓库地址后的是发行版。发行版有两种分类方法 一类是发行版的具体代号，如 xenial,trusty, precise 等 另一类则是发行版的发行类型，如 oldstable, stable, testing 和 unstable 另外，在发行版后还可能有进一步的指定，如 xenial-updates, trusty-security, stable-backports 等 可以通过命令 lsb_release -cs,查看当前操作系统代号, 例如 Ubuntu 16.04 LTS 代号为 xenial, Ubuntu 18.04 LTS 代号为 bionic $ lsb_release -ca No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 18.04.3 LTS Release: 18.04 Codename: bionic 软件包分类 - Component 跟在发行版之后的就是软件包的具体分类了，可以有一个或多个。不同的 Linux 发行版对软件有着不同的分类 Debian main 包含符合 DFSG 指导原则的自由软件包，而且这些软件包不依赖不符合该指导原则的软件包。这些软件包被视为 Debian 发型版的一部分 contrib 包含符合 DFSG 指导原则的自由软件包，不过这些软件包依赖不在 main 分类中的软件包 non-free 包含不符合 DFSG 指导原则的非自由软件包 Ubuntu main 官方支持的自由软件 restricted 官方支持的非完全自由的软件 universe 社区维护的自由软件 multiverse 非自由软件 Ubuntu 自由软件 非自由软件 官方支持 Main Restricted 非官方支持 Universe Multiverse 二、 apt 基本命令 apt [选项] 命令 [选项] list - 根据名称列出软件包 search - 搜索软件包描述 show - 显示软件包细节 install - 安装软件包 remove - 移除软件包 autoremove - 卸载所有自动安装且不再使用的软件 update - 根据 /etc/apt/sources.list 更新 /var/lib/apt/lists 软件包列表 upgrade - 根据 /var/lib/apt/lists 安装/升级 软件来更新系统 full-upgrade - 通过 卸载/安装/升级 来更新系统 edit-sources - 编辑软件源信息文件 添加 PPA 软件源并安装 $ sudo add-apt-repository # 此命令将 PPA 仓库添加到列表中 $ sudo apt-get update # 此命令更新可以在当前系统上安装的软件包列表 $ sudo apt-get install # 此命令安装软件包 # 例如 $ sudo add-apt-repository ppa:dr-akulavich/lighttable $ sudo apt-get update $ sudo apt-get install lighttable-installer 强制重装已安装的软件 $ sudo apt-get --reinstall install # 会先删除软件，再安装 sudo apt install \\ 新增文件位置 主要分散到以下四个目录 /usr/bin - 二进制文件 /usr/lib - 动态函数库文件 /usr/share/doc - 使用手册 /usr/share/man - man page 所以在多用户情况下使用 sudo apt install 安装软件，会造成软件存放散乱，寻找软件配置文件麻烦；但好处是 apt 安装软件系统会自动注册环境变量，且是全局的 当自己使用源码安装软件通常把源码包放在 /usr/local sudo apt update 具体执行动作 执行 sudo apt update 链接 /etc/apt/sources.list 里的软件源的镜像站，自动检索对比镜像站里的所有软件源与本地的 /var/lib/apt/lists/ 目录，若发现有更新，立即在 /var/lib/apt/lists/ 目录里跟新 更新完毕 强制更新 sudo rm -rf /var/lib/apt/lists/* sudo apt-get update 3. sudo apt autoremove autoclean 是另一种方法，用于清除下载的包文件的本地存储库，clean 和之间的区别在于autoclean后者仅删除无法再从其源下载的包文件，并且很可能无用 4. /etc/apt/ 目录详解 /etc/apt 目录详解图 /etc/apt/sources.list && /etc/apt/sources.list.d/ /etc/apt/sources.list内容组成 /etc/apt/sources.list 文件 当使用sudo apt install xxx安装软件时，系统会自动在配置的镜像软件源列表（ /var/lib/apt/lists/ )寻找，找到后自动添加进来 /etc/apt/sources.list.d/内容组成 /etc/apt/sources.list.d/ 文件夹 /etc/apt/sources.list.d/多是由第三方软件源文件组成，比如使用sudo dpkg -i xxx.deb安装或通过添加 PPA 软件第三方源sudo add-apt-repository ppa:user/ppa-name安装，而这些文件主要有这么三种： xxx.list xxx.list.distUpgrade xxx.list.save xxx.list - 记录第三方软件的软件源信息 ### THIS FILE IS AUTOMATICALLY CONFIGURED ### # You may comment out this entry, but any other modifications may be lost. # deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main # 已禁止升级到 bionic xxx.list.save - 是xxx.list.save的备份，内容相同 xxx.list.disUpgrade - 网上没找到，未知待续 ### THIS FILE IS AUTOMATICALLY CONFIGURED ### # You may comment out this entry, but any other modifications may be lost. deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main /etc/apt/apt.conf && /etc/apt/apt.conf.d/ /etc/apt/apt.conf:APT配置文件。 /etc/apt/apt.conf.d/:APT配置文件片段。 /etc/apt/preferences 版本首选项文件。您可以在此处指定“ 固定 ”，即从单独的源或不同版本的分发中获取某些包的首选项。 5. /var/cache/apt/ /var/cache/apt/archives/ 检索到的包文件的存储区域 $ sudo apt clean清空此目录 APT缓存文件，目录是在用 apt-get install 安装软件时，软件包的临时存放路径 /var/cache/apt/archives/partial/ 传输中的包文件的存储区域。 /var/lib/apt/lists/ sources.list中指定的每个包资源的状态信息的存储区域 /var/ lib/apt/lists/partial/ 传输中的状态信息的存储区域。 /var/lib/dpkg/available 文件的内容是软件包的描述信息，该软件包括当前系统所使用的安装源中的所有软件包，其中包括当前系统中已安装的和未安装的软件包 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux性能相关常用命令.html":{"url":"Linux/Linux性能相关常用命令.html","title":"Linux性能相关常用命令","keywords":"","body":"Linux 性能相关常用命令 - Linux Performance 主要以Ubuntu 18.04 LTS 为例，命令在 Linux 不同操作系统可能略有差别 《BPF Performance Tools》 Linux 性能分析工具 Linux 性能观测工具 Linux 性能测评工具 Linux Linux Linux 目录 top - CPU DRAM netstat - Sockets TCP\\UDP IP Ethernet ip - Ethernet nload - iostat - Block Device Interface I/O Controller lsof ps free - Virtual Memory pidstat - CPU vmstat - System Call InterFace Scheduler Virtual Memory dstat - CPU Virtual Memory Disk Port brctl - 网桥管理工具 mpstat - CPU perf - CPU tcpdump - Ethernet nicstat - Ethernet dtrace - Ethernet ping - Port dastat - Port dtrace - Port dastat - Disk dtrace - Disk perl ipconfig slabtop nicstat nmcli conn show -a nmcli conn show '连接名称' vmstat [Top] Virtual Meomory Statistics, Report virtual memory statistics 对操作系统的虚拟内存、进程、CPU活动进行监控，低开销的系统性能观察方式，不足之处是无法对某个进程进行深入分析 使用技巧 vmstat 本身就是低开销工具，在非常高负荷的服务器上，你需要查看并监控系统的健康情况，在控制窗口还是能够使用 vmstat 输出结果 pidstat [Top] Report statistics for Linux tasks 监控全部或指定进程的 cpu、内存、线程、设备 IO 等系统资源的占用情况 pidstat [选项] [时间] [次数] [选项] -u - 默认的参数，显示各个进程的 CPU 使用统计 -r - 显示各个进程的内存使用统计 -d - 显示各个进程的 IO 使用情况 -p - 指定进程号 -w - 显示每个进程的上下文切换情况 -t - 显示选择任务的线程的统计信息外的额外信息 常用命令 pidstat # 显示所有进程的 CPU 使用率 pidstat -r # 输出进程内存使用情况统计 pidstat -d -p 1 1 5 # 每隔一秒，一共输出 5 次进程 ID 为 1 的 IO 统计信息 pidstat -t -p 1 # 显示选择任务 ( pid =1 )的线程的统计信息外的额外信息 使用技巧 pidstat 首次运行时显示自系统启动开始的各项统计信息，之后运行 pidstat 将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息 pidstat 是 sysstat 软件套件的一部分，sysstat 包含很多监控 linux 系统状态的工具，它能够从大多数 linux 发行版的软件源中获得 安装：sudo apt install sysstat 或 yum install sysstat 命令输出详解 pidstat Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 08:41:58 CST UID PID %usr %system %guest %wait %CPU CPU Command 08:41:58 CST 0 1 0.05 0.17 0.00 0.03 0.22 7 systemd 08:41:58 CST 0 7 0.00 0.00 0.00 0.00 0.00 0 ksoftirqd/0 08:41:58 CST 0 8 0.03 0.29 0.00 0.06 0.32 3 rcu_sched 08:41:58 CST 0 16 0.00 0.00 0.00 0.00 0.00 1 ksoftirqd/1 08:41:58 CST 0 22 0.00 0.00 0.00 0.00 0.00 2 ksoftirqd/2 08:41:58 CST 0 28 0.00 0.00 0.00 0.01 0.00 3 ksoftirqd/3 08:41:58 CST 0 34 0.00 0.00 0.00 0.00 0.00 4 ksoftirqd/4 UID - 用户 ID PID - 进程 ID %usr - 进程在用户空间占用 CPU 的百分比 %system - 进程在内核空间占用 CPU 的百分比 %guest - 任务花费在虚拟机上的 CPU 使用率（ 运行在虚拟处理器 ） %CPU - 任务总的 CPU 使用率 CPU - 正在运行这个任务的处理器编号 Command - 这个任务的命令名称 pidstat -r Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 08:55:44 CST UID PID minflt/s majflt/s VSZ RSS %MEM Command 08:55:44 CST 0 1 8.72 0.04 225880 9476 0.12 systemd 08:55:44 CST 0 299 5.12 0.17 174836 46424 0.58 systemd-journal minflt/s - 从内存中加载数据时每秒出现的次要错误的数目，这些不要求从磁盘载入内存页面 majflt/s - 从内存中加载数据时每秒出现的主要错误的数目，这些要求从磁盘载入内存页面 VSZ - 虚拟地址大小，虚拟内存的使用 KB RSS - 长期内存使用，任务的不可交换物理内存的使用量 KB %MEM - 进程使用的物理内存百分比，top命令也会输出该字段 Command - task 命令名 pidstat -d Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 09:01:44 CST UID PID kB_rd/s kB_wr/s kB_ccwr/s iodelay Command 09:01:44 CST 0 1 -1.00 -1.00 -1.00 713 systemd 09:01:44 CST 0 61 -1.00 -1.00 -1.00 8 kworker/2:1 09:01:44 CST 0 219 -1.00 -1.00 -1.00 228 kworker/u16:3 kB_rd/s - 进程每秒从磁盘读取的数据量( kB ) kB_wr/s - 进程每秒向磁盘写入的数据量(kB ) kB_ccwr/s - 任务写入磁盘被取消的速率（ KB ）( 当任务截断脏的 pagecache 的时候会发生 ) pidstat -t Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 09:13:48 CST UID TGID TID %usr %system %guest %wait %CPU CPU Command 09:13:48 CST 0 1 - 0.03 0.12 0.00 0.04 0.15 4 systemd 09:13:48 CST 0 - 1 0.03 0.12 0.00 0.04 0.15 4 |__systemd 09:13:48 CST 0 2 - 0.00 0.00 0.00 0.00 0.00 7 kthreadd TGID - 主线程的标识 TID - 线程 ID pidstat -w Linux 4.15.0-66-generic (xcq) Friday, November 08, 2019 _x86_64_ (8 CPU) 09:17:57 CST UID PID cswch/s nvcswch/s Command 09:17:57 CST 0 1 29.38 0.13 systemd 09:17:57 CST 0 2 0.09 0.00 kthreadd Cswch/s - 每秒主动任务上下文切换数量 Nvcswch/s - 每秒被动任务上下文切换数量 iostat [Top] Report Central Processing Unit (CPU) statistics and input/output statistics for devices and partitions 主要用于监控磁盘 iostat [选项] [时间间隔（秒）] [输出次数] [选项] -c - 显示 CPU 使用情况 -d - 显示磁盘使用情况 -k - 以 KB 为单位显示 -m - 以 M 为单位显示 -N - 显示磁盘阵列 ( LVM ) 信息 -n - 显示 NFS 使用情况 -p - 显示磁盘和分区的情况 -t - 显示终端和 CPU 的信息 -x - 显示详细信息 -V - 显示版本信息 常用命令 iostat -x # 打印磁盘使用详细状态 iostat -d 2 10 # 每隔 2 秒打印一次磁盘使用情况，一共打印 10 次 命令输出详解 iostat # CentOS 7 iostat Linux 3.10.0-514.26.2.el7.x86_64 (iZuf62pye4v8osus1bsqgjZ) Thursday, November 07, 2019 _x86_64_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.49 0.00 0.29 0.13 0.00 99.09 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn vda 4.18 0.82 72.32 1690217 148491664 avg-cpu - 和 top 输出第三行一样 %user - CPU 处在用户模式下的时间百分比 %nice - CPU 处在带 NICE 值的用户模式下的时间百分比 %system - CPU 处在系统模式下的时间百分比 %iowait - CPU 等待输入输出完成时间的百分比。如果该值较高，表示磁盘存在 I/O 瓶颈 %steal - 管理程序维护另一个虚拟处理器时，虚拟 CPU 的无意识等待时间百分比 %idle - CPU 空闲时间百分比 Device tps - 每秒 I/O 数（ 即 IOPS，磁盘连续读和连续写之和 ） kB_read/s - 每秒从磁盘读取数据大小，单位 KB/s kB_wrtn/s - 每秒写入磁盘的数据的大小，单位 KB/s kB_read - 从磁盘读出的数据总数，单位 KB kB_wrtn - 写入磁盘的的数据总数，单位 KB iostat -x # CentOS 7 iostat -x Linux 3.10.0-514.26.2.el7.x86_64 (iZuf62pye4v8osus1bsqgjZ) Thursday, November 07, 2019 _x86_64_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.49 0.00 0.29 0.13 0.00 99.09 Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %util vda 0.00 0.54 0.04 4.14 0.82 72.32 34.97 0.01 2.06 4.43 2.03 0.35 0.15 Device - 设备名称 rrqm/s - 每秒合并到设备的读取请求数 wrqm/s - 每秒合并到设备的写请求数 r/s - 每秒向磁盘发起的读操作数 w/s - 每秒向磁盘发起的写操作数 rkB/s - 每秒读 K 字节数 wkB/s - 每秒写 K 字节数 avgrq-sz - 平均每次设备 I/O 操作的数据大小 avgqu-sz - 平均 I/O 队列长度 await - 平均每次设备 I/O 操作的等待时间 ( 毫秒 )。一般地，系统 I/O 响应时间应该低于 5ms，如果大于 10ms 就比较大了 r_await - 每个读操作平均所需的时间；不仅包括硬盘设备读操作的时间，还包括了在 kernel 队列中等待的时间 w_await - 每个写操作平均所需的时间；不仅包括硬盘设备写操作的时间，还包括了在 kernel 队列中等待的时间 svctm - 平均每次设备 I/O 操作的服务时间 ( 毫秒 )（ 这个数据不可信！） %util - 一秒中有百分之多少的时间用于 I/O 操作，即被 IO 消耗的 CPU 百分比。一般地，如果该参数是 100% 表示设备已经接近满负荷运行了 使用技巧 除了关注指标外，我们更需要结合部署的业务进行分析。对于磁盘随机读写频繁的业务，比如图片存取、数据库、邮件服务器等，此类业务吗，tps 才是关键点。对于顺序读写频繁的业务，需要传输大块数据的，如视频点播、文件同步，关注的是磁盘的吞吐量 如果 %util 接近 100%，说明产生的 I/O 请求太多，I/O 系统已经满负荷，该磁盘可能存在瓶颈 如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间 如果 await 远大于 svctm，说明 I/O 队列太长，I/O 响应太慢，则需要进行必要优化 如果 avgqu-sz 比较大，也表示有大量 I/O 在等待 ps [Top] report a snapshot of the current processes ps [选项] [选项] ps命令支持三种使用的语法格式 UNIX 风格，选项可以组合在一起，并且选项前必须有“-”连字符 BSD 风格，选项可以组合在一起，但是选项前不能有“-”连字符 GNU 风格的长选项，选项前有两个“-”连字符 常用命令 ps aux ps -ef ps axjf ps axms ps axZ ps -U root -u root u lsof [Top] list open files lsof 可以查看打开的文件有：普通文件、目录、网络文件系统的文件、字符或设备文件、(函数)共享库、管道、命名管道、符号链接、网络文件（NFS file、网络 socket、unix 域名 socket ）、还有其它类型的文件，等等 lsof [选项] [选项] -a - 使用 AND 逻辑，合并选项输出内容 -c - 列出名称以指定名称开头的进程打开的文件 -d - 列出打开指定文件描述的进程 +d - 列出目录下被打开的文件 +D - 递归列出目录下被打开的文件 -n - 列出使用 NFS 的文件 -u - 列出指定用户打开的文件 -p - 列出指定进程号所打开的文件 -i - 列出打开的套接字 常用命令 lsof -i # 列出所有的网络连接 lsof -i :80 # 列出 80 端口目前打开的文件列表 lsof -i tcp # 列出所有的 TCP 网络连接信息 lsof -i udp # 列出所有的 UDP 网络连接信息 lsof -i tcp:80 # 列出 80 端口 TCP 协议的所有连接信息 lsof -i udp:25 # 列出 25 端口 UDP 协议的所有连接信息 lsof -c ngin # 列出以 ngin 开头的进程打开的文件列表 lsof -p 20711 # 列出指定进程打开的文件列表 lsof -u xcq # 列出指定用户打开的文件列表 lsof -u xcq -i tcp # 将所有的 TCP 网络连接信息和指定用户打开的文件列表信息一起输出 lsof -a -u uasp -i tcp # 将指定用户打开的文件列表信息，同时是 TCP 网络连接信息的一起输出；注意和上一条命令进行对比 lsof +d /usr/local/ # 列出目录下被进程打开的文件列表 lsof +D /usr/local/ # 递归搜索目录下被进程打开的文件列表 lsof -i @peida.linux:20,21,22,80 -r 3 # 列出目前连接到主机 peida.linux 上端口为 20，21，22，80相关的所有文件信息，且每隔 3 秒不断的执行 lsof 指令 命令输出详解 lsof sudo lsof COMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 8,2 4096 2 / systemd 1 root rtd DIR 8,2 4096 2 / systemd 1 root txt REG 8,2 1595792 46137607 /lib/systemd/systemd systemd 1 root mem REG 8,2 1700792 46137433 /lib/x86_64-linux-gnu/libm-2.27.so systemd 1 root mem REG 8,2 121016 46137523 /lib/x86_64-linux-gnu/libudev.so.1.6.9 systemd 1 root mem REG 8,2 84032 46139105 /lib/x86_64-linux-gnu/libgpg-error.so.0.22.0 systemd 1 root mem REG 8,2 43304 46139138 /lib/x86_64-linux-gnu/libjson-c.so.3.0.1 systemd 1 root mem REG 8,2 34872 21766670 /usr/lib/x86_64-linux-gnu/libargon2.so.0 systemd 1 root mem REG 8,2 432640 46137584 /lib/x86_64-linux-gnu/libdevmapper.so.1.02.1 . . . COMMAND - 进程的名称 PID - 进程标识符 TID - 线程标识符 USER - 进程所有者 FD - 文件描述符，应用程序通过文件描述符识别该文件，一般有以下取值 cwd - 表示 current work dirctory，即：应用程序的当前工作目录，这是该应用程序启动的目录 txt - 该类型的文件是程序代码，如应用程序二进制文件本身或共享库 lnn - library references ( AIX ) er - FD information error ( see NAME column ) jld - jail directory ( FreeBSD ) ltx - shared library text ( code and data ) mxx - hex memory-mapped type number xx m86 - DOS Merge mapped file mem - memory-mapped file mmap - memory-mapped device pd - parent directory rtd - root directory tr - kernel trace file ( OpenBSD ) v86 - VP/ix mapped file 0 - 表示标准输出 1 - 表示标准输入 2 - 表示标准错误 TYPE - 文件类型，常见的文件类型有以下几种 DIR - 表示目录 CHR - 表示字符类型 BLK - 块设备类型 UNIX - UNIX 域套接字 FIFO - 先进先出 ( FIFO ) 队列 IPv4 - 网际协议 ( IP ) 套接字 DEVICE - 指定磁盘的名称 SIZE/OFF - 文件的大小 NODE - 索引节点（ 文件在磁盘上的标识 ） NAME - 打开文件的确切名称 netstat [Top] Print network connections, routing tables, interface statistics, masquerade connections, and multicast memberships 显示与 IP、TCP、UDP 和 ICMP 协议相关的统计数据，同时还可用于检验本机各端口的网络连接情况 netstat [选项] [选项] -a - 显示所有选项，默认不显示 LISTEN 相关 -t - 仅显示 tcp 相关选项 -u - 仅显示 udp 相关选项 -n - 拒绝显示别名，能显示数字的全部转化成数字 -l - 仅显示正在 Listen（ 监听 ）的服务状态 -p - 显示建立相关连接的程序名 -r - 显示路由信息，路由表 -e - 显示扩展信息，例如 uid 等 -s - 按各个协议进行统计 -c - 每隔一个固定时间，执行该 netstat 命令 -i - 显示网卡接口信息 常用命令 netstat -antp # 以数字的形式显示所有的 TCP 连接，并显示对应程序所监听的端口号 netstat -anup # 以数字的形式显示所有的 UDP 连接，并显示对应程序所监听的端口号 netstat -st # 统计 TCP 协议相关的网络统计数据 netstat -rn # 打印内核路由信息 netstat -ie # 显示网络接口信息 # 统计中当前 TCP 每个状态的数量，通过这个数量，我们就可以大致知道服务器 TCP 连接当前的健康状态 netstat -n | awk '/^tcp/{++state[$NF]}; END{for(key in state) print key, \"\\t\", state[key]}' # 统计连接某服务端口最多的 IP 地址 netstat -nat | grep \":80\" | awk '{print $5}' | awk -F: '{print $1}' | sort | uniq -c | sort -nr | head -20 命令输出详解 netstat -a netstat -a Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:http 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:https 0.0.0.0:* LISTEN tcp 0 0 jellythink:https 39.154.11.104:8543 ESTABLISHED tcp 0 0 jellythink:50398 100.100.30.25:http ESTABLISHED . . . . Active UNIX domain sockets (servers and established) Proto RefCnt Flags Type State I-Node Path unix 9 [ ] DGRAM 6897 /dev/log unix 2 [ ] DGRAM 9721 /run/systemd/shutdownd unix 3 [ ] STREAM CONNECTED 11477 unix 3 [ ] STREAM CONNECTED 11478 /run/systemd/journal/stdout unix 3 [ ] STREAM CONNECTED 11234 /run/systemd/journal/stdout . . . . Active Internet connections (servers and established) - 称为有源 TCP 连接，包括 TCP 和 UDP 等的详细状态 Active UNIX domain sockets (servers and established) - 称为有源 Unix 域套接口（ 和网络套接字一样，但是只能用于本机通信，性能可以提高一倍 ） 有源 TCP 连接字段详解： Proto - 当前连接的协议；如 TCP、UDP Recv-Q - 网络接收队列 Send-Q - 网络发送队列；接收队列和发送队列一般都应该是 0，如果不是则表示数据包正在队列中堆积，但是这种情况比较少见 Local Address - 本机的 ip:port（ 注意此处 127.0.0.1 默认显示主机名，0.0.0.0 默认显示 *，端口可能显示别名。若强制显示数字，加 -n 参数 ） Foreign Address - 对端 ip:port；与 Local Address 规则相同 State - 当前套接字的网络状态，有以下几种状态： LISTEN - 监听来自其它 TCP 端口的连接请求 SYN-SENT - 再发送连接请求后等待匹配的连接请求（如果有大量这样的状态包，检查是否中招了） SYN-RECEIVED - 再收到和发送一个连接请求后等待对方对连接请求的确认（如有大量此状态，估计被flood攻击了） ESTABLISHED - 代表一个打开的连接 FIN-WAIT-1 - 等待远程TCP连接中断请求，或先前的连接中断请求的确认 FIN-WAIT-2 - 从远程TCP等待连接中断请求 CLOSE-WAIT - 等待从本地用户发来的连接中断请求 CLOSING - 等待远程TCP对连接中断的确认 LAST-ACK - 等待原来的发向远程TCP的连接中断请求的确认（不是什么好东西，此项出现，检查是否被攻击） TIME-WAIT - 等待足够的时间以确保远程TCP接收到连接中断请求的确认 CLOSED - 没有任何连接状态 netstat -rn netstat -rn 内核 IP 路由表 Destination Gateway Genmask Flags MSS Window irtt Iface 0.0.0.0 192.168.152.1 0.0.0.0 UG 0 0 0 wlo1 169.254.0.0 0.0.0.0 255.255.0.0 U 0 0 0 wlo1 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 192.168.152.0 0.0.0.0 255.255.248.0 U 0 0 0 wlo1 Destination - 目标网络或目标主机 Gateway - 网关地址，如果没有就显示星号 Genmask - 网络掩码，0.0.0.0 表示默认路由 Flags - 标志位，有以下常用取值： U - 表示该路由是启动的 H - 目标是一部主机（ IP ）而非网域 G - 需要透过外部的主机（ gateway ）来转递封包 Iface - 网络接口名 free [Top] Display amount of free and used memory in the system 显示系统中已用和未用的物理内存、交换内存、共享内存和内核使用的缓冲区的总和 free [选项] [选项] -k - 以 KB 为单位显示内存使用情况 -m - 以 MB 为单位显示内存使用情况 -g - 以 GB 为单位显示内存使用情况 -h - 以人类友好的方式显示内存使用情况 命令输出详解 free -h total used free shared buff/cache available Mem: 7.7G 5.5G 637M 735M 1.5G 1.3G Swap: 7.9G 495M 7.4G total - 内存总数，物理内存总数 Mem - 物理内存 used - 已经使用的内存数 free - 空闲的内存数 shared - 多个进程共享的内存总额 buffers - 缓冲内存数 cached - 缓存内存数 Swap - 交换分区，虚拟内存 total = used + free + buff + cache buffer 是用于存放要输出到 disk（ 块设备 ）的数据的，而 cache 是存放从 disk 上读出的数据 A buffer is something that has yet to be \"written\" to disk A cache is something that has been \"read\" from the disk and stored for later use top [Top] Display Linux processes 显示当前系统正在执行的进程的相关信息，包括进程 ID、内存占用率、CPU 占用率等 top [选项] ([参数]) [选项] ( [参数] ) -b - 批处理 -c - 显示进程的命令行参数 ( 默认只有进程名 ) -I - 忽略失效过程 -s - 保密模式 -S - 累积模式 -d - 设置更新间隔时间 -u - 指定用户名 -p - 指定进程 -n - 循环显示的次数 常用命令 top #显示系统进程信息 top -b #以批处理模式显示程序信息 top -S #以累积模式显示程序信息 top -n 2 #设置信息更新次数,表示更新 2 次后终止更新显示 top -d -3 #设置信息更新时间,表示更新周期为 3 秒 top -p 1138 #显示进程号为1138 的进程信息，CPU、内存占用率等 使用技巧 进程字段排序 默认进入 top 时，各进程是按照 CPU 的占用量来排序的。但是，我们可以改变这种排序： M 键 - 根据驻留内存大小进行排序 P 键 - 根据 CPU 使用百分比大小进行排序 T 键 - 根据时间 / 累计时间进行排序 多核 CPU 监控 在 top 基本视图中，第三行表示 CPU 状态信息；这里显示数据是所有 CPU 的平均值（ avg-cpu ），多核 CPU 可以通过按 1 键来展开显示每个 CPU 状态 命令输出详解 top $ top top - 11:32:24 up 6:37, 0 users, load average: 0.50, 0.55, 0.52 Tasks: 2 total, 1 running, 1 sleeping, 0 stopped, 0 zombie %Cpu(s): 4.3 us, 1.4 sy, 0.2 ni, 93.3 id, 0.7 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem : 8055256 total, 444928 free, 4203968 used, 3406360 buff/cache KiB Swap: 8275964 total, 8273784 free, 2180 used. 3538032 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 18508 3188 2776 S 0.0 0.0 0:00.21 bash 10 root 20 0 36484 2940 2540 R 0.0 0.0 0:00.01 top 第一行：与 uptime 输出的信息一样 11:32:24 - 当前系统时间 up 6:37 - 系统已运行时间 0 users - 当前连接系统的终端数 系统负载 load average: 0.50, 0.55, 0.52 - 后面的三个数分别是 1 分钟、5 分钟、15 分钟的负载情况；如果平均负载值大于 0.7 * CPU 内核数，就需要引起关注 第二行：表示进程数信息 2 total - 总进程数 1 running - 正在运行的进程数 1 sleeping - 正在睡眠的进程数 0 stopped - 停止的进程数 0 zombie - 僵尸进程数 第三行：表示 CPU 状态信息 这里显示数据是所有 CPU 的平均值。多核 CPU 可以通过按 1 键来展开显示每个 CPU 状态 4.3 us - 用户空间占用 CPU 百分比 1.4 sy - 内核空间占用 CPU 百分比 0.2 ni - 用户进程空间内改变过优先级的进程占用 CPU 百分比 93.3 id - CPU 空闲率 0.7 wa - 等待 IO 的 CPU 时间百分比 0.0 hi - 硬中断（ Hardware IRQ ）占用 CPU 的百分比 0.0 si - 软中断（ Software Interrupts ）占用 CPU 的百分比 0.0 st - 这个虚拟机被 hypervisor 偷去的 CPU 时间（ 译注：如果当前处于一个 hypervisor 下的 vm，实际上 hypervisor 也是要消耗一部分 CPU 处理时间的 ） 第四行：物理内存使用信息 8055256 total - 物理内存总量 444928 free - 使用的物理内存总量 4203968 used- 空闲内存总量 3406360 buff/cache - 用作内核缓冲 / 缓存的内存量 第五行：交换空间使用信息 我们要时刻监控交换分区的 used，如果这个数值在不断的变化，说明内核在不断进行内存和 swap 的数据交换，这是真正的内存不够用了 8275964 total - 交换区总量 8273784 free - 交换区空闲量 2180 used - 交换区使用量 3538032 avail Mem - 可用于进程下一次分配的物理内存数量 第六行：空行 第七行：各个进程的状态信息 PID - 进程 id USER - 进程所有者 PR - 进程优先级 NI - nice 值；越小优先级越高，最小 -20，最大 20（ 用户设置最大 19 ） VIRT - 进程使用的虚拟内存总量，单位 kb；VIRT=SWAP+RES RES - 进程使用的、未被换出的物理内存大小，单位 kb；RES=CODE+DATA SHR - 共享内存大小，单位 kb S - 进程状态；D = 不可中断的睡眠状态、R = 运行、S = 睡眠、T = 跟踪/停止、Z = 僵尸进程 %CPU - 上次更新到现在的 CPU 时间占用百分比 %MEM - 进程使用的物理内存百分比 TIME+ - 进程使用的 CPU 时间总计 COMMAND - 命令名/命令行 ip [Top] show / manipulate routing, network devices, interfaces and tunnels ip [选项] 对象 { 命令 | help } 常用对象 link - 网络设备 address - 设备上的协议（ IP 或 IPv6 ）地址 addrlabel - 协议地址选择的标签配置 route - 路由表条目 rule - 路由策略数据库中的规则 常用选项 -V，-Version - 显示指令版本信息 -s，-stats，statistics - 输出详细信息 -h，-human，-human-readable - 输出人类可读的统计信息和后缀 -o，-oneline - 将每条记录输出到一行，用 \\ 字符替换换行符 常用命令 # ip address - 设定与 IP 有关的各项参数，包括 netmask， broadcast 等 ip addr show # 显示网卡及配置的地址信息，也可用 ip a s 或 ip a # ip address [add|del] [IP参数] [dev 设备名] [相关参数] # [add|del]：进行相关参数的增加(add)或删除(del)设定 # [IP 参数] ：主要就是网域的设定，例如 192.168.100.100/24 之类的设定 # [dev 设备名]：IP 参数所要设定的设备，例如eth0, eth1等 # [相关参数]： # broadcast：设定广播位址，如果设定值是 + 表示让系统自动计算 # label：该设备的别名，例如eth0:0 # scope：这个设备的领域，默认global，通常是以下几个大类 # global：允许来自所有来源的连线 # site：仅支持IPv6 ，仅允许本主机的连接 # link：仅允许本设备自我连接 # host：仅允许本主机内部的连接 ip addr add 192.168.0.50/255.255.255.0 dev eth0 # 为网卡分配 IP 地址以及其他网络信息 ip addr add broadcast 192.168.0.255 dev eth0 # 设置广播地址 ip addr add 192.168.0.20/24 dev eth0 label eth0:1 # 添加 eth0 网卡别名 ip addr del 192.168.0.10/24 dev eth0 # 删除网卡中配置的 IP 地址 # ip link - 可以操作与设备( device )有关的相关设定，包括 MTU 以及该网络设备的 MAC 等，也可以启动 ( up ) 或关闭 ( down ) 某个网络设备 ip -s link # 显示所有网络接口的统计数据 ip link set eth0 up # 启用网卡名为 etho0 的网卡 ip link set eth0 down # 禁用网卡 ip link set eth0 mtu 1000 # 更改 MTU 为 1000 bytes ip link set ent0 name eth1 # 更改网卡名字 # ip route - 路由配置,功能几乎与 route 这个命令一样，但是，它还可以进行额外的参数设置 ip route show # 查看路由信息，也可用 ip r s 或 ip r ip route get 119.75.216.20 # 通过 IP 地址查询路由包从哪条路由来 # ip route [add|del] [IP或网域] [via gateway] [dev 设备] # [add|del]：增加 ( add ) 或删除 ( del ) 路由 # [IP或网域]：可使用 192.168.50.0/24 之类的网域或者是单纯的 IP # [via gateway]：从哪个 gateway 出去，不一定需要 # [dev 设备名]：所要设定的设备，例如 eth0, eth1 等 ip route add default via 192.168.0.150/24 # 修改当前默认路由为 192.168.0.150 ip route add 172.16.32.32 via 192.168.0.150/24 dev eth0 # 添加特定网卡的路由，增加通往外部路由 ip route del 192.168.0.150/24 # 删除路由 ip route flush cache # 刷新路由表 # 检查所有的 ARP 记录 ip neigh 命令输出详解 ip address ip address 1: lo: mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: eth0: mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:1e:4f:c8:43:fc brd ff:ff:ff:ff:ff:ff inet 192.168.0.24/24 brd 192.168.0.255 scope global eth0 valid_lft forever preferred_lft forever 3: wlo1: mtu 1500 qdisc mq state UP group default qlen 1000 link/ether a4:02:b9:54:3f:80 brd ff:ff:ff:ff:ff:ff inet 192.168.158.164/21 brd 192.168.159.255 scope global dynamic noprefixroute wlo1 valid_lft 3378sec preferred_lft 3378sec inet6 fe80::1b3d:9f06:efac:3878/64 scope link noprefixroute valid_lft forever preferred_lft forever 系统有三个接口：lo 、eth0 和 wlo1，lo 是环回接口，eth0 这个普通网络接口，wlo1 是 wifi 接口 BROADCAST - 表示该接口支持广播 MULTICAST - 表示该接口支持多播 UP - 表示该网络接口已启用 LOWER_UP - 表示网络电缆已插入，设备已连接至网络 mtu 1500 - 最大传输单位（ 数据包大小 ）为 1500 字节 qdisc pfifo_fast - 用于数据包排队 state UP - 网络接口已启用 qlen 1000 - 传输队列长度 link/ether 00:1e:4f:c8:43:fc - 接口的 MAC（ 硬件 ）地址 brd ff:ff:ff:ff:ff:ff - 广播地址 inet 192.168.0.24/24 - IPv4 地址 brd 192.168.0.255 - 广播地址 scope global - 全局有效 dynamic noprefixroute wlo1 - 地址是动态分配的 valid_lft forever - IPv4 地址的有效使用期限 preferred_lft 3378sec - IPv4 地址的首选生存期 inet6 fe80::1b3d:9f06:efac:3878/64 - IPv6 地址 scope link - 仅在此设备上有效 valid_lft forever - IPv6 地址的有效使用期限 preferred_lft forever - IPv6 地址的首选生存期 ip route ip route default via 192.168.152.1 dev wlo1 proto dhcp metric 600 169.254.0.0/16 dev wlo1 scope link metric 1000 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown 192.168.152.0/21 dev wlo1 proto kernel scope link src 192.168.158.164 metric 600 第一条是默认的路由，我们可以根据我们的需要改动它 metric 1002 - 跳跃计数，确定网关的优先级，默认 20，数值越小优先级越高 proto kernel - 该路由的协议，主要有 redirect，kernel，boot，static，ra 等，其中 kernel 指的是直接由核心判断自动设定 ip -s link 1: lo: mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 RX: bytes packets errors dropped overrun mcast 12421814 19572 0 0 0 0 TX: bytes packets errors dropped carrier collsns 12421814 19572 0 0 0 0 2: eno1: mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether ec:8e:b5:44:4a:1c brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 0 0 0 0 0 0 TX: bytes packets errors dropped carrier collsns 0 0 0 0 0 0 3: wlo1: mtu 1500 qdisc mq state UP mode DORMANT group default qlen 1000 link/ether a4:02:b9:54:3f:80 brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 429373334 837924 0 0 0 0 TX: bytes packets errors dropped carrier collsns 23895841 143531 0 0 0 0 ip -s -s link eno1 2: eno1: mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether ec:8e:b5:44:4a:1c brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 0 0 0 0 0 0 RX errors: length crc frame fifo missed 0 0 0 0 0 TX: bytes packets errors dropped carrier collsns 0 0 0 0 0 0 TX errors: aborted fifo window heartbeat transns 0 0 0 0 1 RX - 表示接收 TX - 表示发送 bytes - 接收/发送的字节数 packets - 接收/发送的包数 errors - 接收/发送的带有错误的包总数 dropped - 由于处理资源不足导致接收/发送的丢弃的包数 overrun - 因接收溢出（ 环形缓冲区 ）导致丢失的包；通常如果接口溢出，则表示内核中存在严重问题，或者说服务器上该网络设备的处理设备太慢 mcast - 接收到的多播包数 carrier - 因数据链路错误导致发送失败的包数 collsns - 因在网络上发送冲突而导致的失败数 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux编译安装软件包详解.html":{"url":"Linux/Linux编译安装软件包详解.html","title":"Linux编译安装软件包详解","keywords":"","body":"Linux C/C++ 软件包编译、安装原理详解 Linux 下开源的　C/C++ 项目常常提供源码包，以下是转自阮一峰博客的一篇的安装方法./configure make make install(这些都是典型的使用GNU的AUTOCONF和AUTOMAKE产生的程序的安装步骤)的原理详解 ./configure - 配置　- 确定标准库和头文件的位置　- 确定依赖关系 make - 头文件的预编译(precompilation) - 预处理（Preprocessing）- 编译（Compilation）- 连接（Linking） sudo make install - 安装（Installation）- 操作系统连接 ./configure　通过检查用户的编译环境, 在根据用于指定的编译特性来生成Makefile文件，它是个shell脚本。 make是用来编译的，它从Makefile中读取指令，然后编译 make install是用来安装的，它也从Makefile中读取指令，安装到指定的位置 第一步 配置（configure） 编译器在开始工作之前，需要知道当前的系统环境，比如标准库在哪里、软件的安装位置在哪里、需要安装哪些组件等等。这是因为不同计算机的系统环境不一样，通过指定编译参数，编译器就可以灵活适应环境，编译出各种环境都能运行的机器码。这个确定编译参数的步骤，就叫做\"配置\"（configure） 这些配置信息保存在一个配置文件之中，约定俗成是一个叫做configure的脚本文件。通常它是由autoconf工具生成的。编译器通过运行这个脚本，获知编译参数 第二步 确定标准库和头文件的位置 源码肯定会用到标准库函数（standard library）和头文件（header）。它们可以存放在系统的任意目录中，编译器实际上没办法自动检测它们的位置，只有通过配置文件才能知道。 编译的第二步，就是从配置文件中知道标准库和头文件的位置。一般来说，配置文件会给出一个清单，列出几个具体的目录。等到编译时，编译器就按顺序到这几个目录中，寻找目标。 第三步 确定依赖关系 对于大型项目来说，源码文件之间往往存在依赖关系，编译器需要确定编译的先后顺序。 编译顺序保存在一个叫做makefile的文件中，里面列出哪个文件先编译，哪个文件后编译。而makefile文件由configure脚本运行生成，这就是为什么编译时configure必须首先运行的原因。 在确定依赖关系的同时，编译器也确定了，编译时会用到哪些头文件。 第四步 头文件的预编译（precompilation） 不同的源码文件，可能引用同一个头文件（比如stdio.h）。编译的时候，头文件也必须一起编译。为了节省时间，编译器会在编译源码之前，先编译头文件。这保证了头文件只需编译一次，不必每次用到的时候，都重新编译了。 不过，并不是头文件的所有内容，都会被预编译。用来声明宏的#define命令，就不会被预编译。 第五步 预处理（Preprocessing） 预编译完成后，编译器就开始替换掉源码中bash的头文件和宏。编译器在这一步还会移除注释。 这一步称为\"预处理\"（Preprocessing），因为完成之后，就要开始真正的处理了 第六步 编译（Compilation） 预处理之后，编译器就开始生成机器码。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码 第七步 连接（Linking） 对象文件还不能运行，必须进一步转成可执行文件 编译器的下一步工作，就是把外部函数的代码（通常是后缀名为.lib和.a的文件），添加到可执行文件中。这就叫做连接（linking）。这种通过拷贝，将外部函数库添加到可执行文件的方式，叫做静态连接（static linking），后文会提到还有动态连接（dynamic linking） 第八步 安装（Installation） 上一步的连接是在内存中进行的，即编译器在内存中生成了可执行文件。下一步，必须将可执行文件保存到用户事先指定的安装目录。 表面上，这一步很简单，就是将可执行文件（连带相关的数据文件）拷贝过去就行了。但是实际上，这一步还必须完成创建目录、保存文件、设置权限等步骤。这整个的保存过程就称为\"安装\"（Installation）。 第九步 操作系统连接 可执行文件安装后，必须以某种方式通知操作系统，让其知道可以使用这个程序了。比如，我们安装了一个文本阅读程序，往往希望双击txt文件，该程序就会自动运行。 这就要求在操作系统中，登记这个程序的元数据：文件名、文件描述、关联后缀名等等。Linux系统中，这些信息通常保存在/usr/share/applications目录下的.desktop文件中。另外，在Windows操作系统中，还需要在Start启动菜单中，建立一个快捷方式。 这些事情就叫做\"操作系统连接\"。make install命令，就用来完成\"安装\"和\"操作系统连接\"这两步。 第十步 生成安装包 写到这里，源码编译的整个过程就基本完成了。但是只有很少一部分用户，愿意耐着性子，从头到尾做一遍这个过程。事实上，如果你只有源码可以交给用户，他们会认定你是一个不友好的家伙。大部分用户要的是一个二进制的可执行程序，立刻就能运行。这就要求开发者，将上一步生成的可执行文件，做成可以分发的安装包。 所以，编译器还必须有生成安装包的功能。通常是将可执行文件（连带相关的数据文件），以某种目录结构，保存成压缩文件包，交给用户。 第十一步 动态连接（Dynamic linking） 正常情况下，到这一步，程序已经可以运行了。至于运行期间（runtime）发生的事情，与编译器一概无关。但是，开发者可以在编译阶段选择可执行文件连接外部函数库的方式，到底是静态连接（编译时连接），还是动态连接（运行时连接）。所以，最后还要提一下，什么叫做动态连接。 前面已经说过，静态连接就是把外部函数库，拷贝到可执行文件中。这样做的好处是，适用范围比较广，不用担心用户机器缺少某个库文件；缺点是安装包会比较大，而且多个应用程序之间，无法共享库文件。动态连接的做法正好相反，外部函数库不进入安装包，只在运行时动态引用。好处是安装包会比较小，多个应用程序可以共享库文件；缺点是用户必须事先安装好库文件，而且版本和安装位置都必须符合要求，否则就不能正常运行。 现实中，大部分软件采用动态连接，共享库文件。这种动态共享的库文件，Linux平台是后缀名为.so的文件，Windows平台是.dll文件，Mac平台是.dylib文件。 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux常用命令.html":{"url":"Linux/Linux常用命令.html","title":"Linux常用命令","keywords":"","body":"记录平时常用易忘的 Linux 命令 【参考】 搞定Linux Shell文本处理工具，看完这篇集锦就够了 - 腾讯云 目录 系统信息 硬件信息 性能分析 日志管理 搜索命令 find locate whereis which grep screen wget gcc sed awk grep tr wc 系统信息 [Top] uname -a # 查看 Linux 内核版本信息 cat /proc/version # 查看内核版本 cat /etc/issue # 查看系统版本 lsb_release -a # 查看系统版本，可以带各种参数, -a ALL locale -a # 列出所有语系 locale # 当前环境变量中所有编码 hwclock # 查看时间 who # 显示已登录用户 w # 显示已登录用户并显示它们正在执行任务 whoami # 查看当前用户名 logname # 查看初始登录用户名 uptime # 查看服务器启动时间 sar -n DEV 1 10 # 查看网卡网速流量 dmesg # 显示开机信息 lsmod # 查看内核模块 硬件信息 [Top] lscpu# 查看 CPU 信息 more /proc/cpuinfo# 查看 CPU 信息 cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c # 查看 CPU 型号和逻辑核心数 getconf LONG_BIT # CPU 运行的位数 cat /proc/cpuinfo | grep 'physical id' | sort | uniq -c # 物理 CPU 个数 cat /proc/cpuinfo | grep flags | grep 'lm' | wc -l # 结果大于 0 则支持 64 位 more /proc/meminfo # 查看内存信息 dmidecode # 查看全面硬件信息 dmidecode | grep \"Product Name\" # 查看服务器型号 dmidecode | grep -P -A5 \"Memory\\s+Device\" | grep Size | grep -v Range # 查看内存插槽 cat /proc/mdstat # 查看软 raid 信息 cat /proc/scsi/scsi # 查看 Dell 硬 raid 信息 ( IBM、HP 需要官方检测工具 ) lspci # 查看硬件信息 lspci | grep RAID # 查看是否支持 RAID lspci -vvv | grep Ethernet # 查看网卡型号 lspci -vvv | grep Kernel | grep driver # 查看驱动模块 modinfo tg2 # 查看驱动版本 ( 驱动模块 ) ethtool -i # 查看网卡驱动版本，先用 ip -a 查看网卡名 日志管理 [Top] 搜索命令 [Top] 1. find 实时查找工具，通过遍历指定路径而完成对文件的查找，精确实时查找，但速度慢，且只能搜索用户具备读取和执行权限的目录 find \\ [选项]|[表达式] ... \\ \\ - 指定搜索范围路径，默认为当前目录 \\ - 指定对符合条件的文件的操作，默认输出至屏幕 -exec command - [选项] -name - 搜索文件（夹）名 -iname：name的忽略大小写版本 -lname pattern：查找符号连接文件名为pattern的文件 -ilname：lname的忽略大小写版本 -type filetype - 以指定文件类型 filetype 查找文件，filetype 可以是： b：块设备 c：字符设备 d：目录 p：命名管道 f：普通文件 l：符号连接 s：socket -regex \"PATTERN\" - 以 PATTERN 匹配整个文件路径字符串，而不仅仅是文件名称 -iregex - regex 的忽略大小写版本 -inum - 根据文件的 inode 编号查找 -size [+-]n[cwbkMG] - 指定文件长度查找文件。单位可以是： c：字节单位 b：默认以块为单位，块大小为 512 字节 w：以 words 为单位，words 表示两个字节 k：以 1024 字节为单位 M：以 1048576 字节为单位 G：以 1073741824 字节为单位 +或-：文件大小大于或小于 n 单位 [表达式] expr1 expr2 expr1 -a expr2 或 expr1 -and expr2 - 效果一样，若 expr1 是 false 则不执行 expr2 ，反之则执行 expr2 find / -size +10M -a -size -50M -type f - 根目录下搜索大于 10M 且 小于 50M 的普通文件 expr1 -o expr2 或 expr1 -or expr2 - 效果一样，类似上面 实战 # 正则方式查找 .txt 和 pdf $ find . -regex \".*\\(\\.txt|\\.pdf\\)$\" # 查找 txt 和 pdf 文件 $ find . \\( -name \"*.txt\" -o -name \"*.pdf\" \\) -print # 查找所有非 txt 文本 $ find . ! -name \"*.txt\" -print # 最近 7 天被访问过的所有文件 $ find . -atime 7 -type f -print # 寻找大于 2k 的文件 $ find . -type f -size +2k # 找具有可执行权限的所有文件 $ find . -type f -perm 644 -print # 找用户weber所拥有的文件 $ find . -type f -user weber -print # 删除当前目录下所有的swp文件 $ find . -type f -name \"*.swp\" -delete # 将当前目录下的所有权变更为weber $ find . -type f -user root -exec chown weber {} \\ 2. locate 原理 Linux 系统会在 /etc/crontab 设定每天执行一次 updatedb ，而 updatedatedb 这个命令会建立硬盘中的所有档案和目录资料的索引数据库 更新 lib/mlocate/mlocage.db ，执行 locate 命令会在这个索引数据库中查找，所以相比于 find 命令查找 locate 更快 $ cat /etc/crontab 25 6 * * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily ) . . . $ ls /etc/cron.daily mlocate . . . $ cat /etc/cron.daily/mlocate # 可以看到定时执行 updatedb 具体过程 locate 不能查找到上次(一般一天更新一次) updatedb 或变动的文件，所以，需要查找当天变动的文件，可以前执行一边 updatedb ，更新索引数据库，再执行 locate locate [选项] 目标名 [选项] -r - 使用正规运算式 做寻找的条件 # 搜索 /etc/ 目录下名为 passwd 的文件路径 $ locate /etc/passwd /etc/passwd /etc/passwd- /snap/core/7917/etc/passwd /snap/core/8039/etc/passwd # 搜索主目录下以 a 开头的所有文件，且不区分大小写 $ locate -i ~/a 3. whereis whereis [选项] commandName 用于定位命令的二进制可执行文件、源码文件和手册文件 [选项] -b - binaries -m - manuals -s - sources $ whereis docker docker: /usr/bin/docker /etc/docker /usr/libexec/docker /usr/share/man/man1/docker.1.gz # 选项一定要放在 whereis 和 commandName 之间 $ whereis -b docker docker: /usr/bin/docker /etc/docker /usr/libexec/docker 4. which 在当前环境变量 $PATH 路径中，搜快速查找命令可执行文件路径 which [-a] commandName [-a] - 输出所有匹配的结果 $ which docker /usr/bin/docker # -a 必须在 which 和 commandName 之间 $ which -a java /usr/lib/jvm/jdk-12.0.1/bin/java /usr/bin/java 5. grep screen [Top] yum install screen apt install screen screen - 新建一个会话 screen -S [name] - 新建一个 name 会话 Ctrl+a+d - 暂离当前会话 screen -r -当只有一个会话时，直接重新进入会话 screen -r [name]|[id] - 重新进入 name 会话 screen -ls - 列出已创建的会话 exit - 在需要退出的会话执行 exit ，即删除当前会话 wget - World Wide Web Get [Top] wget [ ] [URL地址] 常用命令 // 支持断点续传 wget -c URL // 获取https地址时不检查证书 wget --no-check-certificate URL // 后台下载文件 wget -b URL //查看下载进度命令：tail -f wget-log // 测试下载链接 wget --spider URL // 设定下载带宽上线，实现限速下载 wget --limit-rate 数字k(千字节)/m(兆字节) URL // 访问需认证的页面 wget --user username -password password URL //指定–user 和–password参数 wget --user username --ask-password pass URL //不指定密码，而由网页提示并手动的输入密码 // 从保存多个链接的文件读取 URL 并下载（又称递归下载） cat > filelist.txt url1 url2 url3 url4 wget -i filelist.txt // 限制总下载文件大小 wget -Q 5m -i filelist.txt //想要下载的文件超过5M而退出下载，-Q 参数对单个文件下载不起作用，只能递归下载时才有效 wget 支持 HTTP，HTTPS 和 FTP 协议，支持 FTP 和 HTTP 下载方式，支持 http、https 代理（ 但不支持 socks 代理 ） gcc - GNU C Compiler - GNU Compiler Collection [Top] gcc 编译 c 源文件过程详解 gcc 命令使用 GNU 推出的基于 C/C++ 的编译器，是开放源代码领域应用最广泛的编译器，具有功能强大，编译代码支持性能优化等特点 经过了这么多年的发展，GCC 已经不仅仅能支持 C 语言；它现在还支持 Ada 语言、C++ 语言、Java 语言、Objective C 语言、Pascal 语言、COBOL 语言，以及支持函数式编程和逻辑编程的 Mercury 语言，等等 格式：gcc [选项] [参数] 选项： -o：指定生成的输出文件； -E：仅执行编译预处理； -S：将C代码转换为汇编代码； -wall：显示警告信息； -c：仅执行编译操作，不进行连接操作 // 无选项编译链接 - 将 test.c 预处理、汇编、编译并链接形成可执行文件，这里未指定输出文件，默认输出为 a.out gcc test.c // 将 test.c 预处理、汇编、编译并链接形成可执行文件 test，-o 选项用来指定输出文件的文件名 gcc test.c -o test // 将 test.c 预处理输出 test.i 文件 gcc -E test.c -o test.i gcc -E test.c //直接在终端输出显示 test.i 文件内容 // 将预处理输出文件 test.i 汇编成 test.s 文件 gcc -S test.c //会生成 test.s 文件 gcc -S test.i gcc -S test.i -o test.s // 将汇编输出文件 test.s 编译输出二进制 test.o 文件 gcc -c test.c //会生成 test.o 文件 gcc -c test.o gcc -c test.s -o test.o // 将编译输出文件 test.o 链接成最终可执行文件 test gcc test.o -o test // 多个文件一起编译 gcc test1.c test2.c -o test //或 gcc -c test1.c -o test1.o gcc -c test2.c -o test2.o gcc test1.o test2.o -o test Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux程序存放目录.html":{"url":"Linux/Linux程序存放目录.html","title":"Linux程序存放目录","keywords":"","body":" Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux文件系统学习.html":{"url":"Linux/Linux文件系统学习.html","title":"Linux文件系统学习","keywords":"","body":"Linux 文件系统学习 最近在做 OS 实现一个文件系统的课程设计，详细学习了一下 Linux 的文件系统，来总结记录一下 参考 阮一峰的网络日志 - 理解inode 背景知识 扇区 、簇 、 块 物理层面：一个磁盘按层次分为 磁盘组合 -> 单个磁盘 -> 某一盘面 -> 某一磁道 -> 某一扇区 扇区 - sector 扇区是磁盘中最小的物理存储单位，通常情况下每个扇区的大小是 512 字节（ 由于不断提高磁盘的大小，部分厂商设定每个扇区的大小是 4096 字节 ） 每个磁盘有多条同心圆似的磁道，磁道被分割成多个部分，每部分的弧长加上到圆心的两个半径，恰好形成一个扇形，所以叫做扇区 簇 - cluster 簇可以说是操作系统在实际分配、调度的逻辑存储单位 由于操作系统无法对数目众多的扇区进行寻址，所以操作系统就将相邻的扇区组合在一起，形成一个簇，然后再对簇进行管理 操作系统规定一个簇中只能放置一个文件的内容，因此文件所占用的空间，只能是簇的整数倍 Windows 的文件系统（ NTFS ）称呼为 “簇” 块 - block 块是 Linux 的文件系统（ EXT ）下逻辑存储单位，类似于簇，产生由来同簇 通过虚拟出来磁盘块的概念，在操作系统中认为块是最小的单位 MBR GPT / BIOS UEFI 待续 # Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux小知识.html":{"url":"Linux/Linux小知识.html","title":"Linux小知识","keywords":"","body":"平时 linux 遇到的问题解决办法和扩展小知识 目录 使用 wget 提示无法建立SSL连接 通过编译安装软件时：[Error]运行时找不到.so文件 更换 Ubuntu 18.04 LTS 登录界面背景 执行 make 命令时提示“makefile:2: * 遗漏分隔符 停止” Linux 下 gcc 编译 c 源文件过程详解 创建启动器（.Desktop文件) 浅谈 /etc/skel 文件夹 apt、wget、curl 设置代理端口 shell、终端、终端模拟器 Ubuntu 彻底关闭 dash sudo apt update显示：鉴于仓库 'xxx' 不支持 'i386' 体系结构，跳过配置文件 'xx' 的获取 Linux 中使用 crontab 命令启用自定义定时任务 Linux 添加环境变量 $PATH Linux 手动添加字体文件 #!/usr/bin/env 与 #!/usr/bin区别 永久修改 DNS Linux程序存放目录 更换镜像源 诊断某文件无法修改 Linux terminal 快捷键 通过 PID 查看进程完整信息 文件权限 777 /tmp 目录自动清理 使用 wget 提示无法建立SSL连接 [Top] [root@localhost ~]# wget https://www.kernel.org/pub/software/scm/git/git-2.0.5.tar.gz --2018-03-22 01:43:37-- https://www.kernel.org/pub/software/scm/git/git-2.0.5.tar.gz Resolving www.kernel.org... 147.75.42.139, 2604:1380:40a0:500::1 Connecting to www.kernel.org|147.75.42.139|:443... connected. ERROR: certificate common name “kernel.org” doesn’t match requested host name “www.kernel.org”. To connect to www.kernel.org insecurely, use ‘--no-check-certificate’. 这是因为 wget 在使用 HTTPS 协议时，默认会去验证网站的证书，而这个证书验证经常会失败，加上 \"--no-check-certificate\" 选项，就能排除掉这个错误 通过编译安装软件时：[Error]运行时找不到.so文件 [Top] 在 linux 下，.so 文件相当与 windows 上的 dll 文件，即动态链接库 在 Linux 下面，共享库(*.so) 的寻找和加载是由 /lib/ld.so 实现的 ld.so 会在标准路经 /lib，/usr/lib 中寻找应用程序用到的共享库 ld.so 也会在存有非标准路径的文件夹 /etc/ld.so.conf.ld 寻找应用程序用到的共享库 动态链接库是为了减少发布程序的大小，可以将具有相同功能的代码模块放在动态链接库中，随应用程序一起发布；而对于应用程序来说，只需要知道其接口就可以，在运行时动态的加载代码到内存中 ./SystemArchitect: error while loading shared libraries: libqt.so.3: cannot open shared object file: No such file or directory 原因：链接器 ld 提示找不到库文件 /etc/ld.so.conf 文件和 /etc/ld.so.conf.d/ 文件夹 Linux 中 ld 的默认目录为 /lib 和 /usr/lib，扩展库路径目录都存储在 /etc/ld.so.conf 文件里，而 /etc/ld.so.conf 的文件内容是include /etc/ld.so.conf.d/*.conf，所以在 /etc/ld.so.conf.d 目录下，加入任何以 .conf 为后缀的文件，都能被 ld 链接器识别 /etc/ld.so.conf 文件 /etc/ld.so.conf.d/文件夹 查看某个库是否安装 # 查看 libqt.so 是否安装 ldconfig -p | grep qt ldconfig -p | grep qt # ldconfig -p: 打印当前缓存所保存的所有库的名字 # grep qt/libqt: 用管道符解析 libqt.so 是否已加入缓存中 # qt 会打印所有 *qt.so.* 库文件信息，可以联想搜索；libqt 只会搜索 libqt.so.* 是否安装，若不存在不会返回显示 ldconfig 是一个动态链接库管理命令，其目的为了让动态链接库为系统所共享 ldconfig 默认搜寻/lib 和 /usr/lib 以及动态库配置文件 /etc/ld.so.conf 内所列的目录下的库文件 ldconfig 会搜索出所有库，进而创建动态装入程序(ld.so)所需的连接和产生缓存文件 /etc/ld.so.cache（该文件保存已排好序的动态链接库名字列表） ldconfig 通常在系统启动时运行，而当用户安装了一个新的动态链接库时，就需要手工运行这个命令 新增库文件（.so文件）方法 若库文件已经在 /lib 和 /usr/lib 里面，是不用修改 /etc/ld.so.conf 文件的，但是添加完后需要调用下 ldconfig，不然添加的 library 会找不到 .so 文件不在 /lib 和 /usr/lib 里，新增库路径方法 直接在 /etc/ld.so.conf 文件中后续添加 将库文件路径写入 /etc/ld.so.conf.d/ 文件夹中的 .conf 文件中 在 /etc/ld.so.conf.d/ 文件夹中添加新的 .conf 文件 如果添加的库不在 /lib 或 /usr/lib 下，但是却没有权限操作写 /etc/ld.so.conf 文件的话，这时就需要往 export 里写一个全局变量LD_LIBRARY_PATH就可以了 ld.so.cache 的更新是递增式的，就像 PATH 系统环境变量一样，不是从头重新建立，而是向上累加，只有重新开机，系统才从零开始建立 ld.so.cache 文件。所以每次修改 /etc/ld.so.conf 文件或 /etc/ld.so.conf.d/ 文件夹都要执行一次命令：ldconfig 更换 Ubuntu 18.04 LTS 登录界面背景 [Top] Ubuntu 18.04 LTS 默认登录界面 修改 /usr/share/gnome-shell/theme/ubuntu.css 或 /usr/share/gnome-shell/theme/gdm3.css 文件 Ubuntu 18.04 用的 Gnome 的桌面，和以前 Unity 桌面配置方式不同，所以 16.04 及以前版本修改方法与此不同 ubuntu.css 和 gdm3.css 内容相同，只需修改其一即可 修改该文件第 1814 行左右（#lockDialogGroup)： 修改前： #lockDialogGroup { background: #2c001e url(resource:///org/gnome/shell/theme/noise-texture.png); background-repeat: repeat; } 修改后： #lockDialogGroup { background: #2c001e url(file:///usr/share/gnome-shell/theme/denglubeijing.jpg); background-repeat: no-repeat; background-size: cover; background-position: center; } 这种方法在执行系统更新 -sudo apt upgrade 后可能以上修改的文件也被更新，再次登录时会发现又变回原来黑界面，所以还需要手动按照以上步骤修改才行 执行 make 命令时提示 “makefile:2: * 遗漏分隔符 停止\" [Top] 分析原因：gcc、rm、cp 前面是 tab 分割符，不能用空格，make 中规定每一 Shell 命令之前的开头必须使用字符 # makefile 文件部分示例 all: gcc -o helloworld helloworld.c fresh: rm -rf Makefile clean: rm -rf helloworld helloworld.o install: cp helloworld /usr/bin uninstall: rm -rf /usr/bin/helloworld Linux 下 gcc 编译 c 源文件过程详解 [Top] gcc 编译过程图 gcc 编译过程文件变化图 Linux 下与 C 语言有关的文件类型 .c - 源代码文件 .h - C语言头文件 .i - 经过预处理之后的源代码文件 .s - 汇编代码文件 .o - 目标代码文件（二进制机器指令文件） .a - 静态对象库文件 .so - 共享（动态）对象库文件 test.c 源文件 预编译（预处理 - Preprocessing） - gcc -E test.c -o test.i test.i 源文件预处理生成的文件 编译（Compilation） - gcc -S test.i -o test.s test.s 经编译生成的汇编文件 此阶段会检查代码逻辑，若出现错误会中断编译提示 test.s 编译出错中断提示 汇编(Assembly) - gcc -c test.s -o test.o test.o 由汇编文件生成的二进制文件 链接(Linking) - gcc test.o test test 链接后生成的可执行文件 多个 c 源文件生成一个可执行文件 方法一、 gcc test1.c test2.c -o test 方法二、 gcc -c test1.c -o test1.o gcc -c test2.c -o test2.o gcc test1.o test2.o -o test 第一种方法编译时需要所有文件重新编译，而第二种方法可以只重新编译修改的文件，未修改的文件不用重新编译 [补充参考] gcc 编译过程详解 创建启动器（.Desktop文件) [Top] 在 Linux 中，一个 .desktop 文件就是一个用来运行程序的快捷方式，没有此文件，你的应用就不会在应用菜单中显示。例如从源代码中编译的程序或者自己下载的压缩格式的应用，每次都需要打开终端来执行它的二进制文件 desktop 文件路径： 仅对当前用户可见：~/.local/share/applications 所有用户可见：/usr/share/applications/ desktop 文件创建 $ touch test.desktop test.desktop 文件内容 [Desktop Entry] Encoding=UTF-8 Name=IntelliJ IDEA GenericName=IntelliJ IDEA Comment=The Java IDE for Professional Developers by JetBrains Exec=/opt/SoftWare/idea-IU-172.4343.14/bin/idea.sh %f Icon=/opt/SoftWare/idea-IU-172.4343.14/bin/idea.png Terminal=false Type=Application Categories=Application;Programme; 语法解释： 关键词 意义 [Desktop Entry] 文件头 Encoding 编码 Name 应用名称 Name[xx] 不同语言的应用名称 GenericName 描述 Comment 注释 Exec 执行的命令 Icon 图标路径 Terminal 是否使用终端 Type 启动器类型 Categories 应用的类型（内容相关） 说明： 其中 Exec 常用的参数有：%f %F %u %U %f：单个文件名，即使选择了多个文件。如果已选择的文件不在本地文件系统中（比如说在HTTP或者FTP上），这个文件将被作为一个临时文件复制到本地，％f将指向本地临时文件； %F：文件列表。用于程序可以同时打开多个本地文件。每个文件以分割段的方式传递给执行程序。 %u：单个URL。本地文件以文件URL或文件路径的方式传递。 %U：URL列表。每个URL以分割段的方式传递给执行程序。本地文件以文件URL或文件路径的方式传递 修改权限: $ chmod 755 test.desktop 浅谈 /etc/skel 文件夹 [Top] skel 是 skeleton 的缩写，每当你新建一个用户的时候 (通过 useradd 命令)，/etc/skel 目录下的文件，都会原封不动的复制到新建用户的家目录下（~/） skel 目录 如果你是一个多用户系统的管理员，你可以在 skel 目录下写个 ReadMe.txt 之类的文件，写一些使用说明，这样每个新建的用户都会在自己的目录下看到这个说明文件了 再比如，你希望新建用户可以直接 startx 就启动到 gnome 桌面环境，你可以在 skel 目录下建立一个 .xinitrc 文件，内容如下： export LC_ALL=\"zh_CN.UTF-8\" export XMODIFIERS=@im=SCIM export GTK_IM_MODULE=\"scim\" eval `dbus-launch --exit-with-session --sh-syntax` exec gnome-session .xinitrc 是 X 启动需要读取的用户配置文件，这样每个用户 startx 之后就直接装载 gnome 了 你甚至可以在 sekl 目录下再建立目录，总之 /etc/skel 下的所有文件都会拷贝的用户的家目录去 你也许会想到，在 skel 目录下的 .bashrc 文件中加入一些方便的环境变量或者命令别名，这样每个新建用户都可以使用这些功能。不过，更好的选择是把这些设置放到全局的 /etc/profile 中，skel 目录下的文件是拷贝过去的，如果你修改或者增加了新的文件，只有新建的用户才能受益 Linux shell 中执行命令的查找顺序 apt、wget、curl 设置代理端口 [Top] apt 代理设置 １. 作用于当前终端（临时有效，关闭当前终端，再打开终端则无效） bash 里命令行执行export http_proxy=http://yourproxyaddress:proxyport（https、ftp等其他代理类型类似） 此时 wget、curl等应用程序都是使用http_proxy ２. 专门设置 apt 的代理 如果您希望 apt（而不是其他应用程序）一直使用某个代理，可以编辑 /etc/apt/apt.conf 配置文件（如果 /etc/apt/ 目录下没有 apt.conf 文件，那么需要手动创建） 按照下面的格式，将网络代理配置信息加入到 apt.conf 文件里Acquire::http::proxy “http://user:passwd@proxyserver:port”; Acquire::http::Proxy \"http://yourproxyaddress:proxyport\"; Acquire::http::Proxy “http://192.168.0.1：80“； Acquire::ftp::proxy \"ftp://127.0.0.1:8000/\"; 保存退出当前配置文件，关闭当前终端，然后打开另一个终端 运行 sudo apt-get update 命令，来检测 ubuntu 系统是否能够正常更新 统一设置所有应用程序的代理，对所有用户有效 统一设置所有应用程序的代理，对当前用户和所有有效，会覆盖　/etc/environment 里的相同代理设置 如果您希望 apt和其他应用程序如 wget 等都使用代理，您可以使用这种方式，编辑 ~/.bashrc文件，在您的.bashrc文件末尾添加如下内容：export http_proxy=http://yourproxyaddress:proxyport # 根据你的实际情况替换yourproxyaddress和proxyport 保存退出当前配置文件，关闭当前终端，然后打开另一个终端 运行 sudo apt-get update 命令，来检测 ubuntu 系统是否能够正常更新 wget 代理设置 １. 临时有效 bash 里命令行执行export http_proxy=http://yourproxyaddress:proxyport（https、ftp等其他代理类型类似） 此时 wget、curl、apt 等应用程序都是使用http_proxy 直接将代理作为 wget 命令的参数：wget ... -e use_proxy=yes -e http_proxy=http://yourproxyaddress:proxyport ... shell、终端、终端模拟器 [Top] shell 其实是 /bin 目录下的可执行文件 Linux 将允许使用的 shell 不同版本名存储在 /etc/shells，可以使用cat /etc/shells查看 /bin 目录下的不同的 shell 版本 终端 - terminal terminal 只是一个命令的输入窗口，例如 Windows 有 CMD 谈到 shell 以前以为就是这个，但这只是 terminal 终端模拟器 - terminal emulator 例如：Windows 下的 Putty、Xshell；Linux 下的 Guake Terminal Ubuntu 彻底关闭 dash [Top] Ubuntu 安装了 dockey 代替系统设置里的默认 dash，但系统设置不能选择关闭 dash（只能选择隐藏，但时常误触就会弹出，很烦人） 解决方法：在目录 /usr/share/gnome-shell/extensions/删除文件夹ubuntu-dock@ubuntu.com 一定要先备份ubuntu-dock@ubuntu.com，注意权限问题 sudo apt update 提示异常信息 [Top] N: 鉴于仓库 'http://dl.google.com/linux/earth/deb stable InRelease' 不支持 'i386' 体系结构，跳过配置文件 'main/binary-i386/Packages' 的获取。 分析：这是因为执行sudo apt update时根据/etc/apt/sources.list镜像站读取下载所有软件源到`/var/lib/apt/lists/'目录，但可能会下载了自己电脑架构不兼容的软件源，这样就会提示上面信息 解决方法 移除架构不兼容的软件源 执行命令：dpkg --remove-architecture i386 上面命令可能出现错误：dpkg: 错误: 无法移除体系结构 i386 ，当前它仍被数据库使用 先查看 安装了哪些外部架构： dpkg --print-foreign-architectures 可能会显示： i386 删除所有已下载的 i386 软件包：apt-get purge \".*:i386\" purge 关键字（而不是 remove ）将删除与要卸载的软件包关联的所有配置文件 现在您可以删除 i386 架构：dpkg --remove-architecture i386 Linux 中使用 crontab 命令启用自定义定时任务 [Top] crontab - 定时任务 简介 Linux 下的任务调度分为两类，系统任务调度和用户任务调度 系统任务调度：系统需要定期执行的任务，比如重启、日志清理等，其配置文件是：/etc/crontab 用户任务调度：某个用户需要定期执行的任务，用户可以使用crontab命令来配置自己的定时任务。所有用户配置的定时任务都存放在 /var/spool/cron/crontabs/ 目录下，其文件名与用户名一致。如：root用户的所有定时任务就保存在 /var/spool/cron/root 文件中 /var/spool/cron/crontabs目录需要切换到 root 权限才能打开 crontab 文件详解 /etc/crontab文件源代码 # /etc/crontab: system-wide crontab # Unlike any other crontab you don't have to run the `crontab' # command to install the new version when you edit this file # and files in /etc/cron.d. These files also have username fields, # that none of the other crontabs do. SHELL=/bin/sh PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin # m h dom mon dow user command 17 * * * * root cd / && run-parts --report /etc/cron.hourly 25 6 * * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily ) 47 6 * * 7 root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly ) 52 6 1 * * root test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly ) # /var/spool/cron/crontab/用户名文件源代码 # DO NOT EDIT THIS FILE - edit the master and reinstall. # (/tmp/crontab.LtbPsE/crontab installed on Fri Dec 14 21:01:59 2018) # (Cron version -- $Id: crontab.c,v 2.13 1994/01/17 03:20:37 vixie Exp $) # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any').# # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command */10 * * * * /usr/local/bin/himawaripy */10 * * * * /usr/local/bin/himawaripy 详解 crontab 文件中添加配置格式 它的格式一共分为六个字段，前五段是时间设置段，第六段是要执行的命令段，格式如下： minute hour day month week command minute： 表示分钟，可以是从 0 到 59 之间的任何整数 hour：表示小时，可以是从 0 到 23 之间的任何整数 day：表示日期，可以是从 1 到 31 之间的任何整数 month：表示月份，可以是从 1 到 12 之间的任何整数 week：表示星期，可以是从 0 到 7 之间的任何整数，这里的 0 或 7 都代表星期日 command：表示需要执行的命令，可以是系统命令，也可以是自己编写的脚本文件 在以上各个字段中，还可以使用以下特殊字符： ``` 代表所有可能的值，例如：如果 month 字段是星号，则表示在满足其它字段的约束条件后每月都执行该命令 , 用逗号隔开的值表示一个范围列表，例如：如果 minute 字段的值是 “1,3,15”，则表示每小时的第 1 分钟、第 3 分钟和第 15 分钟都执行该命令 – 可以用整数之间的 – 表示一个整数范围，例如：如果 day 字段的值是 “2-6”，则表示每月的第2天到底6天都执行该命令 / 可以用斜线表示命令的执行频率，例如：如果 minute 字段的值是 “*/10”，则表示每十分钟执行一次命令 ``` Linux 添加环境变量 $PATH [Top] 有时手动编译安装软件包时，可执行目录 - bin 目录并不在环境变量 $PATH 里，所以不可以直接在终端执行，这时需要手动添加新的 bin 路径到 $PATH 环境变量中 $PATH：决定了 shell 将到哪些目录中寻找命令或程序，PATH 的值是一系列目录，当您运行一个程序时，Linux 在这些目录下进行搜寻编译链接 其格式为： PATH=$PATH::::------: 你可以自己加上指定的路径，中间用冒号隔开 环境变量更改后，在用户下次登陆时生效，如果想立刻生效而免去重新启动，则可执行下面的语句：$source /etc/profile 添加方法 临时添加，退出终端即没有效果了 sudo export PATH=/usr/local/vim/bin:$PATH /etc/profile 文件中修改，全局永久有效 sudo vim /etc/profile # 在文档最后，添加 export PATH=\"/usr/local/vim/bin:$PATH\" # 保存，退出，然后运行，即可立即生效 source /etc/profile Linux 手动添加字体文件 [Top] Linux 的字体都在 /usr/share/fonts 这个目录里，一种字体就是这个目录下面的一个子目录 将字体文件（.ttf 文件）放入这个目录下，还需要用root用户身份依次执行如下三条命令，这个字体才能用sudo mkfontscale sudo mkfontdir sudo fc-cache -fv #!/usr/bin/env 与 #!/usr/bin区别 [Top] 在 Linux、Unix、Mac 的一些脚本中，经常在开头出现#!/usr/bin/env 与 #!/usr/bin 例如： #!/usr/bin/env python #!/usr/bin python #!/usr/bin/env perl #!/usr/bin perl 区别 #!/usr/bin python: 表示脚本执行的一定是/usr/bin/python解释器，但有时 python 解释器并不是安装在/usr/bin目录下，这时脚本就无法执行。 #!/usr/bin/env python: 脚本执行时会通过命令/usr/bin/env运行 python，env 会从环境变量中寻找 python 解释器并执行。所以，即使 python 并未安装在 /usr/bin 目录下也是可以的 推荐使用#!/usr/bin/env python 形式 永久修改 DNS [Top] https://blog.csdn.net/MrBaymax/article/details/79430744 https://www.zhujibiji.com/2017/12/linux-permanently-modify-dns/ Linux程序存放目录 [Top] 更换镜像源 [Top] 阿里镜像源：https://opsx.alibaba.com/mirror?lang=zh-CN 对应镜像源后【帮助】，有对应修改详细介绍 诊断某文件无法修改 [Top] 使用 file filename 查看文件格式，若不是文本文件，是无法编辑的 最可能是权限问题，ls -l filename 查看文件权限，若是，使用 chmod 或 chown 修改之 1 、2 都不是的话，使用 lsattr filename 查看文件隐藏属性，若是，使用 chattr 修改之 Linux terminal 快捷键 [Top] 终端快捷键 功能 Ctrl + a 光标移动到行首 Ctrl + e 光标移动到行尾 Ctrl + c 终止当前程序 Ctrl + d 如果光标前有字符则删除，没有则退出当前中断 Ctrl + l 清屏 Ctrl + u 剪切光标以前的字符 Ctrl + k 剪切光标以后的字符 Ctrl + y 复制 Ctrl u / k 的内容 Ctrl + r 查找最近用过的命令 Ctrl+shift+c 复制 Ctrl+shift+v 粘贴 通过 PID 查看进程完整信息 [Top] 通常已知 Port ，可以通过 lsof -i:\\ 得到 PID，然后使用 ps aux | grep PID 或 ps -ef | grep PID，查看进程信息，但有时需要进程的更多的信息，这时就可以直接找到进程的文件（Linux 中一切皆是文件） 每个进程，都会在 /proc 文件夹里面生成一个进程目录，里面存放了进程的各种信息 sudo ls -l /proc/\\ $ ps -ef | grep v2ray | grep -v grep root 9541 1 0 Nov21 ? 00:00:02 /usr/bin/v2ray/v2ray -config /etc/v2ray/config.json $ sudo ls -l /proc/9541 总用量 0 dr-xr-xr-x 2 root root 0 Nov 21 19:23 attr -rw-r--r-- 1 root root 0 Nov 22 19:41 autogroup -r-------- 1 root root 0 Nov 22 19:41 auxv -r--r--r-- 1 root root 0 Nov 21 19:23 cgroup --w------- 1 root root 0 Nov 22 19:41 clear_refs -r--r--r-- 1 root root 0 Nov 21 19:23 cmdline -rw-r--r-- 1 root root 0 Nov 21 19:23 comm -rw-r--r-- 1 root root 0 Nov 22 19:41 coredump_filter -r--r--r-- 1 root root 0 Nov 22 19:41 cpuset lrwxrwxrwx 1 root root 0 Nov 22 19:41 cwd -> / -r-------- 1 root root 0 Nov 22 19:41 environ lrwxrwxrwx 1 root root 0 Nov 22 19:41 exe -> /usr/bin/v2ray/v2ray dr-x------ 2 root root 0 Nov 21 19:23 fd dr-x------ 2 root root 0 Nov 22 19:41 fdinfo -rw-r--r-- 1 root root 0 Nov 22 19:41 gid_map -r-------- 1 root root 0 Nov 22 19:41 io -r--r--r-- 1 root root 0 Nov 22 19:41 limits -rw-r--r-- 1 root root 0 Nov 21 19:23 loginuid dr-x------ 2 root root 0 Nov 22 19:41 map_files -r--r--r-- 1 root root 0 Nov 22 19:41 maps -rw------- 1 root root 0 Nov 22 19:41 mem -r--r--r-- 1 root root 0 Nov 22 19:41 mountinfo -r--r--r-- 1 root root 0 Nov 22 19:41 mounts -r-------- 1 root root 0 Nov 22 19:41 mountstats dr-xr-xr-x 6 root root 0 Nov 22 19:41 net dr-x--x--x 2 root root 0 Nov 22 19:41 ns -r--r--r-- 1 root root 0 Nov 22 19:41 numa_maps -rw-r--r-- 1 root root 0 Nov 22 19:41 oom_adj -r--r--r-- 1 root root 0 Nov 22 19:41 oom_score -rw-r--r-- 1 root root 0 Nov 22 19:41 oom_score_adj -r-------- 1 root root 0 Nov 22 19:41 pagemap -r-------- 1 root root 0 Nov 22 19:41 patch_state -r-------- 1 root root 0 Nov 22 19:41 personality -rw-r--r-- 1 root root 0 Nov 22 19:41 projid_map lrwxrwxrwx 1 root root 0 Nov 22 19:41 root -> / -rw-r--r-- 1 root root 0 Nov 22 19:41 sched -r--r--r-- 1 root root 0 Nov 22 19:41 schedstat -r--r--r-- 1 root root 0 Nov 21 19:23 sessionid -rw-r--r-- 1 root root 0 Nov 22 19:41 setgroups -r--r--r-- 1 root root 0 Nov 22 19:41 smaps -r--r--r-- 1 root root 0 Nov 22 19:41 smaps_rollup -r-------- 1 root root 0 Nov 22 19:41 stack -r--r--r-- 1 root root 0 Nov 21 19:23 stat -r--r--r-- 1 root root 0 Nov 22 19:41 statm -r--r--r-- 1 root root 0 Nov 21 19:23 status -r-------- 1 root root 0 Nov 22 19:41 syscall dr-xr-xr-x 19 root root 0 Nov 22 19:41 task -r--r--r-- 1 root root 0 Nov 22 19:41 timers -rw-rw-rw- 1 root root 0 Nov 22 19:41 timerslack_ns -rw-r--r-- 1 root root 0 Nov 22 19:41 uid_map -r--r--r-- 1 root root 0 Nov 22 19:41 wchan cwd - 符号链接的是进程运行目录 exe - 符号连接就是执行程序的绝对路径 cmdline - 就是程序运行时输入的命令行命令 environ - 记录了进程运行时的环境变量 fd - 目录下是进程打开或使用的文件的符号连接 文件权限 777 [Top] 文件权限 777、644 等等，其实是八进制的表示方法 /tmp 目录自动清理 [Top] 在线安装软件时，常常将安装包先下载到 /tmp/ 下面，这是因为 /tmp/ 目录会定时自动清理 在 RHEL6 中，系统自动清理 /tmp 文件夹的默认时限是 30 天 在 Ubuntu 中，系统自动清理 /tmp 文件夹的时限默认每次启动 一段脚本片段 [Top] #!/bin/bash # Don't generate .pyc files export PYTHONDONTWRITEBYTECODE=1 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux用户和用户组管理.html":{"url":"Linux/Linux用户和用户组管理.html","title":"Linux用户和用户组管理","keywords":"","body":"Linux 用户和用户组管理 相关配置文件： /etc/passwd 用户账户信息。 /etc/shadow 安全用户账户信息。 /etc/group 组账户信息。 /etc/gshadow 安全组账户信息 一台服务器至少应该设置两个用户，一个是 root,另外一个是拥有 root 权限的普通用户（通过配置 /etc/sudoers 可以实现），这样就能够保证一个密码出错后还可以通过另外一个用户登录服务器重置密码 chmod chown chgrp useradd userdel [username] - 删除 username 用户，但不删除该用户主目录 userdel -r [username] - 删除 username 用户，一并删除该用户主目录 groupadd groupdel passwd gpasswd -a [username] [groupname] - 将用户 username 添加到 groupname 组 gpasswd -d [username] [groupname] - 将用户 username 从 groupname 组中删除 cat -n /etc/group | grep [groupname] - 单独查看 groupname 组信息 cat -n /etc/passwd | grep [username] - 单独查看 username 用户信息 id [username] - 查看 username 用户信息和该用户的组信息 usermod suid/guid useradd userdel usermod groupadd groupdel groupmod chmod ** ** ** ** Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux用户增删改等学习.html":{"url":"Linux/Linux用户增删改等学习.html","title":"Linux用户增删改等学习","keywords":"","body":" Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Linux主机、虚拟机和docker网络配置.html":{"url":"Linux/Linux主机、虚拟机和docker网络配置.html","title":"Linux主机、虚拟机和docker网络配置","keywords":"","body":"Linux 主机、虚拟机和docker网络配置 使用过 VMware 、VirtualBox、KVM，但一直不太喜欢，最主要的原因就是繁琐的网络配置，例如 NAT、桥接、Host-Only 都啥意思，一直不懂，一直都是按着网上安装教程傻瓜式操作，最近需要搭建多台虚拟机，单是一个里面 ping 外面、外面 ping 里面、虚拟机互相 ping，就弄得我晕头转向！关键还是网络配置的短板，特来记录一下几天来的学习！ 背景学习 1、IP、NetMask、GateWay、DNS 检查 DNS 是否正常：因为 QQ 不需要有 DNS ( QQ 只是一个客户端程序，用不到 DNS)，只有浏览网页 ( 需输入网址时 ) 才用到 DNS，所以如果出现 QQ 能用但浏览器连不上网，则很可能是 DNS 出现问题 Sub NetMask - 子网掩码 子网掩码 - 用来判断任意两台计算机的 IP 地址是否属于同一子网络 对于一台计算机来说，差不多有三种场合的通信 1）自己与自己通信 2）与本网段其它主机通信 3）与别的网段主机的通信 子网掩码就是为了分辨出以上三个场景而设计的 举个例子：10.10.10.1 255.255.255.0 其中 255.255.255.0 就是网络掩码，由于这个掩码全 1 的二进制位长为 24位，我们也经常写为 10.10.20.1/24 自己与自己通信 当 ping 10.10.10.1 时，计算机和自己的IP相比较，所以会发给自己，我们称之为精确匹配 与本网段其它主机通信 当 ping 10.10.10.2 时，计算机和自己的 IP 相比较，发现并不相等，则需要退而求其次，使用模糊匹配，用自己的掩码 255.255.255.0 与 10.10.10.2 做按位与，得到网段 10.10.10，这个和自己在一个网段（一个广播域），所以可以广播 ARP 得到对方的 MAC，完成通信。 与别的网段主机的通信 当 ping 8.8.8.8 时，计算机和自己的 IP 相比较，发现并不相等，则需要退而求其次，使用模糊匹配，用自己的掩码 255.255.255.0 与 8.8.8.8 做按位与，得到网段 8.8.8，和自己 10.10.10 不在一个网段，需要使用最模糊的匹配，一般会匹配 0.0.0.0/0，这个是最后的选择，一般指向网关，由于网关和自己在一个网段（一个广播域），所以可以广播 ARP 得到网关的MAC，然后把 ping 包发给网关，完成通信 GateWay - 网关 网关 - 是一个网络通向其他网络的 IP 地址 比如有网络 A 和网络 B，网络 A 的 IP 地址范围为 192.168.1.1~192. 168.1.254，子网掩码为 255.255.255.0；网络 B 的 IP 地址范围为 192.168.2.1~192.168.2.254，子网掩码为 255.255.255.0。在没有路由器的情况下，两个网络之间是不能进行 TCP/IP 通信的，即使是两个网络连接在同一台交换机（或集线器）上，TCP/IP 协议也会根据子网掩码（ 255.255.255.0 ）判定两个网络中的主机处在不同的网络里。而要实现这两个网络之间的通信，则必须通过网关 ( 比如路由器 ) 如果网络 A 中的主机发现数据包的目的主机不在本地网络中，就把数据包转发给它自己的网关，再由网关转发给网络 B 的网关，网络 B 的网关再转发给网络 B 的某个主机 DNS - Domain Name Server - 域名服务器 将 URL 解析成主机 IP 地址 2、常见网卡详解 ​ 服务器通常有多块网卡，有板载集成的，同时也有插在 PCIe 插槽的。Linux 系统的命名原来是 eth0,eth1 这样的形式，但是这个编号往往不一定准确对应网卡接口的物理顺序 网卡查看方法 ip a ifconfig 以上命令都没安装，还可直接读取文件 cat /proc/net/dev 判断网卡是虚拟还是物理网卡 # /sys/devices/virtual/net 目录下都是虚拟网卡 $ ls -l /sys/devices/virtual/net 总用量 0 drwxr-xr-x 7 root root 0 Nov 22 16:48 docker0 drwxr-xr-x 5 root root 0 Nov 22 16:48 lo drwxr-xr-x 6 root root 0 Nov 22 16:48 veth61d2c91 drwxr-xr-x 6 root root 0 Nov 22 16:48 vethbe484a2 物理网卡 eno1 - 代表由主板 bios 内置的网卡，如果从 BIOS 中能够取到可用的，板载网卡的索引号，则使用这个索引号命名，例如: eno1 ens1 - 代表有主板 bios 内置的 PCI-E 网卡，如果从BIOS中能够取到可以用的，网卡所在的PCI-E热插拔插槽(\\注：pci槽位号)**的索引号，则使用这个索引号命名，例如: ens1 enp2s0 - PCI-E 独立网卡，如果能拿到设备所连接的物理位置（PCI总线号+槽位号）信息，则使用这个信息命名，例如: enp2s0 eth0、eth1、eth2 ... - 如果以上都不使用，则回到默认的网卡名，统一的 kernel 命名方法，例如: eth0，这种命名方法的结果不可预知的，即可能第二块网卡对应 eth0，第一块网卡对应 eth1 虚拟网卡 虚拟网络接口并不真实地从外界接收和发送数据包，而是在系统内部接收和发送数据包，因此虚拟网络接口不需要驱动程序 虚拟网卡和物理网卡在使用上是一致的 lo - localhost - 本地环回接口，ip 是 127.0.0.1，实现系统内部发送和接收数据 docker0 - docker 在宿主机中的网卡 3. Linux 网络配置文件 I、CentOS 系列 /etc/sysconfig/network-scripts/ - 网卡的控制文件目录 $ ls /etc/sysconfig/network-scripts/ ifcfg-eth0 ifdown-ib ifdown-ppp ifdown-tunnel ifup-ib ifup-plusb ifup-Team network-functions ifcfg-lo ifdown-ippp ifdown-routes ifup ifup-ippp ifup-post ifup-TeamPort network-functions-ipv6 ifdown ifdown-ipv6 ifdown-sit ifup-aliases ifup-ipv6 ifup-ppp ifup-tunnel ifdown-bnep ifdown-isdn ifdown-Team ifup-bnep ifup-isdn ifup-routes ifup-wireless ifdown-eth ifdown-post ifdown-TeamPort ifup-eth ifup-plip ifup-sit init.ipv6-global /etc/sysconfig/network-scripts/ifcfg-eth0 - 网卡信息文件 DEVICE=eth0 #网卡设备名称 ONBOOT=yes #启动时是否激活 yes | no BOOTPROTO=static #协议类型 dhcp bootp none IPADDR=192.168.1.90 #网络IP地址 NETMASK=255.255.255.0 #网络子网地址 GATEWAY=192.168.1.1 #网关地址 BROADCAST=192.168.1.255 #广播地址 HWADDR=00:0C:29:FE:1A:09 #网卡MAC地址 TYPE=Ethernet #网卡类型为以太网 TYPE 网络类型（通常是 Ethemet） DEVICE 接口名（设备,网卡） USERCTL [yes|no]（非root用户是否可以控制该设备） BOOTPROTO IP 的配置方法 [none|static|bootp|dhcp]（引导时不使用协议|静态分配IP|BOOTP协议|DHCP协议） HWADDR MAC地址 ONBOOT 系统启动的时候网络接口是否有效（yes/no） NETMASK 网络掩码 IPADDR IP 地址 IPV6INIT IPV6 是否有效（yes/no） GATEWAY 默认网关IP地址 BROADCAST 广播地址 NETWORK 网络地址 DNS1 第一 DNS 服务器指向； DNS2 备用 DNS 服务器指向； 修改 /etc/sysconfig/network-scripts/ifcfg-eth0 文件后需要重启网卡 ( sudo systemctl restart network )或电脑 /etc/sysconfig/network /etc/resolv.conf - DNS 配置文件 /etc/hostname - 主机名 /etc/hosts II、Ubuntu 系列 /etc/network /etc/network/interfaces - ip、子网掩码、默认网关 /etc/NetworkManager/ /etc/hostname - 主机名 /etc/resolv.conf - DNS 配置文件 /etc/hosts Linux 主机常用网络配置 I. Ubuntu 设置静态 IP $ vim /etc/network/interface # 在 interface 添加 eth0 接口的 IP，网络号，掩码，广播地址和网关 auto eth0 iface eth0 inet static address 192.168.2.100 network 192.168.2.0 netmask 255.255.255.0 broadcast 192.168.0.255 gateway 192.168.0.1 重启网卡 $ sudo ifup eth0 $ sudo ifdown eth0 # 或 $ sudo ifconfig eth0 down $ sudo ifconfig eth0 up 重启网络 `sudo` `/etc/init``.d``/networking` `restart``sudo` `/etc/init``.d``/network-manager` `restart` ** ** ** 2. NAT Bridged Adapter Host-Only VM -> Host Host -> VM VM VM VM -> Other Host Other Host -> VM 桥接 - Bridged Adapter 虚拟机和主机是处于同等地位的机器，所以网络功能也无异于主机。并且和主机处于同一网段 原理 桥接模式，使用的是VMnet0虚拟网卡。 vmnet0实际上就是一个虚拟的网桥(2层交换机)，这个网桥有若干个接口，一个端口用于连接你的Host主机，其余端口可以用于连接虚拟机，他们的位置是对等的，谁也不是谁的网关。所以桥接模式下，虚拟机和Host主机是同等地位的主机 配置 /etc/sysconfig/network-scripts/ifcfg-enp0s3 NAT - Network address translation - 网络地址转换 Linux 网络配置命令 ifconfig - 网卡配置 【参考】 linux网卡命名规则 IP地址，子网掩码，默认网关，DNS服务器详解 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/SSH详解.html":{"url":"Linux/SSH详解.html","title":"SSH详解","keywords":"","body":"SSH 详解 目录 SSH 介绍 应用篇 Linux SSH 相关命令 SSH 密码或无密码( 密钥 )登录 原理篇 密码学加密算法 SSH 登录原理 SSH 中间人攻击 SSH 介绍 [Top] Secure Shell（安全外壳协议，简称SSH）是一种加密的网络传输协议，可在不安全的网络中为网络服务提供安全的传输环境 SSH通过在网络中创建安全隧道来实现 SSH 客户端与服务器之间的连接 在设计上，SSH是 Telnet 和非安全 shell 的替代品，Telnet 和 Berkeley rlogin、rsh、rexec 等协议采用 明文 传输，使用不可靠的密码，容易遭到监听、嗅探 和 中间人攻击 SSH使用 客户端-服务器 模型，标准端口为 22。服务器端需要开启SSH守护进程以便接受远端的连接，而用户需要使用 SSH 客户端与其创建连接 SSH 的经典用途是登录到远程电脑中执行命令。除此之外，SSH 也支持隧道协议、端口映射和X11连接。借助 SFTP 或 SCP 协议，SSH 还可以传输文件 应用篇 [Top] Linux SSH 相关命令 ssh -v \\@\\ - 打印运行情况和调试信息 ssh \\@\\ - 登录 host ssh \\@\\ \\ - 登录 host 直接执行命令 ssh \\@\\ 'tar cz file' | tar zxv - 本地 ~/file 文件通过 ssh 加密传输到 hostip 的 ~ 目录下 ssh \\@\\ 'tar cz file' | tar xzv - hostip 的 ~/file 文件通过 ssh 加密传输到本地的 ~ 目录下 scp \\ \\@\\:\\ - 通过 scp 命令传输本地文件到 hostip scp \\@\\:\\ \\ - 通过 scp 命令传下载 hostip 文件到本地 ssh-keygen - 默认在 ~/.ssh/ 下生成 RSA 公私密钥对 ssh-keygen -t dsa - 在 ~/.ssh/ 下生成 dsa 公私密钥对 ssh-copy-id \\@\\ - 默认将本地主机公钥 ~/.ssh/id_rsa.pub 添加到远程服务器 /.ssh/authorized_keys 文件中，实现无密码登录 ssh-copy-id -i \\/id_rsa.pub \\@\\ - 将本地主机公钥 公钥路径 中的 id_rsa.pub 添加到远程服务器 /.ssh/authorized_keys 文件中，实现无密码登录 /etc/ssh/ssh.config - 客户端配置文件 /etc/ssh/sshd.config - 服务的配置文件 开启密钥认证登录 # 开启密钥验证 RSAAuthentication yes PubkeyAuthentication yes RSAAuthentication yes # 制定公钥文件路径 AuthorsizedKeysFile $h/.ssh/authorized_keys 关闭密码登录 PasswordAuthentication no ~/.ssh/known_hosts - 查看已知主机的公钥 关闭 hostkeychecking，初次登录时不用输入 yes StrictHostKeyChecking no ~/.ssh/authorized_keys - 存放需要密钥登录本机的 host 公钥 SSH 密码或无密码( 密钥 )登录 SSH 登录通常有密码登录和密钥登录 ( 或无密码直接登录 ) 密码登录 云服务器创建配后置密码登录 无密码登录 生成本地 RSA 或 DSA 密钥对 $ ssh-keygen # 一路回车就可 # root 用户生成公私钥在：/root/.ssh/ # 非 root 用户：在自己主目录下的 .ssh/ 将本地公钥内容追加到远程服务器的 /root/.ssh/authorized_keys 或 用户目录下的 .ssh/authorized_keys # 也可以使用 ssh-copy-id $ ssh-copy-id root@目标节点IP # ssh-copy-id root@192.168.56.101 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/root/.ssh/id_rsa.pub\" /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys root@192.168.56.101's password: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh 'root@192.168.56.101'\" and check to make sure that only the key(s) you wanted were added. 重启 ssh, 退出再次登陆即可实现无密码登录 原理篇 [Top] 密码学加密算法 加密方法可以分为两大类，一类是单钥加密（ private key cryptography ），还有一类叫做双钥加密（ public key cryptography ）。前者的加密和解密过程都用同一套密码，后者的加密和解密过程用的是两套密码 【mì yuè】读音下的“密钥”的意思：紧密的锁闭。这里的用法用了“密钥”的动词性质。 【 mì yào】读音下的“密钥”的意思：密码学中的专有名词，指解密所需要的特殊代码。这里用了“密钥”的名词性 对称密钥加密 - Symmetric-key algorithm 又称为对称加密、私钥加密、共享密钥加密、单钥加密 这类算法在加密和解密时使用相同的密钥，或是使用两个可以简单地相互推算的密钥，所以这被称为 \"对称加密算法\" 1976 年以前，所有的加密算法都使用 \"对称加密算法\"，通用的单钥加密算法为 DES（ Data Encryption Standard ） 在对称密钥加密的情况下，密钥只有一把，所以密钥的保存变得很重要。一旦密钥泄漏，密码也就被破解 公开密钥加密 - Public-key cryptography 又称为非对称加密 - asymmetric cryptography 公开密钥加密需要两个密钥，一个是公开密钥（ 加密使用 ），另一个是私有密钥（ 解密使用 ） SSH 原理简述 ssh 密码登录原理 用户使用 ssh user@host 命令对远程主机发起登陆 远程主机将自己的公钥返回给请求主机 请求主机使用公钥对用户输入的密码进行加密 请求主机将加密后的密码发送给远程主机 远程主机使用私钥对密码进行解密 最后，远程主机判断解密后的密码是否与用户密码一致，一致就同意登陆，否则反之 ssh 密钥登录原理 用户使用 ssh user@host 命令对远程主机发起登陆 远程主机对用户返回一个随机串 用户所在主机使用私钥对这个随机串进行加密，并将加密的随机串返回至远程主机 远程主机使用分发过来的公钥对加密随机串进行解密 如果解密成功，就证明用户的登陆信息是正确的，则允许登陆；否则反之 SSH 中间人攻击 [Top] ​ 由于 SSH 不像 https 协议那样，SSH 协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。这就导致如果有人截获了登陆请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪，用户再通过伪造的公钥加密密码，再发送给冒充主机，此时冒充的主机就可以获取用户的登陆密码了，那么 SSH 的安全机制就荡然无存了，这也就是我们常说的中间人攻击 参考 数字签名是什么？- 阮一峰 SSH原理与运用 - 阮一峰 SSH原理与运用（一）：远程登录 - 阮一峰 SSH原理与运用（二）：远程操作与端口转发 - 阮一峰 详解SSH原理 - 果冻想 Linux ssh命令详解 - 小a玖拾柒 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/Tomcat和Ngnix和Apache.html":{"url":"Linux/Tomcat和Ngnix和Apache.html","title":"Tomcat和Ngnix和Apache","keywords":"","body":" Apache / Nginx 应该叫做「HTTP Server」；而 Tomcat 则是一个「Application Server」，或者更准确的来说，是一个「Servlet / JSP」应用的容器（Ruby / Python 等其他语言开发的应用也无法直接运行在 Tomcat 上）。 一个 HTTP Server 关心的是 HTTP 协议层面的传输和访问控制，所以在 Apache / Nginx 上你可以看到代理、负载均衡等功能。客户端通过 HTTP Server 访问服务器上存储的资源（HTML 文件、图片文件等等）。通过 CGI 技术，也可以将处理过的内容通过 HTTP Server 分发，但是一个 HTTP Server 始终只是把服务器上的文件如实的通过 HTTP 协议传输给客户端。而应用服务器，则是一个应用执行的容器。它首先需要支持开发语言的 Runtime（对于 Tomcat 来说，就是 Java），保证应用能够在应用服务器上正常运行。其次，需要支持应用相关的规范，例如类库、安全方面的特性。对于 Tomcat 来说，就是需要提供 JSP / Sevlet 运行需要的标准类库、Interface 等。为了方便，应用服务器往往也会集成 HTTP Server 的功能，但是不如专业的 HTTP Server 那么强大，所以应用服务器往往是运行在 HTTP Server 的背后，执行应用，将动态的内容转化为静态的内容之后，通过 HTTP Server 分发到客户端 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/trans命令.html":{"url":"Linux/trans命令.html","title":"trans命令","keywords":"","body":"trans 命令详解 常用命令 转换到特定语言，例如转换到中文和日文 $ trans :en+ja Hello Hello こんにちは (Kon'nichiwa) Hello的定义 [ English -> 日本語 ] 感叹词 もしもし！ Hello! 今日は! Hi!, Hello!, Good afternoon!, Good day! Hello こんにちは, もしもし 指定待转换的源语言的语言类型，例如确定“手紙”是中文或日文 $ trans ja: 手紙 手紙 (Tegami) 一封信 (Yī fēng xìn) 手紙 的翻译 [ 日本語 -> 简体中文 ] 手紙 一封信, 信 $ trans en: 手紙 手紙 手纸 (Shǒuzhǐ) 手紙 的翻译 [ English -> 简体中文 ] 手纸 手纸 转换一个句子，例如转换 “Hello world” 若不加引号，则是以单个词逐个翻译 $ trans en: 'Hello world' Hello world 你好，世界 (Nǐ hǎo, shìjiè) Hello world 的翻译 [ English -> 简体中文 ] Hello world 你好，世界, 你好世界 # 多行句子翻译 $ trans en: 'Hello world' 语言和相关的更多细节，参见wiki: Languages Language Code Language Code Language Code Afrikaans Afrikaans af Hebrew עִבְרִית he Portuguese Português pt Albanian Shqip sq Hill Mari Кырык мары mrj Punjabi ਪੰਜਾਬੀ pa Amharic አማርኛ am Hindi हिन्दी hi Querétaro Otomi Hñąñho otq Arabic العربية ar Hmong Hmoob hmn Romanian Română ro Armenian Հայերեն hy Hmong Daw Hmoob Daw mww Russian Русский ru Azerbaijani Azərbaycanca az Hungarian Magyar hu Samoan Gagana Sāmoa sm Bashkir башҡорт теле ba Icelandic Íslenska is Scots Gaelic Gàidhlig gd Basque Euskara eu Igbo Igbo ig Serbian (Cyrillic)) српски sr-Cyrl Belarusian беларуская be Indonesian Bahasa Indonesia id Serbian (Latin)) srpski sr-Latn Bengali বাংলা bn Irish Gaeilge ga Sesotho Sesotho st Bosnian Bosanski bs Italian Italiano it Shona chiShona sn Bulgarian български bg Japanese 日本語 ja Sindhi سنڌي sd Cantonese 粵語 yue Javanese Basa Jawa jv Sinhala සිංහල si Catalan Català ca Kannada ಕನ್ನಡ kn Slovak Slovenčina sk Cebuano Cebuano ceb Kazakh Қазақ тілі kk Slovenian Slovenščina sl Chichewa Nyanja ny Khmer ភាសាខ្មែរ km Somali Soomaali so Chinese Simplified 简体中文 zh-CN Klingon tlhIngan Hol tlh Spanish Español es Chinese Traditional 正體中文 zh-TW Klingon (pIqaD))   tlh-Qaak Sundanese Basa Sunda su Corsican Corsu co Korean 한국어 ko Swahili Kiswahili sw Croatian Hrvatski hr Kurdish Kurdî ku Swedish Svenska sv Czech Čeština cs Kyrgyz Кыргызча ky Tahitian Reo Tahiti ty Danish Dansk da Lao ລາວ lo Tajik Тоҷикӣ tg Dutch Nederlands nl Latin Latina la Tamil தமிழ் ta Eastern Mari Олык марий mhr Latvian Latviešu lv Tatar татарча tt Emoji Emoji emj Lithuanian Lietuvių lt Telugu తెలుగు te English English en Luxembourgish Lëtzebuergesch lb Thai ไทย th Esperanto Esperanto eo Macedonian Македонски mk Tongan Lea faka-Tonga to Estonian Eesti et Malagasy Malagasy mg Turkish Türkçe tr Fijian Vosa Vakaviti fj Malay Bahasa Melayu ms Udmurt удмурт udm Filipino Tagalog tl Malayalam മലയാളം ml Ukrainian Українська uk Finnish Suomi fi Maltese Malti mt Urdu اُردُو ur French Français fr Maori Māori mi Uzbek Oʻzbek tili uz Frisian Frysk fy Marathi मराठी mr Vietnamese Tiếng Việt vi Galician Galego gl Mongolian Монгол mn Welsh Cymraeg cy Georgian ქართული ka Myanmar မြန်မာစာ my Xhosa isiXhosa xh German Deutsch de Nepali नेपाली ne Yiddish ייִדיש yi Greek Ελληνικά el Norwegian Norsk no Yoruba Yorùbá yo Gujarati ગુજરાતી gu Papiamento Papiamentu pap Yucatec Maya Màaya T'àan yua Haitian Creole Kreyòl Ayisyen ht Pashto پښتو ps Zulu isiZulu zu Hausa Hausa ha Persian فارسی fa Hawaiian ʻŌlelo Hawaiʻi haw Polish Polski pl Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/UbuntuSoftwareInstall.html":{"url":"Linux/UbuntuSoftwareInstall.html","title":"UbuntuSoftwareInstall","keywords":"","body":"Ubuntu 软件包安装 deb 是 Debian、Ubuntu 软件安装的一种格式 rpm 是 Redhat、Fedora、SUSE 软件安装的一种格式 源码包（ Tarball 软件) 安装编译工具：$ sudo apt-get install build-essential 在 ubuntu 上编译程序，默认是有 gcc 的，但是没有 g++。如果自己来安装 g++ 也可以，不过它涉及到一些依赖库，有点麻烦，但 build-essential 包里有很多开发必备的软件包：dpkg-dev fakeroot g++ g++-4.6 libalgorithm-diff-perl libalgorithm-diff-xs-perl libalgorithm-merge-perl libdpkg-perl libstdc++6-4.6-dev libtimedate-perl 推荐将源码包放在/usr/local/src目录下 进入/usr/local/src目录，解压源码包，进入源码目录 编译、安装软件 一般情况下，里面有个 configure 文件，则运行命令:sudo ./configure --prefix=/usr/local/filename #存放路径，可更改 make #编译 sudo make install #安装 --prefix 选项是配置安装目录，如果不配置该选项，安装后可执行文件默认放在 /usr /local/bin，库文件默认放在/usr/local/lib，配置文件默认放在/usr/local/etc，其它的资源文件放在/usr /local/share，比较凌乱。如上安装后的所有资源文件都在/usr/local/filename文件夹里 如果只有Makefile文件，则运行命令：make #编译 sudo make install #安装 如果只是Imake文件，则运行命令：xmkmf #配置 make #编译 sudo make install # 安装 卸载软件：$ dpkg -r filename.deb 清除编译过程中产生的临时文件：$ make clean 清除配置过程中产生的文件：$ make distclean (谨用) 卸载软件时，进入源码文件目录：$ make uninstall 关于卸载 如果没有配置 --prefix 选项，源码包也没有提供 make uninstall，则可以通过以下方式可以完整卸载： 找一个临时目录重新安装一遍，如：./configure --prefix=/tmp/to_remove && make install 然后遍历/tmp/to_remove的文件，删除对应安装位置的文件即可（ 因为/tmp/to_remove里的目录结构就是没有配置 --prefix 选项时的目录结构 ） deb包 方法一、 使用 dpkg 软件管理系统双击直接安装 方法二、 命令行安装 sudo apt-get install dpkg #先安装dpkg dpkg -i filename.deb #安装软件 dpkg -r filename.deb #卸载 rpm包 方法一、 先用 alien 命令把 rpm 包转换为 deb 软件包，再安装即可 sudo apt install alien #安装alien alien -d filename.rpm #使用alien将rpm包转换为deb包 sudo dpkg -i filename.deb #安装 sudo dpkg -r filename.deb #卸载 方法二、 使用 rpm 命令直接安装 sudo apt install rpm #安装 rpm ./alien -i filename.rpm 　bin 包 sudo chmod a+x filename.bin #更改执行权限 ./filename.bin #安装 sh 包或 bash 包 sudo chmod a+x filename.sh filename.bash # 更改权限 ./filename.sh (或 $ ./filename.bash) #安装软件 二进制包 不用安装，将软件放于某目录下。 直接运行软件：$ ./filename py 包 sudo apt-get install python # 安装 python sudo python3 setup.py install # 安装 python3 的库 python filename.py # 安装软件 pl 包 sudo apt-get install perl # 安装 perl perl filename.pl # 安装软件 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/bin.html":{"url":"Linux/bin.html","title":"bin","keywords":"","body":" /bin是系统的一些指令。bin为binary的简写主要放置一些系统的必备执行档例如:cat、cp、chmod df、dmesg、gzip、kill、ls、mkdir、more、mount、rm、su、tar等。 /sbin一般是指超级用户指令。主要放置一些系统管理的必备程式例如:cfdisk、dhcpcd、dump、e2fsck、fdisk、halt、ifconfig、ifup、 ifdown、init、insmod、lilo、lsmod、mke2fs、modprobe、quotacheck、reboot、rmmod、 runlevel、shutdown等。 /usr/bin　是你在后期安装的一些软件的运行脚本。主要放置一些应用软体工具的必备执行档例如c++、g++、gcc、chdrv、diff、dig、du、eject、elm、free、gnome*、 gzip、htpasswd、kfm、ktop、last、less、locale、m4、make、man、mcopy、ncftp、 newaliases、nslookup passwd、quota、smb*、wget等。 /usr/sbin 放置一些用户安装的系统管理的必备程式例如:dhcpd、httpd、imap、in.*d、inetd、lpd、named、netconfig、nmbd、samba、sendmail、squid、swap、tcpd、tcpdump等。 如果新装的系统，运行一些很正常的诸如：shutdown，fdisk的命令时，悍然提示：bash:command not found。那么 首先就要考虑root 的$PATH里是否已经包含了这些环境变量。 可以查看PATH，如果是：PATH=$PATH:$HOME/bin则需要添加成如下： PATH=$PATH:$HOME/bin:/sbin:/usr/bin:/usr/sbin Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/ffmpeg详解.html":{"url":"Linux/ffmpeg详解.html","title":"ffmpeg详解","keywords":"","body":"FFmpeg - [github] FFmpeg 是处理多媒体内容（ 如音频，视频，字幕和相关元数据 ）的库和工具的集合 库 libavcodec 提供更广泛的编解码器的实现。 libavformat 实现流协议，容器格式和基本 I / O 访问。 libavutil 包括垫圈，解压缩器和其他实用功能。 libavfilter 提供通过过滤器链改变解码的音频和视频的方法。 libavdevice 提供访问捕获和回放设备的抽象。 libswresample 实现音频混合和重采样例程。 libswscale 实现颜色转换和缩放例程 工具 ffmpeg ffplay ffprobe ffmpeg ffmpeg 是一个非常强大的工具，它可以转换任何格式的媒体文件，并且还可以用自己的 AudioFilter 以及 VideoFilter 进行处理和编辑。有了它，我们就可以对媒体文件做很多我们想做的事情了 预备知识 codec - 编码解码器 A codec is a device or computer program for encoding or decoding a digital data stream or signal. Codec is a portmanteau of coder-decoder. A codec encodes a data stream or a signal for transmission and storage, possibly in encrypted form, and the decoder function reverses the encoding for playback or editing. Codecs are used in videoconferencing, streaming media, and video editing applications. 使用 FFmpeg 视频分割 # 这个例子是将 test.mp4 视频的前 3 秒，重新生成一个新视频 ffmpeg -ss 00:00:00 -t 00:00:03 -y -i test.mp4 -vcodec copy -acodec copy test1.mp4 [参数] -ss 开始时间，如： 00:00:00，表示从 0 秒开始，也可以写成 00:00:0 -t 时长，如： 00:00:03，表示截取 3 秒长的视频，也可以写成 00:00:3 -y 如果文件已存在强制替换 -i 输入，后面是空格，紧跟着就是输入视频文件 -vcodec [copy] 视频的编码格式，copy 表示保持视频编码格式不变 -acodec [copy] 音频的编码格式，copy 表示保持音频编码格式不变 使用 FFmpeg 从视频中制作 GIF 图 使用 FFmpeg 转换 flv 到 mp4 ffmpeg -i input.flv -vcodec copy -acodec copy output.mp4 使用 FFmpeg 给视频添加水印 # 给视频添加图片水印，水印居中显示 ffmpeg -i input.mp4 -i watermark.png -filter_complex overlay=\"(main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2\" output.mp4 # 给视频添加 GIF 动态图水印，水印居中显示 ffmpeg -i input.mp4 -i watermark.gif -filter_complex overlay=\"(main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2\" output.mp4 # 给视频添加文字水印，水印左上角显示 ffmpeg -i input.mp4 -vf \"drawtext=/usr/share/fonts/truetype/source-code-pro/SourceCodePro-BlackIt.ttf:text='视频添加文字水印':x=10:y=10:fontsize=24:fontcolor=yellow:shadowy=2\" output.mp4 [参数] overlay=\"(main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2\" 设置水印的位置，居中显示 参数 overlay 详解 overlay 设置位置格式：`overlay=\"x:y[:1]\" x:y 以左上的视频界面顶点为原点，向右为 x 轴正方向，向下为 y 轴正方向的直角坐标系中一点的横纵坐标 :1 表示支持透明水印 overlay 可选参数 | 说明 ------ | ------ main_w | 视频单帧图像宽度 main_h | 视频单帧图像高度 overlay_w | 水印图片的宽度 overlay_h | 水印图片的高度 (main_w/2)-(overlay_w/2):(main_h/2)-(overlay_h)/2 | 相对位置（居中显示） 10:10 | 绝对位置（距离上边和左边都是 10 像素）main_w-overlay_w-10:10 | 绝对位置（距离上边和右边都是 10 像素） 水印图片的尺寸不能大于视频单帧图像尺寸，否则会出错 使用 FFmpeg 提取视频中的音频文件( aac、mp3 等 ) # 一、提取的音频格式是 mp3 的情况 # 先查看自己的 ffmpeg 的库依赖有没有编码 mp3 的库（通常是 libmp3lame，而且一般安装 ffmpeg 时只有解码 mp3 的库） ffmpeg -codecs | grep mp # 提取视频中音，音频格式为 mp3 ffmpeg -i input.mp4 -f mp3 -vn output.mp3 # 或 ffmpeg -i input.mp4 -acodec libmp3lame -vn output.mp3 [参数] -vn 禁止视频输出 -f 输出编码格式 -acodec 音频编码器 # 二、提取的音频格式是 acc 的情况 # 一般 acc 编码器默认已经装上 ffmpeg -i input.mp4 -c copy output.acc 使用 FFmpeg 合并多个视频或多个音频 一、合并多个音频 ffmpeg -i input1.mp3 -i input2.mp4 output.mp3 二、合并多个视频 更多方法 FFmpeg concat 分离器（需要 FFmpeg 1.1 以上版本，最通用方法） 先创建一个文本文件(.txt)# 例如文件 inputfilelist.txt 内容 file 'input1.mp4' file 'input2.mp4' file 'input3.mp4' 文件新建在当前目录下，文件存放待合并的视频文件名，注意格式：file 'xxx' 然后执行命令ffmpeg -f concat -i inputfilelist.txt -c copy output.mp4 使用 FFmpeg 将字幕文件集成到视频文件 字幕文件格式间转换 # 将 .srt 文件转换为 .ass 文件 ffmpeg -i subtitle.srt subtitle.ass # 将 .ass 文件转换为 .srt 文件 ffmpeg -i subtitle.ass subtitle.srt 由于 mp4 容器，不像 mkv 等容器有自己的字幕流 mkv 这种容器的视频格式中，会带有一个字幕流，可以在播放中，控制字幕的显示与切换，也可以通过工具或命令，将字幕从视频中分离出来 mp4 格式的容器，是不带字幕流的，所以如果要将字幕添加进去，就需要将字幕文件烧进视频中去。烧进去的视频，不能再分离出来，也不能控制字幕的显示与否 # 比如将 input.srt 烧入 input.mp4 中，将合并的视频拷到 output.mp4 # input.srt、input.mp4、output.mp4都是相对当前目录下 ffmpeg -i input.mp4 -vf subtitles=input.srt output.srt [参数] -y :覆盖同名的输出文件 -i ：资源文件 -vf：一般用于设置视频的过滤器 ( set video filters ) subtitles= ：后面跟字幕文件，可以是 srt，ass ffplay ffplay 是以 FFmpeg 框架为基础，外加渲染音视频的库 libSDL 构建的媒体文件播放器 格式 - ffplay [选项] ['输入文件'] 主要选项 '-x width' 强制以 \"width\" 宽度显示 '-y height' 强制以 \"height\" 高度显示 '-an' 禁止音频 '-vn' 禁止视频 '-ss pos' 跳转到指定的位置(秒) '-t duration' 播放 \"duration\" 秒音/视频 '-bytes' 按字节跳转 '-nodisp' 禁止图像显示(只输出音频) '-f fmt' 强制使用 \"fmt\" 格式 '-window_title title' 设置窗口标题(默认为输入文件名) '-loop number' 循环播放 \"number\" 次(0将一直循环) '-showmode mode' 设置显示模式 可选的 mode '0, video' 显示视频 '1, waves' 显示音频波形 '2, rdft' 显示音频频带 默认值为 'video'，你可以在播放进行时，按 \"w\" 键在这几种模式间切换 '-i input_file' 指定输入文件 一些高级选项 '-sync type' 设置主时钟为音频、视频、或者外部。默认为音频。主时钟用来进行音视频同步 '-threads count' 设置线程个数 '-autoexit' 播放完成后自动退出 '-exitonkeydown' 任意键按下时退出 '-exitonmousedown' 任意鼠标按键按下时退出 '-acodec codec_name' 强制指定音频解码器为 \"codec_name\" '-vcodec codec_name' 强制指定视频解码器为 \"codec_name\" '-scodec codec_name' 强制指定字幕解码器为 \"codec_name\" 一些快捷键 'q, ESC' 退出 'f' 全屏 'p, SPC' 暂停 'w' 切换显示模式(视频/音频波形/音频频带) 's' 步进到下一帧 'left/right' 快退/快进 10 秒 'down/up' 快退/快进 1 分钟 'page down/page up' 跳转到前一章/下一章(如果没有章节，快退/快进 10 分钟) 'mouse click' 跳转到鼠标点击的位置(根据鼠标在显示窗口点击的位置计算百分比) ffprobe ffprobe 是 ffmpeg 命令行工具中是用来查看媒体文件格式的工具 xcq@xcq-HP-Pavilion-Notebook:~/桌面$ ffprobe test.mp4 ffprobe version 3.4.4-0ubuntu0.18.04.1 Copyright (c) 2007-2018 the FFmpeg developers built with gcc 7 (Ubuntu 7.3.0-16ubuntu3) configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared libavutil 55. 78.100 / 55. 78.100 libavcodec 57.107.100 / 57.107.100 libavformat 57. 83.100 / 57. 83.100 libavdevice 57. 10.100 / 57. 10.100 libavfilter 6.107.100 / 6.107.100 libavresample 3. 7. 0 / 3. 7. 0 libswscale 4. 8.100 / 4. 8.100 libswresample 2. 9.100 / 2. 9.100 libpostproc 54. 7.100 / 54. 7.100 Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test.mp4': Metadata: major_brand : isom minor_version : 1 compatible_brands: isomavc1 creation_time : 2018-07-16T15:13:16.000000Z Duration: 00:08:46.07, start: 0.000000, bitrate: 2577 kb/s # 该视频文件的时长是 8 分 46 秒 7 毫秒，开始播放时间是 0，整个文件的比特率是 2577 Kbit/s Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 2446 kb/s, 23.98 fps, 23.98 tbr, 24k tbn, 47.95 tbc (default) # 第一个流是视频流，编码格式是 h264 格式( 封装格式为 AVC1 )，每一帧的数据表示为 yuv420p，分辨率为 1920 × 1080，这路流的比特率为2466 Kbit/s，帧率为每秒钟 24 帧 Metadata: creation_time : 2018-07-16T15:13:16.000000Z Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default) # 第二个流是音频流，编码方式为 ACC（ 封装格式为 MP4A ），并且采用的 Profile（ 配置文件 ）是 LC 规格，采样率是 44.1 KHz，声道是立体声，这路流的比特率 92 Kbit/s Metadata: creation_time : 2018-07-16T14:53:06.000000Z 颜色编码：其中YUV420是视频中通常采用的颜色编码方式，Y表示亮度，而U，V则与颜色相关，而420则分别对应着存储相应分量所占用的比特数之比。其实采用这种编码方式就是为了早期彩色电视与黑白电视能更好的相容 tbn is the time base in AVStream that has come from the container, I think. It is used for all AVStream time stamps. tbc is the time base in AVCodecContext for the codec used for a particular stream. It is used for all AVCodecContext and related time stamps. tbr is guessed from the video stream and is the value users want to see when they look for the video frame rate, except sometimes it is twice what one would expect because of field rate versus frame rate. fps 自然的是 frame per second，就是帧率了。 所以tbn和tbc应该都是在相应层上的时间单元，比如tbn=2997就相当于在视频流层把1s的时间分成了2997个时间单元，如此精细可以更好的与其他流比如音频流同步，对应着fps=29.97就表示每100个时间单元中有一帧。 时间同步方式： 问题来了：fps=29.97这是一个小数啊，我如果直接利用公式 frame number = time * fps 得到了也不是一个整数啊，而帧号应该是一个整数才对。 首先，29.97f/s这个变态的数是如何得到的？这起源于早期的NTSC电视制式，而现代的数字编码只是为了兼容而沿用了它的标准。其实在标准制定 时，NTSC采用的是30f/s的帧率，只是后来為了消除由彩色信号及伴音信号所產生的圖像干擾，每秒幀幅由30幀稍微下調至29.97幀，同時線頻由 15750Hz稍微下降至15734.26Hz 然后，带小数点的帧率如何实现呢，显然每一秒不可能显示相同个数的帧。实际上存在着叫做SMPTE Non-Drop-Frame和SMPTE Drop-Frame的时间同步标准，也就是说在某些时候，会通过丢掉一些帧的方式来将时间同步上。 比如刚才提到的29.97帧率，我们可以计算：29.97 f/sec = 1798.2 f/min = 107892 f/hour; 对于30f/s的帧率我们可以计算： 30 f/s = 1800 f/s = 108000 f/hour; 这样，如果利用每秒30帧的速度来采集视频，而用29.97f/s的速率来播放视频，每个小时就少播放了108帧，这样播放时间会比真实时间变慢。为了解决这个问题，SMPTE 30 Drop-Frame就采取了丢掉这108帧的方式，具体策略是每1分钟丢两帧，如果是第10分钟则不丢，所以每小时丢掉的帧数是：2×60 – 2×6 = 108 帧。更具体的信息， 25 tbr代表帧率；1200k tbn代表文件层（st）的时间精度，即1S=1200k，和duration相关；50 tbc代表视频层（st->codec）的时间精度，即1S=50，和strem->duration和时间戳相关。 25 tbr代表帧率； 90k tbn代表文件层（st）的时间精度，即1S=1200k，和duration相关； 50 tbc代表视频层（st->codec）的时间精度，即1S=50，和strem->duration和时间戳相关。 https://www.jianshu.com/p/bfec3e6d3ec8 https://www.jianshu.com/p/5b78a91f1091 显示帧信息 ffprobe -show_frames test.mp4 查看包信息 ffprobe -show_packets test.mp4 参考 20 篇 ffmpeg 学习 系统学习 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/YAML-配置文件语言.html":{"url":"Linux/YAML-配置文件语言.html","title":"YAML-配置文件语言","keywords":"","body":"YAML 配置文件语言 基本语法 大小写敏感 使用缩进表示层级关系 缩进时不允许使用 Tab 键，只允许使用空格 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略 字符串可以不用引号标注 数据结构 对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）：单个的、不可再分的值 例子 对象 - key: value person: student: xiaoming teacher: wang # 或 person: { student: xiaoming, teacher: wang } 数组 - - value（横杠和空格）开头 - - xiaoming - xiaohong - wang # 类似 python 中：[[xiaoming, xiaohong, wang]] 纯量 字符串、布尔值、整数、浮点数、Null、时间、日期 --- num: 12.23 iftrue: true # null 用 ~ 表示 isNull: ~ # 时间采用 ISO8601 格式 iso8601: 2001-12-14t21:59:43.10-05:00 # 使用两个感叹号，强制转换数据类型 e: !!str 123 f: !!str true 纯量 - 字符串 字符串默认不是有引号 字符串中包含空格或特殊字符，需要使用引号 只有单引号可以对特殊字符转义 字符串可以使用 | 保留换行符，也可以使用 > 折叠换行 引用 & 用来建立锚点（defaults）， 表示合并到当前数据，* 用来引用锚点 - &showell Steve - Clark - *showell # 等价于 python 中 # [ Steve, Clark, Steve ] &defaults defaults: adapter: postgres development: database: myapp_development Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/yum和rpm.html":{"url":"Linux/yum和rpm.html","title":"yum和rpm","keywords":"","body":"Yum 和 RPM RedHat 系列软件安装大致可以分为两种： rpm 文件安装 - 使用 rpm 指令 类似 [ubuntu] deb 文件安装，使用 dpkg指令 yum 安装 - 类似 [ubuntu] apt 安装 RPM rpm 包命名规范 包名-版本信息-发布版本号.运行平台 zabbix-agent-4.4.0-1.el7.x86_64.rpm zabbix-release-4.4-1.el7.noarch.rpm # noarch 代表的是软件可以平台兼容 常用命令 查看已安装软件信息 rpm -qa - 查看系统中已经安装的软件 rpm -qf [文件绝对路径] - 查看一个已经安装的文件属于哪个软件包 rpm -ql [软件名] - 查看已安装软件包的安装路径，[软件名] 是 rpm 包去除平台信息和后缀后的信息 rpm -qi [软件名] - 查看已安装软件包的信息 rpm -qc [软件名] - 查看已安装软件的配置文件 rpm -qd [软件名] - 查看已经安装软件的文档安装位置 rpm -qR [软件名] - 查看已安装软件所依赖的软件包及文件 查看未安装软件信息 rpm -qpi [rpm文件] - 查看软件包的用途、版本等信息 rpm -qpl [rpm文件] - 查看软件包所包含的文件 rpm -qpc [rpm文件] - 查看软件包的配置文件 rpm -qpR [rpm文件] - 查看软件包的依赖关系 软件包的安装、升级、删除等 - rpm -ivh [rpm文件] - 安装 rpm -Uvh [rpm文件] - 升级 rpm -e [软件名] - 删除 rpm -e [软件名] --nodeps - 不管依赖问题，强制删除软件 rpm --import [签名文件] - 导入签名 YUM yum 可以更方便的添加、删除、更新 RPM 包，并且能自动解决包的倚赖问题 rpm -ivh https://opsx.alibaba.com/mirror/detail/1859610790?lang=zh-CN - 安装 yum yum check-update - 检查可以更新的软件包 yum -y update - 升级所有包同时也升级软件和系统内核 yum -y upgrade - 只升级所有包，不升级软件和系统内核 yum update [软件名] - 更新特定的软件包 yum install [rpm文件] - 安装 rpm 包 yum remove [rpm文件] - 删除 rpm 包 yum clean all - 清除缓存中旧的 rpm 头文件和包文件 yum clean packages - 清楚缓存中 rpm 包文件 yum clean headers - 清楚缓存中 rpm 的头文件 yum clean old headers - 清除缓存中旧的头文件 yum list - 列出资源库中所有可以安装或更新的 rpm 包 yum list google* - 可以在 rpm 包名中使用通配符,查询类似的 rpm 包 yum list updates - 列出资源库中所有可以更新的 rpm 包 yum list installed - 列出已经安装的所有的 rpm 包 yum list extras - 列出已经安装的但是不包含在资源库中的 rpm 包 yum info - 列出资源库中所有可以安装或更新的 rpm 包的信息 yum info google* - 列出资源库中特定的可以安装或更新以及已经安装的 rpm 包的信息 yum info updates - 列出资源库中所有可以更新的 rpm 包的信息 yum info installed - 列出已经安装的所有的 rpm 包的信息 yum info extras - 列出已经安装的但是不包含在资源库中的 rpm 包的信息 yum search google - 搜索匹配特定字符的 rpm 包 yum provides google - 搜索包含特定文件的 rpm 包 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/从BashShell启动“窥探”Linux环境变量相关文件.html":{"url":"Linux/从BashShell启动“窥探”Linux环境变量相关文件.html","title":"从BashShell启动“窥探”Linux环境变量相关文件","keywords":"","body":"从 Bash Shell 启动“窥探” Linux 环境变量相关文件（ 代码以 Ubuntu 18.04 LTS 为例 ） 本篇涉及的 Linux 文件，除了设置环境变量，往往还有很多其他用途；本篇内容参考多篇相关网络文章，并结合自己理解，可定会有错误或不准确的地方，望指正！ Linux Shell 在有像平时启动 Windows 立马出现的图形化界面之前，与计算机的交互只能输入命令。在 UNIX 系统或 Linux 系统中，用来解释和管理命令的程序称作 Shell Linux Shell 种类 名称 说明 Bash Shell 全称 Bourne Again Shell，现今大多数 Linux 发行版本都包含 C Shell ( csh ) BSD UNIX 用户中非常流行 Korn Shell ( ksh ) UNIX System V用户中非常流行 Tcsh Shell 一种改进的 C Shell Ash Shell 与 Bourne Shell 非常相似 Bash Shell 常用的环境配置文件 Linux Bash Shell 运行时，按照一定的顺序加载配置文件，初始化配置文件后，运行 Bash Shell Linux Bash 的配置文件大概分为两类：系统配置文件和用户配置文件 bash shell 系统配置文件/etc/profile、/etc/bash.bashrc、/etc/profile.d/*.sh bash shell 用户配置文件~/.bash_profile、~/.bash_login、~/.profile、~/.bashrc Bash 配置文件解读 文件 说明 /etc/profile 该文件为每个用户设置了用户环境信息。当首次登录时执行该文件，还可以在该文件里设置用户邮箱位置、历史文件大小、PATH 路径之类的环境变量。并且该文件还会从 /etc/profile.d/ 目录的配置文件中收集相关的 Shell 设置 /etc/bashrc 对于运行 Bash Shell 的用户来说，每次打开一个 Bash Shell 时都会执行该文件。可以在该文件里使用命令 alias 添加别名等。此外，每个用户可以用 ~/.bashrc 文件中信息重写 /etc/bashrc 中的已存在值 ~/.bash_profile 该文件内设置的信息只对当前用户有效。只有当用户登录时才会执行该文件，在默认情况下，它设置一些环境变量并执行 ~/.bashrc 文件。添加环境变量通常是在这个文件里 ~/.bashrc 该文件包含了特定于 Bash Shell 信息。当进行登录以及每次打开一个新的 Bash Shell 时都会读取该文件。此外，alias 添加别名通常是在该文件里 ~/.bash_logout 每次注销（ 即退出最后一个 Bash Shell ）执行该文件，并且默认清除屏幕 除了读取上述配置文件之外，在登陆 shell 中还会读取其他相关配置信息，如读取 ~/.bash_history、/etc/man.config、~/.bash_logout 等等 Bash Shell 环境配置文件加载顺序详解 登录 shell（ login shell ）配置文件载入顺序 取得 bash 时需要完整的登陆流程的，就称为 login shell 比如通过 ssh 方式连接，或者由 tty1 ~ tty6 登陆，需要输入用户的账号与密码，此时取得的 bash 就称为 login shell login shell 载入读取环境配置文件过程图 ~/.bash_profile、~/.bash_login、~/.profile、~/.bashrc文件若没有，可自行创建 前两列只有 login shell 情况下才会加载（ /etc/profile及　~/bash_profile 列 ） 非登录 shell（ non-login shell ）配置文件载入顺序 取得 bash 接口的方法不需要重复登陆的举动 比如你以 X window 登陆 Linux 后， 再以 X 的图形化接口启动终端机，此时该终端接口无需输入账号与密码，则为 non-login shell 比如你在原本的 bash 环境下再次下达 bash 这个命令，同样的也没有输入账号密码，那第二个 bash (子程序) 也是 non-login shell non login shell 载入读取环境配置文件过程图 CentOs Bash Shell 环境配置文件加载顺序情况 《鸟哥的 linux 私房菜》里的 CentOs Bash Shell 配置文件加载顺序 source 命令 对于 shell 环境变量修改之后需要立即生效的情形，可以使用 source 来立即生效（ 也可以用命令 \".\" ） source 接带路径的配置文件名 source filename # source /etc/profile . 接带路径的配置文件名 . filename（中间有空格） # . /etc/profile source filename 与 sh filename 、./filename的区别： source - 在当前 shell 内去读取、执行a.sh，而a.sh不需要有 \"执行权限\"，所有新建、改变变量的语句都会保存在当前 shell 里面 sh - 打开一个 subshell 去读取、执行 filename ，而 filename 不需要有 \"执行权限\" . - 打开一个 subshell 去读取、执行 filename ，但 filename 需要有 \"执行权限\" 在子 shell 中执行脚本里面的语句，该子 shell 继承父 shell 的环境变量，但子在 shell 中改变的变量不会被带回父 shell（除非使用 export） Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/防火墙学习.html":{"url":"Linux/防火墙学习.html","title":"防火墙学习","keywords":"","body":" 之前很少会需要修改防火墙，也一直懒得系统学习一下，尤其在 VPS 配置安全组时，只能照着教程改，但并不明白啥意思，总归还是太菜和太懒！最近接触 zabbix ，看来不得不学习一下了 防火墙学习笔记 背景补充 SELinux、Netfilter、iptables、firewall 和 ufw五者关系 SELinux ( Security-Enhanced Linux，安全增强式 Linux ) 是一个 Linux 内核的安全模块，其提供了访问控制安全策略机制 netfilter 是 Linux 内核中的一个软件框架，用于管理网络数据包。不仅具有网络地址转换（ NAT ）的功能，也具备数据包内容修改、以及数据包过滤等防火墙功能。利用运作于用户空间的应用软件，如 iptables、ebtables 和 arptables 等，来控制 netfilter，系统管理者可以管理通过 Linux 操作系统的各种网络数据包 iptables 是一个命令行工具，用来配置 netfilter 防火墙 firewall 是 centos7+、RHEL7+、Fedora 里面新的防火墙管理命令 ufw 是 Ubuntu 下的一个简易的防火墙配置工具 SELinux 是美国国家安全局 (NSA ) 对于强制访问控制的实现，是 Linux 历史上最杰出的新安全子系统，它不是用来防火墙设置的，但它对 Linux 系统的安全很有用。Linux 内核 ( Kernel ) 从 2.6 就有了SELinux ufw、firewall 其实都是对 iptables 的封装，底层执行的都是 iptables 命令；iptables 调用内核模块 netfilter 实施真正的操作 /etc/services文件详解 /etc/services 文件包含网络服务和它们映射端口的列表；inetd 或 xinetd ( Internet 守护程序 ) 会查看这些细节，以便在数据包到达各自的端口或服务有需求时，它会调用特定的程序 文件格式：service-name port/protocol [aliases..] [#comment] service-name 是网络服务的名称。例如 telnet、ftp 等 port/protocol 是网络服务使用的端口（一个数值 ）和服务通信使用的协议（ TCP/UDP ） alias 是服务的别名 comment 是你可以添加到服务的注释或说明，以 # 标记开头 最后两个字段是可选的，因此用 [ ] 表示 sudo vim /etc/services SELinux 很多教程安装配置的时候一上来就让我们关了 SELinux，知乎回答 SELinux 策略是白名单原则，所以你需要非常清楚你的各项操作都需要哪些访问权限，这个好像数量有点多了 不外乎不懂怎么用，关了一了百了，懂怎么用的不想折腾，还是关了一了百了 因为它在本来已经很安全的 Linux 上，凌驾于 root 权限之上，设置了很多额外的条条框框；如果你了解这些条条框框，那还好；但如果不了解，那 SELinux 可能并没有帮什么忙，却给你带来了很多不确定因素 常用命令 # 查看 SELinux 是否运行 getenforce # disabled：表示 selinux 关闭，没有启动；其他两种 ( enforcing、permissive ) 均表示 selinux 启动了，只是运行的模式不一样 # 关闭SELinux # 临时生效，重启机器后失效 # 命令临时生效： setenforce 0 # 1 启用 # 0 告警，不启用 # 永久生效 # 操作前先备份 cp /etc/selinux/config /etc/selinux/config.bak # 更改 setlinux 级别 sed -i 's/SELINUX=enforcing/\\SELINUX=disabled/' /etc/selinux/config # 或 vim /etc/selinux/config # 修改SELINUX=disabled # 使用配置生效 reboot # 或 setenforce 0 #使配置立即生效 netfilter netfilter 是 Linux 操作系统核心层内部的一个数据包处理模块 iptables 在 Linux 生态系统中，iptables 是使 用很广泛的防火墙工具之一，它基于内核的包过滤框架（packet filtering framework） netfilter iptables 是运行在用户态的一个程序，通过 netlink 和内核的 netfilter 框架打交道 iptables 是 Linux 下功能强大的应用层防火墙工具, 说到 iptables 必然提到Netfilter，iptables 是应用层的，其实质是一个定义规则的配置工具，而核心的数据包拦截和转发是 Netfiler 常用命令 # 安装 iptables yum install iptables-serices -y # 查看防火墙状态： service iptables status # 关闭防火墙（永久性,重启机器后也会保持生效) chkconfig iptables off # 开启防火墙 (永久性,重启机器后也会保持生效） chkconfig iptables on # 临时关闭防火墙（重启机器后失效) service iptables off # 临时开启防火墙（重启机器后失效) service iptables on iptables 深度详解 firewall firewall 的底层是使用 iptables 进行数据过滤，建立在 iptables 之上 firewall 是动态防火墙，使用了 D-BUS 方式，修改配置不会破坏已有的数据链接 firewalld firewalld - Dynamic Firewall Manager 常用命令 # 安装 firewall yum install firewalld firewall-config -y # 启动防火墙 systemctl start firewalld.service # 停止防火墙/关闭防火墙 systemctl stop firewalld.service # 重启防火墙 systemctl restart firewalld.service # 设置开机启用防火墙 systemctl enable firewalld.service # 设置开机不启动防火墙 systemctl disable firewalld.service 配置 修改 firewall 三种方法：firewall-config ( 图形化 )、firewall-cmd ( 命令行 )、配置文件内修改 firewalld 的配置文件是以 xml 的格式，存储在 /usr/lib/firewalld/（用户 和 /etc/firewalld/ 目录中 firewall-cmd firewall - cmd is the command line client of the firewalld daemon. It provides interface to manage runtime and permanent configuration. 常用命令 # 查看 firewall 状态 firewall-cmd --state # 列出开放的端口号 firewall-cmd --zone=public --list-ports # 新增开放端口号 firewall-cmd [--zone=] --add-port=[-]/ [--timeout=] [--permanent] # 例如： firewall-cmd --zone=public --add-port=80/tcp --permanent #说明: # --zone 网络区域定义了网络连接的可信等级 # 阻塞区域（block）：任何传入的网络数据包都将被阻止 # 工作区域（work）：相信网络上的其他计算机，不会损害你的计算机 # 家庭区域（home）：相信网络上的其他计算机，不会损害你的计算机 # 公共区域（public）：不相信网络上的任何计算机，只有选择接受传入的网络连接 # 隔离区域（DMZ）：也称为非军事区域，内外网络之间增加的一层网络，起到缓冲作用。对于隔离区域，只能选择接受传入的网络连接 # 信任区域（trusted）：所有的网络连接都可以接受 # 丢弃区域（drop）：任何传入的网络连接都被拒绝 # 内部区域（internal）：信任网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 # 外部区域（external）：不相信网络上的其他计算机，不会损害你的计算机。只有选择接受传入的网络连接 # --add-port=80/tcp 添加端口，格式为：端口或端口范围/协议(udp/tcp) # --permanent 永久生效，没有此参数重启后失效 # 查看 firewall-cmd --zone=public --query-port=80/tcp # 删除 firewall-cmd --zone=public --remove-port=80/tcp --permanent # 查看当前活动的区域,并附带一个目前分配给它们的接口列表 firewall-cmd --get-active-zones # 查看默认区域 firewall-cmd --get-default-zone # 查看所有可用区域 firewall-cmd --get-zones # 列出指定域的所有设置 firewall-cmd --zone=public --list-all # 列出所有预设服务 firewall-cmd --get-services # (这样将列出 /usr/lib/firewalld/services/ 中的服务器名称。注意:配置文件是以服务本身命名的service-name. xml) # 列出所有区域的设置 firewall-cmd --list-all-zones # 设置默认区域 firewall-cmd --set-default-zone=dmz # 设置网络地址到指定的区域 firewall-cmd --permanent --zone=internal --add-source=192.168.122.0/24 # (--permanent参数表示永久生效设置,如果没有指定--zone参数,那么会加入默认区域) # 删除指定区域中的网路地址 # firewall-cmd --permanent --zone=internal --remove-source=192.168.122.0/24 # 添加、改变、删除网络接口 firewall-cmd --permanent --zone=internal --add-interface=eth0 firewall-cmd --permanent --zone=internal --change-interface=eth0 firewall-cmd --permanent --zone=internal --remove-interface=eth0 # 添加、删除服务 firewall-cmd --permanent --zone=public --add-service=smtp firewall-cmd --permanent --zone=public --remove-service=smtp # 列出、添加、删除端口 firewall-cmd --zone=public --list-ports firewall-cmd --permanent --zone=public --add-port=8080/tcp firewall-cmd --permanent --zone=public --remove-port=8080/tcp # 重新载入，每次执行完 firewall-cmd 都应该 reload 一次 # 注意: 这并不会中断已经建立的连接,如果打算中断,可以使用 --complete-reload 选项 firewall-cmd --reload zone 信任等级详解 ufw - uncomplicated firewall - 简易防火墙 ufw 是一个 Arch Linux、Debian 或 Ubuntu 中管理防火墙规则的前端；ufw 默认包含在 Ubuntu 中，但在 Arch 和 Debian 中需要自行安装 ufw 是基于 iptables 实现的防火墙管理工具，所以实际上 ufw 修改的是 iptables 的规则 配置 /etc/ufw - 一些 ufw 的环境设定文件 /etc/sysctl.conf - 若开启ufw之 后，/etc/ufw/sysctl.conf会覆盖默认的/etc/sysctl.conf文件，若你原来的/etc/sysctl.conf做了修改，启动ufw后，若/etc/ufw/sysctl.conf中有新赋值，则会覆盖/etc/sysctl.conf的，否则还以/etc /sysctl.conf为准 /etc/default/ufw - 当然你可以通过修改/etc/default/ufw中的IPT_SYSCTL=条目来设置使用哪个 sysctrl.conf 备份/还原规则 ufw 的所有规则文件都在路径/etc/ufw/，其中before.rules规则为 ufw 在运行用户自定义的规则之前运行的规则，相应的before6.rules对应 IPV6；after.rules为 ufw 启用用户自定义规则之后运行的规则；user.rules即为用户自定义的规则 所以可以通过直接备份这些配置文件的方式来备份防火墙规则，需要备份的文件有： /etc/ufw/*.rules /lib/ufw/*.rules /etc/default/ufw 这个配置文件如果没有修改过，可以不备份 修改配置文件之后需要重新加载配置文件：sudo ufw reload 常用命令 # 安装 ufw sudo apt-get install ufw # 查看防火墙状态 sudo ufw status # 启动、关闭、查看状态、开机启动、开机不启动防火墙 systemctl start|stop|status|enable|disable ufw # 开机启动、开机不启动防火墙 ( 默认设置是 disable ) sudo ufw enable|disable # 设置默认策略，即为拒绝所有传入连接，允许所有传出链接 sudo ufw default deny incoming sudo ufw default allow outgoing # 允许/拒绝访问 20 端口，20 后可跟 /tcp 或 /udp，表示 tcp 或 udp 封包 sudo ufw allow/deny 20[/tcp|/udp] # 删除上面定义的“允许/拒绝访问 20 端口”的规则 sudo ufw delete allow/deny 20[/tcp|/udp] # ufw 的 allow 不加 in/out 允许连接默认是指允许入站连接，如果要指定允许出站，可以加上 out，如： sudo ufw allow in port #允许 port 入站 sudo ufw allow out port #允许 port 出站 # 允许/拒绝访问某个 service 的端口 ( 在 /etc/services 文件中查看 service )，删除同前面加 delete # ufw 通过 /etc/services 文件得到 service 默认端口号 sudo ufw allow/deny [service] # 例如 sudo ufw allow http sudo ufw allow 80/tcp # 设置外来访问默认允许/拒绝 sudo ufw default allow/deny # 允许/拒绝特定端口范围连接 sudo ufw allow/deny 1000:2000[/tcp|/udp] # 允许/拒绝特定 IP，删除同前面加 delete sudo ufw allow/deny from 192.168.254.254 # 允许/拒绝特定 IP 特定端口的连接，删除同前面加 delete sudo ufw allow/deny from 111.111.111.111 to any port 22 # 允许/拒绝自10.0.1.0/10 的 tcp 封包访问本机的 25 端口，删除同前面加 delete sudo ufw allow/deny proto tcp from 10.0.1.0/10 to 127.0.0.1 port 25 # 查看所有规则的规则号 sudo ufw status numbered # 删除规则编号或删除指定实际规则 delete num/rule # 重置防火墙 # 该命令将禁用 ufw，删除所有已经定义的规则，所有规则将被重设为安装时的默认值，不过默认该命令会对已经设置的规则进行备份 sudo ufw reset # 批量禁止 IP，file.txt 里面是一个需要禁止的 IP 列表 while read line; do sudo ufw deny from $line; done Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/通过Linux开机启动项展开学习.html":{"url":"Linux/通过Linux开机启动项展开学习.html","title":"通过Linux开机启动项展开学习","keywords":"","body":"通过 Linux 开机启动项学习 目录 相关文章 一、简述 Linux 开机启动流程 二、开机启动相关文件 三、Linux 管理守护进程两种方式 四、设置开机启动方法 【相关文章】[Top] - 阮一峰 Linux 的启动流程 - 阮一峰 Linux 守护进程的启动方法 - 阮一峰 Systemd 入门教程：命令篇 - 阮一峰 Systemd 入门教程：实战篇 - 阮一峰 一、简述 Linux 开机启动流程 [Top] 这个过程不涉及操作系统，只与主板的板载程序有关 Linux 操作系统的启动流程 第一步、加载内核 内核在 /boot/ 目录下 第二步、启动初始化进程 内核文件加载以后，就开始运行第一个程序 /sbin/init，它的作用是初始化系统环境 由于 init 是第一个运行的程序，它的进程编号（ pid ）就是 1。其他所有进程都从它衍生，都是它的子进程 第三步、确定运行级别 许多程序需要开机启动。它们在 Windows 叫做 \"服务\"（ service ），在 Linux 就叫做\"守护进程\"（ daemon ） init 进程的一大任务，就是去运行这些开机启动的程序 Linux 允许为不同的场合，分配不同的开机启动程序，这就叫做 \"运行级别\"（ runlevel ）。也就是说，启动时根据 \"运行级别\"，确定要运行哪些程序 第四步、加载开机启动程序 七种预设的 \"运行级别\" 各自有一个目录，存放需要开机启动的程序。不难想到，如果多个 \"运行级别\" 需要启动同一个程序，那么这个程序的启动脚本，就会在每一个目录里都有一个拷贝。这样会造成管理上的困扰：如果要修改启动脚本，岂不是每个目录都要改一遍 Linux 的解决办法，就是七个 /etc/rcN.d 目录里列出的程序，都设为链接文件，指向另外一个目录 /etc/init.d，真正的启动脚本都统一放在这个目录中。init 进程逐一加载开机启动程序，其实就是运行这个目录里的启动脚本 第五步、用户登录 开机启动程序加载完毕以后，就要让用户登录了 一般来说，用户的登录方式有三种： （1）命令行登录 （2）ssh 登录 （3）图形界面登录 第六步、进入 login shell 用户登录时打开的 shell，就叫做 login shell 第七步，打开 non-login shell 用户进入操作系统以后，常常会再手动开启一个 shell。这个 shell 就叫做 non-login shell，意思是它不同于登录时出现的那个shell，不读取/etc/profile和.profile等配置文件 二、开机启动相关文件 [Top] /etc/rc[0-6].d目录 ls /etc/ | grep '^rc.*' rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d rc.local rcS.d 0 - 6 是 Linux 操作系统的运行级别，运行命令 runlevel 查看当前运行级 运行级别 说明 0 系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 1 单用户，无网络连接，不运行守护进程，不允许非超级用户登录，用于系统维护，禁止远程登陆 2 多用户，无网络连接，不运行守护进程 3 多用户，正常启动系统，登陆后进入控制台命令行模式 4 用户自定义 5 多用户，带图形界面，X11 控制台 6 系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 ls /etc/rc0.d/ K01alsa-utils K01dnsmasq K01irqbalance K01openipmi K01resolvconf K01tlp K02gdm3 K01bluetooth K01docker K01lightdm K01plymouth K01speech-dispatcher K01unattended-upgrades K04rsyslog K01cgroupfs-mount K01gdomap K01mysql K01polipo K01spice-vdagent K01uuidd K05hwclock.sh K01cups-browsed K01ipmievd K01nginx K01postfix K01thermald K02avahi-daemon K06networking 目录下文件的命名规则：S|K + nn + script S | K - S 开头命名的是开机要执行的脚本，K 开头命名的是关机要执行的脚本 nn - 取值 0 - 100，表示优先级，数字越大，优先级越低 script - 软链接指向的脚本的文件名 ls -l /etc/rc0.d/ 总用量 0 lrwxrwxrwx 1 root root 20 Mar 10 2018 K01alsa-utils -> ../init.d/alsa-utils lrwxrwxrwx 1 root root 19 Mar 10 2018 K01bluetooth -> ../init.d/bluetooth lrwxrwxrwx 1 root root 24 Jan 2 2019 K01cgroupfs-mount -> ../init.d/cgroupfs-mount lrwxrwxrwx 1 root root 22 Mar 10 2018 K01cups-browsed -> ../init.d/cups-browsed lrwxrwxrwx 1 root root 17 Mar 29 2019 K01dnsmasq -> ../init.d/dnsmasq lrwxrwxrwx 1 root root 16 Jan 14 2019 K01docker -> ../init.d/docker lrwxrwxrwx 1 root root 16 Dec 6 2018 K01gdomap -> ../init.d/gdomap lrwxrwxrwx 1 root root 17 Oct 13 14:44 K01ipmievd -> ../init.d/ipmievd lrwxrwxrwx 1 root root 20 Mar 10 2018 K01irqbalance -> ../init.d/irqbalance lrwxrwxrwx 1 root root 17 Mar 10 2018 K01lightdm -> ../init.d/lightdm lrwxrwxrwx 1 root root 15 Jun 9 18:52 K01mysql -> ../init.d/mysql lrwxrwxrwx 1 root root 15 Oct 6 15:12 K01nginx -> ../init.d/nginx lrwxrwxrwx 1 root root 18 Oct 13 14:44 K01openipmi -> ../init.d/openipmi lrwxrwxrwx 1 root root 18 Mar 10 2018 K01plymouth -> ../init.d/plymouth lrwxrwxrwx 1 root root 16 Oct 4 12:56 K01polipo -> ../init.d/polipo . . . 可见 /etc/rcX.d/ 目录下的文件都是软链接到 /etc/init.d 下的守护进程 ( daemon ) 启动文件 三、Linux 管理守护进程两种方式 [Top] 守护进程 守护进程 ( daemon ) 就是一直在后台运行的进程 许多程序需要开机启动，它们在 Windows 叫做 \"服务\"（service），在Linux就叫做 \"守护进程\"（daemon） 命名规则 通常在服务的名字后面加上 d，即表示守护进程，比如 sshd、teamviewerd、etc 守护进程两种管理方式 service service sshd start ---> /etc/init.d/sshd ---> /usr/sbin/sshd 参数1 参数2 ... ---> 成功启动 ssh 相关文件 - /etc/init.d、/usr/sbin/service、etc which service - /usr/sbin/service file service - POSIX shell script file /etc/init.d/ssh - POSIX shell script - /etc/init.d 目录下全是守护进程的执行脚本 cat /usr/sbin/service - A convenient wrapper for the /etc/init.d init scripts 所以，service 其实就是一个在 /etc/init.d 目录下查找 $1 并执行的脚本 所以，service mysql start 其实就是 /etc/init.d/mysql start /etc/init.d 目录存在是为了封装直接使用命令操控守护进程传入各种参数等操作过程，通过查看该目录下脚本，简化言之就是通过调用 /usr/bin、/usr/sbin/等目录下守护进程对应可执行文件并传以各种参数，达到只需要 /etc/init.d/xxx start|stop|reload|.... 就可以操控守护进程的目的 systemctl 相关文件 - /etc/systemd/system、/lib/systemd/system(ubuntu)、/usr/lib/systemd/system(RedHat)、etc 可使用 man systemd.unit 查看各个文件解释 systemctl 是 Linux 系统最新初始化系统的守护进程 systemd 对应的进程管理命令 对于那些支持 systemd 的软件，安装的时候，会自动在 /usr/lib/systemd/system 目录添加一个配置文件 systemctl 兼容 service 四、设置开机启动方法 [Top] 1. 编辑/etc/rc.local文件 没有的话自己创建 #!/bin/sh # # This script will be executed *after* all the other init scripts. # You can put your own initialization stuff in here if you don't # want to do the full Sys V style init stuff. touch /var/lock/subsys/local /etc/init.d/mysqld start #mysql开机启动 /etc/init.d/nginx start #nginx开机启动 /etc/init.d/php-fpm start #php-fpm开机启动 /etc/init.d/memcached start #memcache开机启动 #在文件末尾（exit 0之前）加上你开机需要启动的程序或执行的命令即可（执行的程序需要写绝对路径，添加到系统环境变量的除外），如： /usr/local/thttpd/sbin/thttpd -C /usr/local/thttpd/etc/thttpd.conf 2. 使用 chkconfig \\ systemctl 命令 早期的 Linux 版本是用 chkconfig 命令来设置 rc 的 link，设置开机启动项；用 service 命令调用服务的 start、stop、restart、status 等函数。在现在主流 Linux 版本已经将这两个命令合并成一个 systemctl 命令了，映射关系如下: 任务 旧指令 ( chkconfig、service ) 新指令 ( systemctl ) 设置服务开机自启 chkconfig --level 3 httpd on systemctl enable httpd.service 禁止服务开机自启 chkconfig --level 3 httpd off systemctl disable httpd.service 查看服务状态 service httpd status systemctl status httpd.service 显示所有开机启动服务 chkconfig --list systemctl list-units --type=service 显示当前已启动的开机启动服务       --- systemctl list-units | grep enable 显示当前已启动的开机启动文件       --- systemctl list-files | grep enable 显示启动失败的开机启动服务       --- systemctl --failed 启动服务 service httpd start systemctl start httpd.service 关闭服务 service httpd stop systemctl stop httpd.service 重启服务 service httpd restart systemctl restart httpd.service 3. 自己写一个shell脚本 将写好的脚本（ .sh 文件）放到目录 /etc/profile.d/ 下，系统启动后就会自动执行该目录下的所有 shell 脚本。 /etc/profile.d 文件夹中文件 4. 添加一个开机启动服务 将你的启动脚本复制到/etc/init.d目录下，并设置脚本权限, 假设脚本为 test $ mv test /etc/init.d/test $ sudo chmod 755 /etc/init.d/test /etc/init.d 目录下的控制脚本接受参数 start | stop | restart | status | force-reload 将该脚本放倒启动列表中去 $ cd .etc/init.d $ sudo update-rc.d test defaults 95 其中数字 95 是脚本启动的顺序号，按照自己的需要相应修改即可。在你有多个启动脚本，而它们之间又有先后启动的依赖关系时你就知道这个数字的具体作用了。 update-rc.d 命令 : 为/etc/init.d目录下的脚本建立或删除到/etc/rc[0-6].d的软链接 update-rc.d 命令要在 etc/init.d/ 目录下执行，可能还需要 root 权限 增加一个服务 添加这个服务并让它开机自动执行 : update-rc.d apache2 defaults 并且可以指定该服务的启动顺序 : update-rc.d apache2 defaults 90 还可以更详细的控制start与kill顺序 : update-rc.d apache2 defaults 20 80 其中前面的 20 是 start 时的运行顺序级别，80 为 kill 时的级别。也可以写成 : update-rc.d apache2 start 20 2 3 4 5 . stop 80 0 1 6 .(其中 0 ～ 6 为运行级别) 删除一个服务 update-rc.d -f apache2 remove Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/新创建主机常用初始化配置.html":{"url":"Linux/新创建主机常用初始化配置.html","title":"新创建主机常用初始化配置","keywords":"","body":"新建主机常用初始化配置 修改 SELINUX # 查看 SELinux 是否运行 getenforce # disabled：表示 selinux 关闭，没有启动；其他两种 ( enforcing、permissive ) 均表示 selinux 启动了，只是运行的模式不一样 # 关闭SELinux # 临时生效，重启机器后失效 # 命令临时生效： setenforce 0 # 1 启用 # 0 告警，不启用 # 永久生效 # 操作前先备份 cp /etc/selinux/config /etc/selinux/config.bak # 更改 setlinux 级别 sed -i 's/SELINUX=enforcing/\\SELINUX=disabled/' /etc/selinux/config # 或 vim /etc/selinux/config # 修改SELINUX=disabled # 使用配置生效 reboot # 或 setenforce 0 #使配置立即生效 禁用防火墙 # 关闭 sudo systemctl stop firewalld # CentOS sudo systemctl stop ufw # Ubuntu # 禁用 sudo systemctl disable firewalld # CentOS sudo systemctl disable ufw # Ubuntu 查看是否能连接外网 ping www.baidu.com 更换国内软件源 # CentOS 7 阿里云软件源 $ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo $ sed -i -e '/mirrors.cloud.aliyuncs.com/d' -e '/mirrors.aliyuncs.com/d' /etc/yum.repos.d/CentOS-Base.repo $ yum clean all $ yum makecache # ubuntu 18.04(bionic) 阿里云软件源 用你熟悉的编辑器打开： /etc/apt/sources.list 替换默认的 http://archive.ubuntu.com/ 为 mirrors.aliyun.com Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/正则表达式学习.html":{"url":"Linux/正则表达式学习.html","title":"正则表达式学习","keywords":"","body":"正则表达式 常见正则表达式元字符 元字符 解释 命令 匹配结果 字符串 匹配字符串字面值 echo 'abc' | grep a abc . 匹配除 \\n 之外的任何字符 echo 'abc' | grep . abc ^ 匹配字符串起始部分 echo 'abc' | grep ^ab abc $ 匹配字符串终止部分 echo 'abc' | grep bc$ abc * 匹配 0 或 n 次前面出现的正则表达式 echo 'abc' | grep -E '[a-z]*' abc ? 匹配 0 或 1 次前面出现的正则表达式 echo 'abc' | grep -E 'a?' abc {N} 匹配 N 次连续前面出现的正则表达式 echo 'aabc' | grep -E a{2} aabc {M,N} 匹配 M~N 次连续前面出现的正则表达式 echo 'abaac' | grep -E 'a{1,2}' abaac [...] 匹配来自中括号内字符集的任意单一字符 echo 'abc' | grep -E '[ab]' abc [x-y ] 匹配 x~y 范围中的任意单一字符（包含两端边界值） echo '012abc' | grep -E '[0-9a-z]' 012abc ... 不匹配此字符集（包括某一范围的字符）中出现的任何一个字符 echo '012abc' | grep -E '0-1ab' 012abc (...) 匹配封闭的正则表达式，然后另存为子组 需要转义的特殊符号 \\\\ \\` \\* \\_ \\{\\} \\[\\] \\(\\) \\# \\+ \\- \\. \\! Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Linux/终端代理.html":{"url":"Linux/终端代理.html","title":"终端代理","keywords":"","body":"Ubuntu 桌面终端代理 折腾终端开启代理实在是一波三折，反反复复尝试了数次，之前没一次成功，但每次遇到需要安装国外源的软件时就痛不欲生！跨度一两年的一个问题终于解决了，记录一下 一、终端代理原理 终端代理究其原理和 chrome 扩展 Proxy SwitchyOmega 是一样的，都是为了将 socks 协议的数据转换成 http 协议, 因为终端很多下载安装命令 - wget、curl、git、brew、等等都是使用的 http协议 二、实现代理方法 I. 使用终端全局代理软件 v2ray + polipo + http_proxy + curl ip.gs v2ray 客户端和服务端安装配置很简单 - v2ray 官方安装教程 v2ray 客户端和服务端一定要在 /etc/v2ray/config.json 文件添加日志路径！！！ \"log\": { \"loglevel\": \"warning\", \"access\": \"/var/log/v2ray/access.log\", \"error\": \"/var/log/v2ray/error.log\" } 安装 polipo ## Ubuntu 下的安装 sudo apt-get install polipo ## CentOS 下的安装 sudo yum install polipo ## 编辑配置文件 /etc/polipo/config vim /etc/polipo/config # This file only needs to list configuration variables that deviate # from the default values. See /usr/share/doc/polipo/examples/config.sample # and \"polipo -v\" for variables you can tweak and further information. logSyslog = true logFile = /var/log/polipo/polipo.log proxyAddress = \"0.0.0.0\" socksParentProxy = \"127.0.0.1:1080\" socksProxyType = socks5 chunkHighMark = 50331648 objectHighMark = 16384 serverMaxSlots = 64 serverSlots = 16 serverSlots1 = 32 # This file only needs to list configuration variables that deviate # from the default values. See /usr/share/doc/polipo/examples/config.sample # and \"polipo -v\" for variables you can tweak and further information. logSyslog = true logFile = /var/log/polipo/polipo.log # socks 代理地址 socksParentProxy = \"127.0.0.1:1080\" # 类型 socksProxyType = socks5 # 转换为 HTTP 之后的端口 proxyPort = 8123 # 下面不清楚，但需要 chunkHighMark = 50331648 objectHighMark = 16384 serverMaxSlots = 64 serverSlots = 16 serverSlots1 = 32 确保服务器 v2ray、客户端 v2ray 和 polipo 服务都正常运行，且查看日志没有报错！ 在客户端本地 ~/.bashrc 文件中设置 export http_proxy=http://127.0.0.1:8123 export https_proxy=http://127.0.0.1:8123 别名 # 添加如下 alias hp=\"export http_proxy=http://127.0.0.1:8123\" alias hps=\"export https_proxy=http://127.0.0.1:8123\" 使用 curl ip.gs 查看是否成功实现代理，若不成功，检查如下 本地和服务器防火墙是否开启，都没开启则跳过这项；本地防火墙开启的话，检查 8123 和 1080 端口是否开启 tcp；服务器防火墙开启的话，检查 v2ray 配置的端口是否开启 tcp，以上端口没开启的话，都要开启 登录 VPS 控制台，检查安全组（称呼不一，阿里云叫防火墙）里的 v2ray 端口是否开启 tcp 可以在本地使用 paping -p port hostip 检查服务器和本地端口开启情况 一般修改安全组，需要重启服务器才有效 设置了安全组就可以不设置云服务器防火墙，因为安全组规则相对于云服务器防火墙是在更上一层的拦截！比如，安全组开启了 10001 端口的 tcp，如果开启防火墙的服务器没有开启 10001 端口的 tcp ，外面也是无法连接的。 重启服务，再次使用 curl ip.gs 检查是否代理成功，不成功，就 Google！ II. 修改需要代理的命令配置文件 太麻烦 Xiechengqi            最新修订时间： 2019-12-06 21:06:22 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/":{"url":"Shell/","title":"Shell","keywords":"","body":" Xiechengqi            最新修订时间： 2019-12-06 21:21:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/shell小知识.html":{"url":"Shell/shell小知识.html","title":"shell小知识","keywords":"","body":"Linux Shell 学习时的小知识 目录 exit 0 和 exit 1 特殊变量 让一个变量获得命令输出的结果 命令 > /dev/null 2 > &1和命令 &> /dev/null 数值比较 几种数值计算方法 数值进制间相互转换 等号两边不能有空格 [ $( )、` `、${ }、$(( ))、$[ ] 、[ ]、(( )) 和 [[ ]] 详解]（#---------和---详解-top) 用 cat、echo 命令向文件写入 杀死一个进程 删除空行 文件去重 截取文件开头几行、末尾几行和中间几行 修改文件以包含当前时间命名 查看当前主机公网 IP while 无限循环 进程查端口，端口查进程 查看其他主机开放的端口 快速查看配置文件中有效配置行 exit 0和exit 1 [Top] Linux exit 命令用于退出目前的 shell 执行 exit 可使 shell 以指定的状态值退出 若不设置状态值参数，则 shell 以预设值退出；状态值 0 代表执行成功，其他值代表执行失败 exit 也可用在 script，离开正在执行的 script，回到 shell 语法：exit [ 状态值 ] Ubuntu shell exit 特殊变量 [Top] $X 说明 $? 最近一次运行命令的结束代码（返回值 0 表示成功，非 0 表示失败） $$ 脚本运行的当前进程 ID 号（PID） $n(n=1,2...) 传递给该shell脚本的第 n 个参数 $0 执行脚本本身的名字 $# 传递给脚本参数的个数 $* 脚本的所有参数列表,代表\"$1 $2 … $n\"，即当成一个整体输出，每一个变量参数之间以空格隔开 $@ 脚本的所有参数列表,代表\"$1\" \"$2\" … \"$n\" ，即每一个变量参数是独立的 ,也是全部输出 $* 和 $@区别 #!/bin/bash # This script is to verify the difference between $* and $@ echo Dollar Star is $* echo \"Dollar Star in double quotes is $*\" echo Dollar At is $@ echo \"Dollar At in double quotes is $@\" echo echo \"Looping through Dollar Star\" for i in $* do echo \"parameter is $i\" done echo echo \"Looping through Dollar Star with double quotes\" for i in \"$*\" do echo \"Parameter is $i\" done echo echo \"Looping through Dollar At\" for i in $@ do echo \"Parameter is $i\" done echo echo \"Looping through Dollar At with double quotes\" for i in \"$@\" do echo \"Parameter is $i\" done $ bash test.sh 1 2 \" 3 4 \" 5 6 Dollar Star is 1 2 3 4 5 6 Dollar Star in double quotes is 1 2 3 4 5 6 Dollar At is 1 2 3 4 5 6 Dollar At in double quotes is 1 2 3 4 5 6 Looping through Dollar Star parameter is 1 parameter is 2 parameter is 3 parameter is 4 parameter is 5 parameter is 6 Looping through Dollar Star with double quotes Parameter is 1 2 3 4 5 6 Looping through Dollar At Parameter is 1 Parameter is 2 Parameter is 3 Parameter is 4 Parameter is 5 Parameter is 6 Looping through Dollar At with double quotes Parameter is 1 Parameter is 2 Parameter is 3 4 Parameter is 5 Parameter is 6 相同点如下： 1、直接输出不保留空格 2、带双引号输出会保留带引号的空格 3、不带双引号循环遍历的输出结果一样：每个字符串单独输出 不同点如下： 1、带双引号遍历$*相当于带双引号输出$* 2、带双引号遍历$@分别输出每个参数，带双引号的参数保留空格输出 $* 示例 让一个变量获得命令输出的结果 [Top] 1、$(命令)表示 #!/bin/bash i=$(ls 123.txt) echo $i 2、反引号表示 #!/bin/bash i=`ls 123.txt` echo $i 命令 > /dev/null 2 > &1和命令 &> /dev/null [Top] 解释：无提示（包括 stdin 和 stderr ）执行 文件描述符 文件描述符是与文件输入、输出关联的整数。它们用来跟踪已打开的文件 最常见的文件描述符是 stidin、stdout、和 stderr 0 —— stdin（标准输入） 1 —— stdout （标准输出） 2 —— stderr （标准错误） 我们可以将某个文件描述符的内容重定向到另外一个文件描述符中 stdout （标准输出） stderr （标准错误） /dev/null /dev/null是一个特殊的设备文件，这个文件接收到的任何数据都会被丢弃。因此，null 这个设备通常也被成为位桶（ bit bucket ）或黑洞 重定向操作给这个/dev/null文件的所有东西都会被丢弃 扩展使用 # 将 stderr 单独定向到一个文件，将stdout重定向到另一个文件 $ ls 123.txt 1> stdout.txt 2> stderr.txt # 将 stderr 转换成 stdout，使得 stderr 和 stdout 都被重新定向到同一个文件中 $ ls 123.txt 1> output.txt 2>&1 # 或 $ ls 123.txt > output.txt 2>&1 # 或 $ ls 123.txt &> output.txt # 或 $ ls 123.txt >& output.txt > 或 1>（标准输出）：把 STDOUT 重定向到文件,将默认或正确的传到另一个终端 2>（标准错误）：把 STDERR 重定向到文件，可将错误信息传到另一个终端，正确留下 2>&1：将错误转为正确输出，老式“洗钱”方法 1>&2：将正确转为错误输出 &>or>&：正确、错误都输出，新式方法 数值比较 [Top] arg1 OP arg2 ( OP ) 说明 -eq arg1 is equal arg2 -ne arg1 is not-equal arg2 -lt arg1 is less-than arg2 -le arg1 is less-than-or-equal arg2 -gt arg1 is greater-than arg2 -ge arg1 is greater-than-or-equal arg2 几种数值计算方法 [Top] $ ((i=5%2)) $ echo $i # 1 $ let i=5%2 $ echo $i # 1 $ expr 5 % 2 # expr 之后的 5，%，2 之间必须有空格分开。如果进行乘法运算，需要对运算符进行转义，否则 Shell 会把乘号解释为通配符，导致语法错误 $ i=$(echo 5%2 | bc) $ echo $i # 1 $ i=$(echo \"5 2\" | awk `{print $1+$2;}`) $ echo $i # 1 let，expr，bc 都可以用来求模，运算符都是 %，而 let 和 bc可以用来求幂，运算符不一样，前者是**，后者是 ^ (()) 的运算效率最高，而 let 作为 Shell 内置命令，效率也很高，但是 expr，bc，awk 的计算效率就比较低 let 和 expr 都无法进行浮点运算，但是 bc 和 awk 可以 ``` shell $ echo \"scale=3; 1/12\" | bc0.083 $ echo \"1 12\" | awk '{printf(\"%0.3f\\n\",$1/$2)}' 0.083 ``` 数值进制间相互转换 [Top] ``` shell 八进制 12 转换为十进制 方法一、 $ echo \"obase=8;ibase=10;12\" | bc 10 obase - 进制源 ibase - 进制转换目标 bc 命令是任意精度计算器语言，通常在 linux 下当计算器用 方法二、 $ echo $((8#12) 10 ## 等号两边不能有空格 [[Top]](#目录) = 含有空格导致无法运行 正确 ## $( )、\\` \\`、${ }、$(( ))、$[ ] 、[ ]、(( )) 和 [[ ]] 详解 [[Top]](#目录) | | 说明 | 举例 | 例子说明 | | --- | --- | --- | --- | | $( ) | 命令替换 | `version=$(uname -r)` | 得到内核版本号 | | \\` \\` | 命令替换，同 $() | version=\\`uname -r\\` | 同上 | | ${ } | 用于变量替换 | `a=1; b=${a}` 其实这里用 $a 一样，但有时会有区别 | a 赋给 b | | $(( )) | 进行数学运算 | `echo $(( 1+2*3 ))` | 输入 1+2×3 的结果 | | $[ ] | 进行数学运算 | `echo $[ 1+2*3 ]` | 同上 | | [ ] | test 命令的另一种形式 | `if [ 1 eq 1 ]...` | 字面意思 | | (( )) | 是`[ ]`的针对数学比较表达式加强版 | | | | [[ ]] | 是`[ ]`的针对字符串表达式的加强版 | [[ $? != 0 ]] | | * \\` \\` 和 $( )：反引号几乎可以在所有 shell 上执行，而`$( )`有些不可以；多层使用反引号需要加`\\`，`$( )`更浅显易懂，不易出错 ``` shell $ cat a.txt b.txt $ cat b.txt c.txt $ cat c.txt Hello World! $ cat `cat \\`cat a.txt\\`` # ``内的反引号必须使用 \\` Hello World! $ cat $(cat $(cat a.txt)) Hello World! bash 只能作整数运算，对于浮点数是当作字符串处理的 [ ]：必须在左括号的右侧和右括号的左侧各加一个空格，否则会报错 更多资料 http://bbs.chinaunix.net/forum.php?mod=viewthread&tid=218853&page=7#pid1617953 https://www.cnblogs.com/zejin2008/p/8412680.html 用 cat、echo 命令向文件写入 [Top] cat # 文件不存在则自动创建 # EOF 为开头结尾标记，可以换成任意字符串 # 1. 覆盖 cat > test.sh 1 > 2 > EOF # 2. 追加 $ cat >> test.sh 1 > 2 > EOF echo # 文件不存在则自动创建 # 1. 覆盖 echo 'hello hello world'>hello # 2. 追加 echo 'hello hello world' >> hello 杀死一个进程 [Top] ps aux | grep 进程名 ---> kill -s 9 进程号 kill -s 9 `ps aux | grep 进程名 | grep -v grep | awk '{print $2}'` ps aux | grep 进程名 | grep -v grep | xrags kill -s 9 kill -s 9 `pgrep 进程名` pkill -s 9 进程名 kill [信号] [进程号] kill 给指定进程发送指定信号，默认发送 TERM 信号，这回杀死不能捕获该信号的进程，对于单纯 kill 杀不死的进程，可能需要使用 kill ( 9 ) 信号，因为该信号不能被任何进程捕获 当我们杀掉父进程时，其下的子进程也会被杀死 kill -9 常用来杀死僵尸进程 pkill -9 进程名 可以一次性杀死所有包含 进程名 的进程 killall -9 进程名全称 也是一次性杀死所有包含 进程名 的进程，但必须使用进程完整名称 kill -s singal 命令最长使用的信号： Signal Name Single Value Effect SIGHUP 1 挂起 SIGINT 2 中断（等同 Ctrl + C） 3 退出（同 Ctrl + \\） SIGKILL 9 发出强制杀死信号 SIGTERM 15 默认，发出终止信号 SIGSTOP 17, 19, 23 暂停（等同 Ctrl + Z） 删除空行 [Top] sed '/^$/d' file sed -n '/./p' file grep -v ^$ file awk '/./ {print}' file awk '{if($0!=\"\") print}' tr -s \"\\n\" 文件去重 [Top] # 1. awk （不排序直接去重，按原顺序输出） awk '!a[$0]++' file cat file | awk '!a[$0]++' # 2. sort + uniq (先排序再去重，打乱了顺序) cat file | sort | uniq 截取文件开头几行、末尾几行和中间几行 [Top] # 截取前 5 行 - head、sed、awk head -5 filename # 或 sed -n '1,5p' filename # 或 awk 'NR 修改文件以包含当前时间命名 [Top] $ ls hello_log.txt $ mv hello_log.txt $(date +%Y%m%d-%H%M%S)_hello_log.txt $ ls 20191113-205057_hello_log.txt $ tar cvf hello_log_$(date +%Y%m%d-%H%M%S).tar.gz 20191113-205057_hello_log.txt 20191113-205057_hello_log.txt $ ls 20191113-205057_hello_log.txt hello_log_20191113-205252.tar.gz 查看当前主机公网 IP [Top] # 只返回 ip $ curl ip.sb $ curl www.pubyun.com/dyndns/getip $ curl members.3322.org/dyndns/getip # 返回中文解析，包括 IP、地址、运营商 $ curl cip.cc while 无限循环 [Top] while : do echo '我是死循环' done while /bin/true do echo '我是死循环' done 进程查端口，端口查进程 [Top] 进程 -> 端口 sudo netstat -tlpn | grep nginx sudo ss -tlpn | grep nginx sudo netstat -nap | grep \\ 端口 -> 进程 lsof -i:\\ sudo netstat -nap | grep \\ 查看其他主机开放的端口 [Top] sudo nmap -sS \\ $ sudo nmap -sS 47.101.133.201 Starting Nmap 7.60 ( https://nmap.org ) at 2019-11-26 19:40 CST Nmap scan report for 47.101.133.201 Host is up (0.045s latency). Not shown: 995 filtered ports PORT STATE SERVICE 22/tcp open ssh 80/tcp closed http 443/tcp closed https 1080/tcp closed socks 8080/tcp closed http-proxy Nmap done: 1 IP address (1 host up) scanned in 28.81 seconds 快速查看配置文件中有效配置行 [Top] 配置文件往往动辄几百行，但可能只有几行是非注释非换行的有效配置，可以使用 egrep -v 排除空行和注释行，快速查看配置文件的有效配置行 # 查看 ansible 配置文件中的有效配置 ( 以 # 号开头是注释行 ) $ egrep -v \"(^$|^#)\" ./ansible.cfg Xiechengqi            最新修订时间： 2019-12-06 21:21:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/Linux文本操作三大利器-grep、sed、awk.html":{"url":"Shell/Linux文本操作三大利器-grep、sed、awk.html","title":"Linux文本操作三大利器-grep、sed、awk","keywords":"","body":"grep、sed、awk 详解 grep - 更适合单纯的查找或匹配文本 sed - 更适合编辑匹配到的文本 awk - 更适合格式化文本，对文本进行较复杂格式处理 grep grep - global search regular expression(RE) and print out the line - 全面搜索正则表达式并把行打印出来 sed sed - stream editor - 流编辑器 一次处理一行内容，处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”( pattern space )，接着用 sed 命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕 sed 默认不会直接修改源文件 sed 不管是否找到指定的模式，命令退出状态都是 0；只有当命令存在语法错误时，sed 的退出状态才是非 0 sed 适合使用 vi 类编辑器操作不太方便的情况，比如操作有数千行的文本和在 shell 脚本中修改文本文件 sed [选项] '命令' 文件名> [选项] -n - 取消默认输出 ( sed 默认会打印模式空间里的内容 ) -e - 多点编辑，可以执行多个子命令，每个 -e 后都可以接一个 '命令' -f - 从脚本文件中读取命令（ sed 操作可以事先写入脚本，然后通过 -f 读取并执行） -r - 在 '命令' 中允许使用扩展正则表达式，默认是允许基础正则表达式 -i - 直接编辑原文件，且不输出到终端 '命令' a \\ - append - 在当前行后添加一行或多行。多行时除最后一行外，每行末尾需用\\续行 c \\ - chang - 用 c 后的新文本替换指定行。多行时除最后一行外，每行末尾需用 \\续行 i \\ - insert - 在当前行之前插入一行或多行。多行时除最后一行外，每行末尾需用 \\ 续行 d - delete - 删除选中的行 p - print - 打印当前选择的行 s/re/string/[flag] - subs - 用 string 替换正则表达式 re 常用命令 sed -n 修改行后不会有输出，所以想查看结果，一般会用 sed -n -e '操作' -e '1,$p' filename $ - 行尾定位符 对指定的 n~m 行操作 显示 n~m 行 sed -n 'n,mp' filename 新增行 第 n 行后新增字符串 string：sed 'na string' filename 第 n 行前新增字符串 string：sed 'ni string' filename 需要新增多行，新增行末尾加 \\，再换行输入下一新增行即可 删除 n~m 行 sed 'n,md' filename sed 'n,$d' filename - 删除从第 n 行开始到结束所有行，$ 代表最后一行 sed 'n' filename - 删除第 n 行单行 替换 n~m 行 sed 'n,mc newstring' filename - 用 newstring 替换第 n~m 行 对匹配 string 的行操作 在指定 n~m 行内操作匹配 string 的行：sed -n -e '[位置参数] 操作命令' -e '1,$ p' filename eg: sed -n -e '2,3 s/old/new/g' -e '1,$ p' inputfile 显示匹配 string 的行 sed -n '/string/p' filename 删除匹配 string 的行 sed -n '/string/d' filename 在匹配 string 的行后插入字符串 new sed -n '/string/a new' filename 在匹配 string 的行前插入字符创 new sed -n '/string/i new' filename 用 new 字符串替换 string 字符串 sed '[位置参数] s/string/new/[替换标志]' [替换标志] - 标志可以一起使用，比如 2p 就是替换每行第 2 个匹配的字符串，并打印修改过的行 g - 全局替换，会替换文本行中所有匹配的字符串 eg: ps aux | sed -n -e '1,10 s/0/1/g' -e '1,10 p' n ( 数字 ) - 替换每行中第 n 个匹配的字符串 eg: ps aux | sed -n -e '1,10 s/0/1/2' -e '1,10 p' p - 替换第一个匹配的字符串，并打印修改过的行 eg: ps aux | sed -n -e '1,10 s/0/1/p' -e '1,10 p' w file - 替换每行第一个匹配的字符串，并将所选的行写入文件 file 中 eg: ps aux | sed -n -e '1,10 s/0/1/w test' -e '1,10 p' 缺省 - 默认替换每行第一个匹配的字符串 eg: ps aux | sed -n -e '1,10 s/0/1/' -e '1,10 p' 对匹配 string 行执行自定义命令 sed -n '[位置参数] s/string/{命令}' filename 实战命令 # 删除空行并输出 $ sed '/^$/d' file 或 $ sed -n '/./p' file # 删除首行空格 $ sed 's/^[[ :space: ]]*//g' file # 在特定字符串后添换行 $ sed 's/new/&\\n/g' file # 在特定字符串前添加空行 $ sed 's/new/\\n&/g' file awk 抛砖引玉 如何查看Linux系统上的所有用户？ awk 'BEGIN{ FS=\":\" printf(\"%-10s%-20s\\n\", \"UserName\", \"HomeDir\") print \"==============================\" } { printf(\"%-10s%-20s\\n\", $1, $6) } END{ print \"==============================\" printf(\"User(s):%d\\n\", NR) print \"==============================\" }' /etc/passwd 原理简述 awk 原理 从上图中可以看出，awk 在工作时主要分为以下三个部分： BEGIN - 也就是所谓的初始化模块，比如定义分隔符，初始化一些值等，它会在数据处理部分执行之前执行，并且只执行一次，这一部分是可选的 数据处理 - 这一部分也就是 awk 脚本的核心部分，它是一对以模式 pattern 与大括号括起来的操作 action 组合而成的，二者可能会出现以下组合： pattern {action} - 记录匹配对应的模式，则执行大括号中的操作 pattern - 记录匹配对应的模式，则直接打印记录 {action} - 对每一条记录都执行大括号中的操作 数据处理模块会循环读取待处理文件中的记录，每次读取一条记录，处理完一条以后再读取下一条记录，直至所有记录被读取完毕 END - 是最终的收尾处理模块，它会在所有数据处理完成以后才执行，并且只执行一次；比如我们处理完数据了，需要输出一共处理了多少条记录，多少个字段等信息，就可以在 END 部分进行输出，这一部分也是可选的 记录 - 行 字段 - 列 命令使用 awk 是一种处理文本文件的语言，是一个强大的文本分析工具 awk 更适合格式化文本，对文本进行较复杂格式处理 awk 是以列为划分计数的，$0 表示当前行（即所有列），$1 表示第一列，$2 表示第二列 awk [选项] '[动作]' [文件名] awk 动作只能使用单引号 [选项] 选项 解释 -F fs 划分数据字段的分隔符 -f file 从指定文件中读取 awk 命令 -v var=value awk printf 格式说明符 awk [选项] '{printf \"%说明符1,%说明符2\",var1，var2}' 文件名 %说明符 - %[flags][width][.precision]conversion % - 是必须的, 任何格式符都由百分号开始 flag 标志（可省） flag 解释 默认 右对齐，且用空格填充 - 左对齐 + 打印正负数的符号 0 用 0 填充 width 宽度（可省） - 输出的宽度 precision 精度（可省） awk '{printf \"%.5说明符\\n\",$1}' 解释 %d,%i,%o,%u,%x,%X 数字位数最大为 5，不够前缀补 0 %e, %E 数字位数最大为 5，不够后缀补 0 %f 如果小数点后位数少于 5，后缀补 0 %g, %G 最多数字位数 %s 字符位数少于 5，原样输出，多于5，只输出前 5 个字符 conversion 说明符（必选） conversion 说明符 解释 %d 和 %i 十进制的整数部分 %s 字符串 %f 浮点数 %c 单个字符 %e 或 %E 科学计数法格式 %o 八进制数 %x 十六进制数 %% % 实例解析 %-5.2f - 输出总宽度为 5 的浮点数，其中小数位为 2，整数位为 2，小数点占 1 位，不够 5 为左对齐 %9.2f - 表示输出场宽为9的浮点数, 其中小数位为 2， 整数位为 6，小数点占 1 位, 不够 9 位右对齐 %04d - 表示在输出一个小于 4 位的数值时, 将在前面补 0 使其总宽度为 4 位 %6.9s - 表示显示一个长度不小于 6 且不大于 9 的字符串。若大于 9, 则第 9 个字符以后的内容将被删除 awk 内置变量 NF：表示当前行的字段总数 NF - 打印当前行字段数 $NF - 打印当前行最后一个字段 $NF-1 - 打印当前行倒数第二个字段 NR：表示当前处理的是第几行 FILENAME：当前文件名 FS：字段分隔符，默认是空格和制表符。 RS：行分隔符，用于分割每一行，默认是换行符。 OFS：输出字段的分隔符，用于打印时分隔字段，默认为空格。 ORS：输出记录的分隔符，用于打印时分隔记录，默认为换行符。 OFMT：数字输出的格式，默认为 ％.6g。 $ cat /etc/passwd | awk -F ':' '{printf \"行字段数：%d\\n\",NF}' $ cat /etc/passwd | awk -F ':' '{printf \"行最后一个字段是：%s\\n\", $NF}' # print 命令里面，如果原样输出字符，要放在双引号里面 $ cat /etc/passwd | awk -F ':' '{print \"行字段数：\" NF}' # 和上面 printf 效果一样 awk 内置函数 内置函数完整列表 toupper()：字符转为大写 tolower()：字符转为小写 length()：返回字符串长度 substr()：返回子字符串 sin()：正弦 cos()：余弦 sqrt()：平方根 rand()：随机数 $ cat /etc/passwd | head -10 | awk '{print toupper($0)}' awk 条件判断 awk [选项] '条件判断 {动作}' 文件名 适合于只需一次判断 [选项] 和 '条件判断 {动作}' 之间空格一定不能少，'条件判断 {动作}' 内部空格可以省略 # 输出奇数行 $ cat /etc/passwd | awk 'NR % 2 == 1 {print $0}' # 输出第 5 行后的行 $ cat /etc/passwd | awk 'NR > 5 {print $0}' # 输出第一个字段是 'root' 或 'bin' 的行 $ cat /etc/passwd | awk -F ':' '$1 == \"root\" || $1 == \"bin\" {print $0} ' awk if 条件判断 awk [选项] '{if(条件判断) 动作}' 文件名 适合于需要多次判断 # if 判断出第一个字段的第一个字符大于 'q' 的行，并输出 $ cat /etc/passwd | awk -F ':' '{if ($1 > \"q\") print $0}' # 等价于 $ cat /etc/passwd | awk -F ':' '$1 > \"q\" {print $0}' # if else $ cat /etc/passwd | awk -F ':' '{if ($1 > \"m\") print $0; else print \"---\"}' 参考 awk 入门教程 - 阮一峰 进阶：玩玩awk - 果冻想 进阶：awk中的函数 - 果冻想 Xiechengqi            最新修订时间： 2019-12-06 21:21:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/Shell文本处理常用工具补遗.html":{"url":"Shell/Shell文本处理常用工具补遗.html","title":"Shell文本处理常用工具补遗","keywords":"","body":"Shell 文本处理常用工具补遗 sort uniq count cut wc find xargs tr paste join paste split sort 对文本的行排序 sort 将文件的每一行作为一个单位，相互比较，默认比较原则是从首字符向后，依次按 ASCII 码值进行比较，最后将它们按升序输出 sort [选项] file [选项] -r - 逆序排序 ( 从大到小 ) -u - 去掉重复的行 -k N - 指定按第N列排序 -n - 按数字进行排序，sort 默认是按字符进行排序 -d - 按字典序进行排序 -t - 指定分隔符，默认分隔符是制表符 -k [n,m] - 按照指定的字段范围排序。从第 n 个字段开始，到第 m 个字段（ 默认到行尾 ） -f - 忽略大小写 -b - 忽略每行前面的空白部分 -o - 将排序后的结果存入指定的文件 常用命令 # 以冒号分割 /etc/passwd 每行，并按第 1 列字符排序 $ cat /etc/passwd | sort -t ':' -k1 # 以冒号分割 /etc/passwd 每行，并按第 3 列数字排序 $ cat /etc/passwd | sort -t ':' -k 3n $ cat /etc/passwd | sort -n -t \":\" -k 3 $ cat /etc/passwd | sort -n -t \":\" -k 3,3 # -k 3 ：代表从第三个字段到行尾都排序（第一个字段先排序，如果一致，则第二个字段再排序，直到行尾） # -k 3,3：代表仅对第三个字段进行排序，后面字段按原来顺序 uniq 检查并删除文本中相邻重复出现的行 uniq [选项] 文件 [选项] 空 - 默认将相邻或连续相同的行删除到只剩一行，并输出 -c 在每列旁边显示该行重复出现的次数 Xiechengqi            最新修订时间： 2019-12-06 21:21:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/句子解析.html":{"url":"Shell/句子解析.html","title":"句子解析","keywords":"","body":"句子解析 目录 [ $# -lt 1 ] && echo \"please input the income file\" && exit -1 [ ! -f $1 ] && echo \"$1 is not a file\" && exit -1 for i in ${seq -f %03g 1 12};do wget \"https://img.ivsky.com/img/tupian/pre/201812/29/lvyouyou_nongtian-$i.jpg\"; done for i in {1..5} ; do echo -n \"$i \"; done hash $1 &> /dev/null echo \"`date +%F' '%H:%M:%S`\" [ -d $dirname ] || mkdir -p $dirname &> /dev/null [ -e ${dirname}${filename} ] || touch ${dirname}${filename} &> /dev/null cat /etc/passwd|grep -v nologin|grep -v halt|grep -v shutdown|awk -F\":\" '{ print $1\"|\"$3\"|\"$4 }' [ $# -lt 1 ] && echo \"please input the income file\" && exit -1 解释：脚本不带参数时，输出 \"please input the income file\" 并以 -1 （非零表示执行失败）状态值退出 [ $# -lt 1 ] ：$# 是传入脚本参数个数，-lt是小于 &&：当前面出现第一个 false，则false后面都不执行；前面都是 true，则接着执行后面的语句 [ ! -f $1 ] && echo \"$1 is not a file\" && exit -1 解释：传入脚本的第一个参数不是文件格式时，输出 \"$1 is not a file\" 并以 -1 （非零表示执行失败）状态值退出 for i in `seq -f %03g 1 12`; do wget \"https://img.ivsky.com/img/tupian/pre/201812/29/lvyouyou_nongtian-$i.jpg\"; done 解释：wget 下载 https://img.ivsky.com/img/tupian/pre/201812/29/lvyouyou_nongtian-(001-012).jpg seq -f %03g 1 12： -f - 指定打印的格式 % - 后面指定数字的位数 默认是%g %3g - 打印 3 位数不足部分是空格 %03g - 打印 3 位数不足部分是 0 还可以在%前面加上固定的字符串：$ seq -f \"str%03g\" 9 11 str009 str010 str011 for i in {1..5}; do echo -n \"$i \"; done 解释：打印输出 \"1 2 3 4 5 \" {1..5}：中间是两点.. echo -n：输出不换行 hash $1 &> /dev/null 解释：判断第一个参数是否存在于当前系统命令，无输出 hash 命令：返回 0 ( 命令已存在于当前系统 ) 或 1 echo `date +'%Y-%m-%d %H:%M:%S'` # 显示的是本地时区的时间 echo `date -u -d\"+8 hour\" +'%Y-%m-%d %H:%M:%S'` # 先打印 UTC 时间，在转换成中国时间 (CST)，这样即使本地时区未设置成中国地区，也显示的是 CST 时间 2019-10-22 18:25:34 解释：格式化输出时间，注意 date 后面是空格、加号 [ -d $dirname ] || mkdir -p $dirname &> /dev/null [ -e ${dirname}${filename} ] || touch ${dirname}${filename} &> /dev/null 解释：dirname 文件夹和 ${dirname}${filename} 文件存在则无反应，不存在则创建之 $ cat /etc/passwd | grep -v nologin | grep -v halt | grep -v shutdown | awk -F\":\" '{ print $1\"|\"$3\"|\"$4 }' root|0|0 sync|5|0 admin|1000|1000 xcq|1001|1001 解释：格式化输出 Linux 用户列表 grep -v：输出显示不匹配的行 awk -F\":\" '{ print $1\"|\"$3\"|\"$4 }'：使用 \":\" 分割输入字符串，并输出第 1、3、4 列内容 Xiechengqi            最新修订时间： 2019-12-07 10:13:15 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/识别是否是root用户.html":{"url":"Shell/识别是否是root用户.html","title":"识别是否是root用户","keywords":"","body":"案例一、 #!/usr/bin/env bash Green_background_prefix=\"\\033[42;37m\" && Font_color_suffix=\"\\033[0m\" check_root(){ [[ $EUID != 0 ]] && echo -e \"${Error} 当前非ROOT账号(或没有ROOT权限)，无法继续操作，请更换ROOT账号或使用$ {Green_background_prefix}sudo su${Font_color_suffix} 命令获取临时ROOT权限（执行后可能会提示输入当前账号的密码）。\" && exit 1 } check_root echo echo -e —— 开启转义，即可读取 '\\n' 为换行 shell 脚本中 echo 显示内容带颜色显示，echo 显示带颜色，需要使用参数 -e 例如： echo -e \"\\033[41;36m something here \\033[0m\" 其中 41 的位置代表底色， 36 的位置是代表字的颜色 注： 字背景颜色和文字颜色之间是英文的 \"\" 文字颜色后面有个 m 字符串前后可以没有空格，如果有的话，输出也是同样有空格 下面是相应的字和背景颜色，可以自己来尝试找出不同颜色搭配 字颜色：30—–37 　　echo -e “\\033[30m 黑色字 \\033[0m” 　　echo -e “\\033[31m 红色字 \\033[0m” 　　echo -e “\\033[32m 绿色字 \\033[0m” 　　echo -e “\\033[33m 黄色字 \\033[0m” 　　echo -e “\\033[34m 蓝色字 \\033[0m” 　　echo -e “\\033[35m 紫色字 \\033[0m” 　　echo -e “\\033[36m 天蓝字 \\033[0m” 　　echo -e “\\033[37m 白色字 \\033[0m” 字背景颜色范围：40—–47 echo -e “\\033[40;37m 黑底白字 \\033[0m” 　　echo -e “\\033[41;37m 红底白字 \\033[0m” 　　echo -e “\\033[42;37m 绿底白字 \\033[0m” 　　echo -e “\\033[43;37m 黄底白字 \\033[0m” 　　echo -e “\\033[44;37m 蓝底白字 \\033[0m” 　　echo -e “\\033[45;37m 紫底白字 \\033[0m” 　　echo -e “\\033[46;37m 天蓝底白字 \\033[0m” 　　echo -e “\\033[47;30m 白底黑字 \\033[0m” 最后面控制选项说明 　　\\33[0m 关闭所有属性 　　\\33[1m 设置高亮度 　　\\33[4m 下划线 　　\\33[5m 闪烁 　　\\33[7m 反显 　　\\33[8m 消隐 　　\\33[30m — \\33[37m 设置前景色 　　\\33[40m — \\33[47m 设置背景色 　　\\33[nA 光标上移n行 　　\\33[nB 光标下移n行 　　\\33[nC 光标右移n行 　　\\33[nD 光标左移n行 　　\\33[y;xH设置光标位置 　　\\33[2J 清屏 　　\\33[K 清除从光标到行尾的内容 　　\\33[s 保存光标位置 　　\\33[u 恢复光标位置 　　\\33[?25l 隐藏光标 　　\\33[?25h 显示光标 案例二、id -u（显示当前用户的 uid ） [ $(id -u) != \"0\" ] && echo \"Error: You must be root to run this script\" && exit 1 或 [ `id -u` != \"0\" ] && echo \"Error: You must be root to run this script\" && exit 1 案例三、whoami（显示当前用户的用户名） # != 两边一定要有空格，中括号内两侧也一定要有一个空格 [ $(whoami) != \"root\" ] && echo \"Error: You must be root to run this script\" && exit 1 或 [ `whoami` != \"root\" ] && echo \"Error: You must be root to run this script\" && exit 1 Xiechengqi            最新修订时间： 2019-12-06 21:21:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Shell/识别系统.html":{"url":"Shell/识别系统.html","title":"识别系统","keywords":"","body":"#!/usr/bin/env bash check_sys(){ if [[ -f /etc/redhat-release ]]; then release='centos' elif cat /etc/issue | grep -q -E -i 'debian'; then release='debian' elif cat /etc/issue | grep -q -E -i 'ubuntu'; then release='ubuntu' elif cat /etc/issue | grep -q -E -i 'centos|red hat|redhat'; then release='centos' elif cat /proc/version | grep -q -E -i 'debian'; then release='debian' elif cat /proc/version | grep -q -E -i 'centos|red hat|redhat'; then release='centos' elif cat /proc/version | grep -q -E -i 'ubuntu'; then release='ubuntu' fi echo $release } check_sys grep -q, --quiet, --silent 不显示所有常规输出 -i, --ignore-case 忽略大小写 -E, --extended-regexp 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式 Xiechengqi            最新修订时间： 2019-12-06 21:21:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Docker/":{"url":"Docker/","title":"Docker","keywords":"","body":"Docker 学习 Xiechengqi            最新修订时间： 2019-12-06 21:49:28 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Docker/Docker必知单词.html":{"url":"Docker/Docker必知单词.html","title":"Docker必知单词","keywords":"","body":"Docker 学习中的单词 isolated - 隔离的 compose - 编排 expose - 开放 reference - 参考 Xiechengqi            最新修订时间： 2019-12-06 21:08:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Docker/Docker基础学习.html":{"url":"Docker/Docker基础学习.html","title":"Docker基础学习","keywords":"","body":"Docker 基础学习笔记 目录 Docker 常用命令 Docker 基础架构 Docker 原理简述 Dockerfile - 构建产生镜像 Docker Compose - 编排操控容器 Docker Machine - 创建管理容器宿主机 Docker Swarm Docker 常用命令 [Top] docker search 关键字 - 默认从 docker hub 搜索指定镜像 docker pull 镜像名:tag - 拉取镜像 docker images - 列出已安装的镜像 docker rmi image-id - 删除指定镜像 docker rm container-id - 删除指定容器 docker ps - 查看运行中的容器 -a 查看所有容器 docker start|stop container-id|container-name - 通过容器 id 或容器名运行 / 关闭容器 docker run --name 容器名 -d -p 3306:3306 mysql - docker 启动容器 --name - 自定义容器名 -p - 端口映射，-p 宿主机端口:容器端口 -d - 守护进程 docker logs container-name/container-id 查看容器日志 Ctrl+P+Q 退出容器交互式界面，但不关闭容器 docker help - 检查最新 Docker 可用命令 docker attach—将本地输入、输出、错误流附加到正在运行的容器 docker commit—从当前更改的容器状态创建新镜像 docker exec—在活动或正在运行的容器中运行命令 docker exec -it container command docker history [img]—显示镜像历史记录 docker info—显示系统范围信息 docker inspect [img|con]—查找 docker 指定容器和镜像的系统级信息 docker login --username=xxx --email=xxx - 登录到本地注册表或 Docker Hub docker pull—从本地注册表或 Docker Hub 中提取镜像或存储库 docker ps—列出容器的各种属性 docker start/stop/restart—启动/关闭/重启容器 docker rm—移除容器 docker rmi—删除镜像 docker run—在隔离容器中运行命令 docker search—在 Docker Hub 中搜索镜像 docker version—显示 docker 版本信息 docker run volume - 数据卷、数据卷容器 docker run -v|--volume[=[[HOST-DIR:]CONTAINER-DIR[:OPTIONS]]] - 添加一个数据卷 docker run -it -v /dbdata --name dbdata ubuntu - 创建一个数据卷容器 dbdata ，并在其中创建一个数据卷挂载到 /dbdata docker run -it --volumes-from dbdata --name db1 ubuntu - 创建 db1 容器，并从 dbdata 容器挂载数据卷 docker rm -v - 删除容器和容器绑定的数据卷 docker run --rm - 在关闭容器后也会自动删除容器和容器绑定的数据卷 ** - docker network - 管理网络 docker network ls docker network connect docker network create docker network disconnect docker network inspect docker network prune docker network rm Docker 基础架构 [Top] C/S 架构 - 客户端、服务器两大组件 客户端可以通过 socket 或 RESTful API 与服务器进行通信 常说的 Docker 也可称为 Docker Engine Docker Engine = Docker 守护进程 + REST API （指定与守护进程交互的接口） + 命令行接口（CLI）（与守护进程通信，通过封装 REST API） 服务端 一、四大组件 dockerd $ ps -ef | grep dockerd root 3769 1 0 Dec02 ? 00:01:08 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock docker-proxy dockerd 子进程，当容器启动并使用端口映射时才会执行，负责配置容器的端口映射规则 $ ps aux | grep docker-proxy root 24923 0.0 0.0 700716 4656 ? Sl 13:19 0:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8011 -container-ip 172.17.0.2 -container-port 80 root 24937 0.0 0.0 626728 3824 ? Sl 13:19 0:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 2222 -container-ip 172.17.0.2 -container-port 2222 containerd dockerd 子进程 containerd-shim containerd 子进程 客户端 Docker 原理简述 [Top] 命名空间 - namespace 操作系统中，进程间共享的资源有内核、文件系统、网络、进程号 ( Process ID, PID )、用户号 ( User ID，UID )、进程间通信 ( InterProcess Communication，IPC )等。Linux 命名空间就是为了实现以上的相互隔离，保证了容器之间彼此互补影响 进程命名空间 IPC 命名空间 IPC - Interprocess Communication - 进程间交互 容器中的进程交互还是采用 Linux 常见 IPC，包括信号量、消息队列、共享内存等方式 网络命名空间 挂载命名空间 UTS 命名空间 UTS - UNIX Time-sharing System 用户命名空间 控制组 - Control Groups - CGroups Linux 内核特性，主要用来对共享资源进行隔离、限制、审计等 联合文件系统 - Union File System - UnionFS 容器就是由存储 image 的只读层和读写层构成 容器需要修改只读层的文件，会先从只读层拷贝一份到读写层，再修改它，实际上修改的是副本。但修改后，只读层对应的文件就“隐藏” 起来了 容器的只读层是共享的，也就是当同一镜像创建的多个容器时，其实只是创建了多个读写层，删除容器时，就只是删除容器的读写层。而且读写层也是在容器操作产生数据时才消耗资源，所以创建容器的成本很小！ docker engine 是共享宿主机操作系统的，容器又是共享 image 的（只读层共享），所以容器启动成本很小！ Dockerfile - 构建产生镜像 [Top] Docker Compose - 编排操控容器 [Top] 编写需要重复生成应用 ( app ) 的 Dockerfile 一般一个容器里一个应用，比如 mysql 数据库 定义用于编排多个应用以组成服务 ( service ) 的 docker-compose.yml 一个服务一般由多个应用组成，比如 web service 可以由 nignx 负载均衡器、tomcat web 服务器、mysql 数据库服务器等组成 docker-compose up docker-compose 本身没有构建镜像的功能，如果容器镜像是直接从 docker registry 拉取，则不需要 Dockerfile ；但如果需要基于基础镜像构建新的镜像，则需要使用 Dockerfile Docker Machine - 创建管理容器宿主机 [Top] 简介 docker-machine 可以在本地、云端服务器快速创建包含 Docker Engine 的虚拟主机环境，但不能在虚拟机中创建（虚拟机中不能再创建虚拟机） docker-machine 可以启动、审查、停止和重新启动托管的宿主机、升级 Docker 客户端和守护程序、并配置 Docker 客户端与你的宿主机通信 也可以使用 Ansible 等 DevOps 工具实现对 Docker 环境的自动化管理 本质上 docker-machine 是一个虚拟机管理工具，它通过创建一个安装好docker 的虚拟机（支持 VirtualBox，DigitalOcean，EC2 等），并设置对应的环境变量（ DOCKER_HOST，DOCKER_MACHINE_NAME 等），使得本地的 docker 工具获得透明远程操作虚拟机的能力。从而使本身不支持 docker 的 Windows 和 Mac 系统能够直接使用 docker 命令 安装 https://github.com/docker/machine/releases/ $ curl -L https://github.com/docker/machine/releases/download/v0.16.2/docker-machine-`uname -s`-`uname -m` >/usr/local/bin/docker-machine $ chmod +x /usr/local/bin/docker-machine 常用命令 docker-machine [OPTIONS] COMMAND [arg...] docker-machine -h - 查看常用命令 docker-machine COMMAND -h - 查看具体某一个命令功能 解决首次运行慢 第一次运行 docker-machine create 会去 https://github.com/boot2docker/boot2docker/releases/ 下载一个最新的 57M 的 boot2docker.iso 镜像，国内下载会很慢 # 1. 下载 boot2docker.iso 最新版本到本地 - https://github.com/boot2docker/boot2docker/releases/ # 2. 移动 boot2docker.iso 到 ~/.docker/machine/cache/ $ mv boot2docker.iso ~/.docker/machine/cache/ # 3. 指定本地的 boot2docker.iso 路径，并跳过网络检查创建新的 docker machine ，命名为 default $ docker-machine create default -d virutalbox --virtualbox-boot2docker-url=/home/`whoami`/.docker/machine/cache/boot2docker.iso # --virtualbox-boot2docker-url 手动指定了boot2docker.iso 位置 配置当前shell docker server $ docker-machine env default export DOCKER_TLS_VERIFY=\"1\" export DOCKER_HOST=\"tcp://192.168.99.100:2376\" export DOCKER_CERT_PATH=\"/home/xcq/.docker/machine/machines/default\" export DOCKER_MACHINE_NAME=\"default\" # Run this command to configure your shell: # eval $(docker-machine env default) $ eval $(docker-machine env default) # 执行上面命令即可切换 docker server 为 default 主机中 docker server Docker Swarm [Top] Xiechengqi            最新修订时间： 2019-12-06 21:46:33 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Docker/Docker小知识.html":{"url":"Docker/Docker小知识.html","title":"Docker小知识","keywords":"","body":"Docker 小知识 目录 连接 docker 容器 连接 docker 容器 [Top] Docker 原生命令连接容器 docker attach [container] docker exec -i -t [container] /bin/bash SSH 登录 使用 nsenter、nsinit 等第三方工具 Xiechengqi            最新修订时间： 2019-12-06 21:08:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Git/":{"url":"Git/","title":"Git","keywords":"","body":"Git 分布式世界 1. 版本控制之道 版本库 集中式（CVS、SVN） 分布式（git） 工作目录树 断面视图 工作拷贝 1、初始化（init）.git目录 2、克隆（clone） 代码修改与文件同步 跟踪项目、目录和文件 使用标签跟踪里程碑 使用分支来跟踪并行演进 合并 锁机制 2. 安装与设置 安装 Linux Mac：sudo port install git-core +svn +doc Windows Cygwin MSys 设置 git config 提 交 者：git config --global user.name \"Jamsonwoo\" 邮件地址：git config --global user.email \"Jamsonwoo@126.com\" 查看：git config --global --list 颜色：git config --global color.ui \"auto\" （auto/always/false)(注：MSys建议用always) GUI Tcl/TK：git gui(备注：工作目录树) gitk --all(备注：工作目录树) GitX (Mac) 内置帮助 git help git-doc 3. Hello Git 创建版本库：git int 修改代码 1、添加索引：git add index.html 2、提交记录：git commit -m \"add in hello git HTML\" （备注：提交留言至少应该体现出进行本次修改的原因。先用一句简单的话来概括该提交；然后用几句话全面解释。） 3、查看日志 git log （扩展：SHA-1哈希码） git log --pretty=oneline 视图状态：git status （备注：存放代码） 1、工作目录树 2、索引（暂存区） 3、版本库 分支 1、创建分支：git branch 新分支名称 父分支名称 git branch RB_1.0 master 2、提交修改：git commit -a（-a：提交全部修改过的文件） 3、切换分支：git checkout 分支名称 git checkout RB_1.0 处理发布 1、打标签：git tag 标签名称 打标签的点 git tag 1.0 RB_1.0 2、变基命令：git rebase 分支名称（合并到主分支） git rebase RB_1.0 3、删除分支：git branch -d 分支名称 git branch -d RB_1.0 4、创建归档：git archive --format=输出格式 --prefix=包内容 需要归档的标签名称 | gzip > 压缩结果重定向 git archive --format=tar --prefix=mysite-1.0/ 1.0 | gzip > mysite-1.0.tar.gz git archive --format=zip --prefix=mysite-1.0/ 1.0 > mysite-1.0.zip 克隆远程版本库：git clone 远程版本库的位置 存放该版本库的本地目录 git clone git://github.com/tswicegood/mysit.git mysite-remote Git用法 1. 添加与提交 添加文件到暂存区 1、启动交互命令提示符：git add -i 2、直接进入补丁模式：git add -p 提交修改 1、跟踪空目录：git不单独记录和跟踪目录，解决：在空目录里添加一个句点开头的空文件 2、git commit 的提交留言编辑器 -v 如果输入不带-m参数的git commit命令，Git将启动编辑器来编辑提交留言。为启动编辑器，Git会按照一下顺序查找编辑器的设置： 1、环境变量 GIT_EDITOR 的值。 2、Git 的设置 core.editor 的值。 3、环境变量 VISUAL 的值。 4、环境变量 EDITOR 的值。 5、如果上述值均为空，Git 会尝试启动 vi 编辑器。 提交三法 备注 a、提交暂存后的修改（先暂存后提交） 备注 b、提交工作目录树中的所有修改（把修改直接提交） 备注 c、提交工作目录树中执行的修改（把修改直接提交） 1、添加到暂存区 1、git add 文件 2、git commit -m \"留言\" 2、提交所有修改到版本库：git commit -m \"留言\" -a 3、指定提交文件（列表）：git commit -m \"留言\" 文件 Git别名: git commit 简写为：git ci git config --global alias.ci \"commit\" 查看修改内容 1、查看当前状态：git status Changes to be committed. 待提交变更 Changed but not updated. 未更新到索引的变更 2、查看文件改动：git diff a、git diff 无参 工作目录树 VS 暂存区 b、git diff --cached 暂存区 VS 版本库 b、git diff HEAD 工作目录树（暂存＋未暂存） VS 版本库 管理文件 1、文件重命名与移动：git mv 原文件名称 新文件名称 2、复制文件：无git cp命令，无需复制 3、忽略文件： a、版本级：文件加入.gitignore文件中，支持通配符* b、本地级：.git/info/exclude 2. 分支 什么叫分支 分支重命名：git branch -m 分支原名称 新名称 git branch -m master mymaster 显示本地版本库所有本地分支名称：git branch 创建分支：1、试验性更改 2、增加新功能 3、Bug修复 创建新分支 创建分支：git branch 新分支名称 git branch newBranchName 检出分支：git checkout 分支名称 git checkout newBranchName 创建并检出：git checkout -b 新分支名称 新分支源分支 git checkout -b newBranchName2 master 合并分支 合并(merge)方法 1、直接合并：把两条分支上的历史轨迹合并，交汇到一起 2、压合合并：一条分支上若干提交条目压合成一个提交条目，提交到另一条分支的末梢 3、拣选合并：拣选另一条分支上的某个提交条目的改动带到当前分支上 直接合并 git merge 分支名称 git checkout alternate git add about.html git commit -m \"add about page\" git checkout master git merge alternate 压合合并 git merge --squash 分支名称 git checkout -b contact master git add contact.html git commit -m \"add contact file\" git commit -m \"add contact file 2\" -a git checkout master git merge --squash contact git status git commit -m \"add contact page\" -m \"has primary and secondary email\" 拣选合并 git cherry-pick 提交名称 git checkout contact git commit -m \"add contact 3\" -a [contact 6dbaf82]...... git checkout master git cherry-pick 6dbaf82 / git cherry-pick -n 6dbaf82 冲突处理 git merge git checkout -b about master 编辑about.html git add about.html git commit -m \"add about.html \" git branch about2 about 编辑about.html git commit -m \"add about.html 1\" -a git checkout about2 编辑about.html git commit -m \"add about.html 2\" -a git checkout about git merge about2 git mergetool git commit 处理冲突软件（kdiff3）：git config --global merge.tool kdiff3 git mergetool 删除分支 git branch -d 分支名称 （成功合并到当前分支时） git branch -d about2 git branch -D 分支名称 （强制删除） 分支重命名 git branch -m 原分支名称 新分支名称 （不允许重名） git branch -m contact abc git branch -M 原分支名称 新分支名称 （强制覆盖） git branch -m master contact 3. 查询历史记录 查看日志 git log j 向下浏览；k 向上浏览；q 退出 提交名称、提交人、提交日期、提交留言 git log -p （显示版本之间的代码差异） git log -1（数字表示提交日志条数） git log 7b1558c （指定提交名称缩写[前7位]） 指定查找范围 git log --since/before=\"英文格式日期\" git log --since=\"5 hours\" （最近5小时内） git log --before=\"2012-8.20\" -1 （20120820之前的最后一条） git log 最老版本..最新版本 git log 18f822e..0bb3dfb 注：日志结果不包括最老，包括最新 git log 18f822e..HEAD / git log 18f822e.. git log 标签名称 git log --pretty=format:\"%h %s\" 1.0..HEAD git log --pretty=oneline 1.0..HEAD \\^：回溯一个版本 git log 18f822e^^ 注：1、windows系统下，^需要添加双引号 git log “18f822e^^”。 注：2、当遇到某个节点（通常是版本合并后的节点）有并列的多个父节点时，“^1”代表第一个父节点，“^2”代表第二个，以此类推。而“^”是“^1”的简写。 *~N：回溯N个版本 git log -1 HEAD^^^ / git log -1 HEAD^~2 / git log -1 HEAD~1^ / git log -1 HEAD~3 git log -1 HEAD~10..HEAD 查看版本间差异 git diff 版本名称（与当前工作目录树的差异） git diff 18f822e git diff --stat 1.0（数据统计） 查明提交者 git blame 文件名（特定代码块历史） git blame hello.html 注：1、格式：提交名称 初始文件名（提交人 提交时间 行号） 代码行 注：2、^脱字号开头表示版本库中第一个递交 git blame -L , 文件名（特定代码行历史） git blame -L 12,13 hello.html git blame -L 12,+2 hello.html git blame -L 12,-2 hello.html git blame -L 正则表达式 文件名（特定代码行历史） git blame -L \"//\",+2 hello.html git blame -L \"//\",-2 \"4333289e^\" -- index.html 跟踪内容 检查在同一个文件内移动或复制的代码行：git blame -M 文件名 查看文件之间的复制：git blame -C -C 文件名 查看显示代码的具体变动的历史记录：git log -C -C -1 -p 撤销修改 增补提交：git commit -C HEAD -a --amend --amend：增补提交 -C：复用指定提交的提交留言 -c：打开编辑器，在已有提交留言基础上修改 反转提交：git revert -n 提交名称 参数：--no-edit 复位：git reset 提交名称 提交名称默认值：HEAD 提交名称可用^和~修饰符 参数--soft：暂存所有因复位带来的差异，但不提交它 参数--hard：慎用，从版本库和工作目录树中同时删除提交 重新改写历史记录 重新排序提交：git rebase -i HEAD~3 将多个提交压合成一个提交：git rebase -i 0bb3dfb^ 将一个提交分解成多个提交：git rebase --continue 4. 与远程版本库协作 网络协议 SSH：用户名@服务器名/版本库路径 git@github.com/tswicegood/mysite-chp6.git git：协议://服务器名/版本库路径 （使用9418端口、匿名、无须加密、只读） git://github.com/tswicegood/mysite-chp6.git HTTP/HTTPS：需架设WebDAV服务 最快：git 安全：SSH 不受防火墙限制：HTTP(S) 克隆远程版本库：git clone git://github.com/tswicegood/mysite-chp6.git 版本库同步 取来（fetch）：git fetch 查看远程分支：git branch -r 取来合并：git pull 远程版本库名称 须要拖入的远程分支名 远程分支名前缀origin/表示远程版本库上的分支名称，origin是默认远程版本库别名 推入改动 推入默认版本库origin：git push 查看推入哪些提交：git push --dry-run 推入指定版本库：git push git push origin mybranch:master 添加新的远程版本库 一次拖入：git pull git://ourcompany.com/dev-erin.git 使用别名：git remote add 别名 路径 查看远程版本库详细信息：git remote show 删除别名：git remote rm 5. 管理本地版本库 使用标签标记里程碑 标签只读、标签名不能包含空格 查看已存在标签：git tag 新建标签：git tag 标签名 git tag 标签名 提示名称/分支名称 发布分支的处理 发布分支通常以RB_为前缀并包含版本号，RB_1.3 git branch RB_1.0.1 1.0 标签与分支的有效名称 不能以“/”结尾 不能以“.”开头 不能使用特殊字符：空格~^:?*[控制符删除键 不能出现“..” 记录和跟踪多个项目 多个项目共享一个版本库 多项目多版本库 使用Git子模块跟踪外部版本库 添加新子模块 查看该版本库的子模块：git submodule 添加新子模块：git submodule add 源版本库 存储路径 git submodule add git://github.com/tswicegood/hocus.git hocus 初始化子模块：git submodule init hocus 克隆含子模块的版本库：git submodule update 子模块名 cd work git clone magic new-magic cd new-magic git submodule git submodule init hocus git submodule update hocus 改变子模块的版本 使用子模块时要提防的错误 git add 确保结尾没有“\\” submodule update 先检查提交 添加新内容到本地自模块版本库，要检出正确分支 修改提交，确保改动被送回远程版本库 6. 高级功能 压缩版本库 git gc 整理版本库、优化Git内部存储历史记录 git gc 重新计算增量存储单元 到处版本库 创建版本快照:git archive 格式类型 指定版本 git archive --format= 转换格式 git archive --format=zip --prefix=mysite-release/ HEAD > mysite-release.zip git archive --format=tar --prefix=mysite-release/ HEAD | gzip > mysite-release.tar.gz 分支变基 git rebase --continue/--skip/--abort git rebase --onto master contacts search 重现隐藏的历史：git reflog 二分查找 git bisect start git bisect bad git bisect good 1.0 git bisect reset git bisect visualize git bisect log git bisect replay git bisect run 1 Downloading1 Xiechengqi            最新修订时间： 2019-12-06 21:21:13 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"Git/git学习.html":{"url":"Git/git学习.html","title":"git学习","keywords":"","body":"Git 学习笔记 【参考】 常用 Git 命令清单 Git 简明指南 图解Git Github 帮助 Git 官方文档 Git远程操作详解 - 阮一峰 常用命令 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 工作区 -> git add - > 暂存区 -> git commit -> 本地仓库 -> git push -> 远程仓库 git init 时默认创建了一个 master 分支，后续 git commit就是往 master 上提交 git init - 初始化当前目录没 git 仓库 git init [RepName] - 新建一个目录 RepName，并将其初始化为 git 本地仓库 git config- 修改 ./.git/config 配置文件，当前仓库配置，相同配置会覆盖用户和系统配置 ./.git/config - 在 git 仓库目录下执行该命令，同 git config git config --global - 修改 ~/.gitconfig 配置文件，当前用户配置，会覆盖系统配置 git config --system - 修改 /etc/gitconfig 配置文件，系统配置 git config -l[--list] - 显示 system、global、local 配置 git config --local --list - 显示当前仓库配置 git config --global --list - 显示用户配置 git config --system --list - 显示系统配置 git config [--global] user.name \"[name]\" - 设置提交代码时的用户名 git config [--global] user.email \"[email]\" - 设置提交代码时的用户邮箱 git config [--global] http.https://github.com.proxy socks5://127.0.0.1:1080 - 配置 git github socks5 代理，执行 git 命令时只对 github 代理 git config [--global] https.https://github.com.proxy socks5://127.0.0.1:1080 - 配置 git github socks5 代理 git config --unset http.https://github.com.proxy - 取消 github git 代理 git add \\ - 工作区把 file 添加到暂存区 git add -u - 可以暂存 ( stage ) 工作区 modified、deleted 文件，但不能暂存 untracked 文件 git add --ignore-removal . - 可以暂存工作区 modified、untracked 文件，但不能暂存 deleted 文件 git add . - git 2.0+ 版本中，和 git add -A 功能一样，可以暂存工作区 modified、deleted、untracked 文件 git add -A - 暂存工作区所有文件变化 ( modified、deleted、untracked ) git rm \\ - 同时删除工作区和暂存区 file git mv \\ \\ - 在工作区和暂存区同时重命名 file1 为 file2 git commit -m \\ - 提交 ( commit ) 暂存区到本地仓库，message 是本次提交说明 git commit -a -m \\ - 会自动暂存 modified、deleted，但不会暂存 untracked 文件，然后 commit git status - 查看工作区和暂存区文件修改状态 git status -s - git status 输出精简版 git log - 查看本地仓库 commit 记录 git log --pretty=oneline - 查看本地仓库 commit 记录及对应 commit ID，以单行形式展示 git reflog - 可以查看所有分支对当前仓库的操作记录 ( commit / reset / checkout / merge / etc ) 以及操作的 commit ID ( 方便回退到某个操作时版本状态 ) git ls-files - 查看暂存区文件 git checkout -- \\ - 工作区撤销 file 修改，工作区的 file 回退到最近一次 git commit 或 git add 时的状态 git reset HEAD \\ - 暂存区撤销 file 修改，把暂存区内关于 file 的修改回退到工作区 git reset --hard HEAD^ - 本地仓库回退到上一次 commit 版本 git reset --hard HEAD~5 - 本地仓库回退到 5 次 commit 前版本 git reset --hard \\ - 本地仓库跳到 commit_ID 对应的 commit 版本 git diff file - 查看 file 工作区和暂存区里的区别 git diff HEAD - 查看工作区与当前分支最新commit之间的差异 git diff HEAD -- file - 查看文件 file 工作区和当前本地仓库之间的差异 git diff --cached - 查看已暂存未提交的内容，及查看暂存区和本地仓库里的区别 git fetch origin master:temp - 从远程的 origin 仓库的 master 分支下载到本地，并新建一个 temp 分支 git checkout \\ - 切换到其他分支，并更新工作区 git checkout -b \\ - 创建并切换到 newbranch 分支 git checkout - - 切换到上一分支 git merge \\ - 合并 branch 分支到当前分支 git cherry-pick \\ - 选择一个 commit，合并到当前分支 git switch -c \\ - 切换到 branch 分支，最新版切换分支方式 git switch master - 切换到本地仓库的 master 主分支 git branch 显示所有分支和用 * 标记当前所在分支 git branch -r - 列出所有远程分支 git branch -a - 列出所有本地分支和远程分支 git branch \\ - 新建一个分支，但依旧停在当前分支 git branch -d \\ - 删除分支 ( 删除不了当前分支，需要先切换到其他分支; 也删除不了未合并的分支 ) git branch -D - 强制删除分支 git branch -vv - 查看本地分支和远程分支的跟踪关系 git branch --set-upstream-to=/ - 为本地分支创建跟踪分支，跟踪远程主机的某个分支 git clone git clone [-o ] [] git clone - 从远程主机克隆一个版本库到本地，且默认生成的本地仓库名就是远程版本库名 - 指定克隆到本地的版本库名字， -o - 克隆并指定远程主机名，默认是 origin git remote 列出所有远程主机名 git remote -v - 参看远程主机的网址 git remote show - 查看远程主机详细信息 git remote add - 添加远程主机 git remote add origin git@github.com:username/reponame.git - 本地 git 仓库关联 github 上的仓库 git remote rm - 删除远程主机 git remote rename - 远程主机重命名 git fetch git fetch - 将某个远程主机的更新，全部取回本地 git fetch - 取回远程主机特定分支的更新，默认取回所有分支的更新 git pull 取回远程主机某个分支的更新，再与本地的指定分支合并 git pull : git pull - 远程主机指定分支与本地当前分支合并 git pull - 当前分支设置了跟踪分支 git pull - 当前分支只设置了一个跟踪分支 git pull -p - 在本地删除远程已经删除的分支 git pull --rebase - 合并采用 rebase 模式 git push 将本地分支的更新，推送到远程主机 git push : git push - 省略远程分支名，则表示将本地分支推送与之存在\"追踪关系\"的远程分支（通常两者同名），如果该远程分支不存在，则会被新建 git push : - 省略本地分支名，则表示删除指定的远程分支，因为这等同于推送一个空的本地分支到远程分支 git push - 当前分支与远程分支之间存在追踪关系 git push - 当前分支只有一个追踪分支，那么主机名都可以省略 git push --delete - 删除远程分支，效果同上 git push -u : - 当前分支与多个主机存在追踪关系，则可以使用 -u 选项指定一个默认主机，之后就可以直接用git push git push -u origin master - 第一次推送 master 分支，-u 创建跟踪关系，指定当前分支的 upstream git push origin master - 后续本地推送到远程仓库 ** - ** - ** - 查看变更内容 - git diff git diff file - 查看 file 工作区和暂存区里的区别 git diff HEAD -- file - 查看 file 工作区和本地仓库里的区别 git diff --cached - 查看已暂存未提交的内容，及查看暂存区和本地仓库里的区别 git diff t diff --git a/t b/t index f007ede..d09b7e1 100644 --- a/t +++ b/t @@ -1,4 +1,4 @@ 吃了吗 吃了 你吃了吗 -没吃 +我也吃了 diff --git a/t b/t - 对比两个文件，其中 a 改动前，b 是改动后 iindex f007ede..d09b7e1 10064 - 两个版本的 git 哈希值，index 区域（ add 之后）的 f007ede 对象和工作区域的 d09b7e1 对象， 100 表示普通文件，644 表示控制权限 --- a/t - --- 代表源文件 +++ b/t - +++ 代表目标文件 @@ -1,2 +1,5 @ - @@ 表示文件变动描述合并显示的开始和结束，一般在变动前后多显示3行，其中-+表示变动前后，逗号前是起始行位置，逗号后为从起始行往后几行。合起来就是变动前后都是从第4行开始，变动前文件往后数8行对应变动后文件往后数9行 变动内容 ——+表示增加了这一行，-表示删除了这一行，没符号表示此行没有变动。 当git status告诉你有文件被修改过，用git diff可以查看修改内容 回退 HEAD 指向当前版本，HEAD^ 上一个版本，HEAD~100 之前 100 个的版本 版本回退 - git reset # 使用 git log --pretty=oneline 或 git log 可以查看 commit 日志及 commit ID $ git log --pretty=oneline 14ab3268f5bda2287d04cd713e9df978b65bf381 create README b61f11035eff9ca39acd7a8d98356b3060c5997d delete again README.md; 0e41957b5b5be1be7cabcffd09de3bf8ae297e60 modify README.md 6ed84a9599334f9e9632479860b2dfd038f6e2aa create test 9d0e11c192851639ccfba51436af852e6fd5a029 create README.md # 使用 HEAD 回滚一次 $ git reset --hard HEAD^ $ git log --pretty=oneline b61f11035eff9ca39acd7a8d98356b3060c5997d delete again README.md; 0e41957b5b5be1be7cabcffd09de3bf8ae297e60 modify README.md 6ed84a9599334f9e9632479860b2dfd038f6e2aa create test 9d0e11c192851639ccfba51436af852e6fd5a029 create README.md # 使用 HEAD 回滚两次 git reset --hard HEAD~2 重置后撤出暂存区的变更： D README.md $ git log --pretty=oneline 6ed84a9599334f9e9632479860b2dfd038f6e2aa create test 9d0e11c192851639ccfba51436af852e6fd5a029 create README.md # 使用 commid ID 回到“未来”版本 $ git reset --hard 14ab $ git log --pretty=oneline 14ab3268f5bda2287d04cd713e9df978b65bf381 create README b61f11035eff9ca39acd7a8d98356b3060c5997d delete again README.md; 0e41957b5b5be1be7cabcffd09de3bf8ae297e60 modify README.md 6ed84a9599334f9e9632479860b2dfd038f6e2aa create test 9d0e11c192851639ccfba51436af852e6fd5a029 create README.md # 使用 git reflog 查看各个版本的 commit ID 前 7 位，以供返回对应版本（ git reset commitID ） $ git reflog 14ab326 HEAD@{0}: reset: moving to 14ab 6ed84a9 HEAD@{1}: reset: moving to HEAD~2 b61f110 HEAD@{2}: reset: moving to HEAD^ 14ab326 HEAD@{3}: reset: moving to 14ab3 0e41957 HEAD@{4}: reset: moving to HEAD^ b61f110 HEAD@{5}: reset: moving to HEAD^ 14ab326 HEAD@{6}: commit: create README b61f110 HEAD@{7}: commit: delete again README.md; 0e41957 HEAD@{8}: commit: modify README.md 6ed84a9 HEAD@{9}: commit: create test 9d0e11c HEAD@{10}: commit (initial): create README.md 修改回退- git checkout git reset 工作区 file 修改的回退 git checkout -- \\ 工作区 file 修改撤销，工作区的 file 回退到最近一次 git commit 或 git add 时的状态 上次 commit -> 修改 file -> git checkout -- file -> file 回退到上次 commit 上次 commit -> 修改 file -> git add file -> git checkout -- file -> file 回退到上一次 add 后状态 暂存区 file 修改的回退 git reset HEAD \\ 暂存区 file 修改撤销，把暂存区内关于 file 的修改全部回退到工作区 删除回退 git rm file - 同时删除工作区和暂存区 file - 还原：git reset HEAD file + git checkout file rm file - 只删除工作区里的 file - 还原：git checkout file 重命名回退 mv file file1 - 只在工作区里重命名 file 为 file1 - 还原：git checkout file + rm file1 -rf git mv file file1 - 同时重命名工作区和暂存区 file 为 file1 - 还原：git reset HEAD file + git checkout file + rm file1 -rf note: 重命名 file file1 = 删除 file + 新建 file1（ 和 file 内容相同 ） 建立、删除、修改跟踪关系 git clone 时自动创建 master 分支追踪 origin/master 分支 $ git clone git@github.com:Xiechengqi/test.git testbook 正克隆到 'testbook'... . . . $ cd testbook $ git branch -vv * master 77418ad [origin/master] Update index.html 案例实操 1. file 在工作区修改并 add 一次，之后又在工作区修改了，此时可以回退到上一次 add 状态，也可以回退到上一次 commit 状态 工作区内操作文件 file 只要没 commit 都能回退到上次 commit 时的版本 没有 git add 时，用 git checkout -- file 已经 git add 时，先 git reset HEAD 回退到 1，再按 1 操作 $ git status -s $ cat test 你好 你也好 他也好 $ echo 'hello' > test $ git add test $ echo 'hello world!' > test $ git status -s MM test # 此时工作区、暂存区和仓库内的 file 都不相同 # 工作区和暂存区比较 $ git diff test diff --git a/test b/test index ce01362..a042389 100644 --- a/test +++ b/test @@ -1 +1 @@ -hello +hello world! # 工作区和仓库比较 git diff HEAD -- test diff --git a/test b/test index f9132cb..a042389 100644 --- a/test +++ b/test @@ -1,3 +1 @@ -你好 -你也好 -他也好 +hello world! ### 回退还原 # 先回退暂存区与否无所谓，先退回暂存区比先退回工作区少一步操作而已 git reset HEAD test # 回退暂存区 重置后取消暂存的变更： M test $ git status -s M test $ git checkout test # 回退工作区 $ git status -s $ cat test 你好 你也好 他也好 2. 更新本地仓库至最新改动 方法一、git pull # 在本地仓库执行 git pull，便自动更新你的本地仓库至最新改动 $ git pull 方法二、git merge 如果远程仓库分支和本地仓库当前分支都修改了同一文件的同一位置（都修改了同一文件是可以的），这就会导致 merge 失败，需要手动修改远 程或本地其一 $ git fetch origin master:temp 来自 github.com:Xiechengqi/wiki * [新分支] master -> temp $ git diff temp # 查看当前分支 master 和 temp 分支的不同 diff --git a/index.md b/index.md deleted file mode 100644 index c0cd5ef..0000000 --- a/index.md +++ /dev/null @@ -1,3 +0,0 @@ -# 目录 - -* [hello world](./hello.md) diff --git a/index.rst b/index.rst new file mode 100644 index 0000000..42cee67 --- /dev/null +++ b/index.rst @@ -0,0 +1,20 @@ $ git merge temp # 合并 temp 到当前分支 master 更新 7df7451..36ce930 Fast-forward index.md | 3 +++ index.rst | 20 -------------------- 2 files changed, 3 insertions(+), 20 deletions(-) create mode 100644 index.md delete mode 100644 index.rst $ git brach -d temp # 删除 temp 分支 Xiechengqi            最新修订时间： 2019-12-07 08:59:31 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"VPS/":{"url":"VPS/","title":"VPS","keywords":"","body":"目录 AWS [Top] AWS LightSail 创建和基本配置 GCP [Top] VM 实例创建和基本配置.md Xiechengqi            最新修订时间： 2019-12-06 21:36:11 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"VPS/AWS_lightsail.html":{"url":"VPS/AWS_lightsail.html","title":"AWS_lightsail","keywords":"","body":"AWS LightSail 创建和基本配置 本地使用 ssh 命令行登录 步骤讲解 1、首次登录命令: ssh -i xxx.pem username@host_ip 使用密钥直接登录无需密码 2、xxx.pem 可以在 aws lightsail 服务器控制台下载 ( Lightsail 在您创建实例的每个 AWS 区域中创建一个默认密钥对 ) 每个地区都有自己的默认密钥 3、首次登录用户需要在实例的 \"管理\" 中的 \"连接\" 页面查看 4、登录后切换成 root 用户, 设置 root 密码 sudo su passwd root 5、修改 /etc/ssh/sshd_config 文件 # 被注释去掉注释, 是 no 的改为 yes PermitRootLogin yes PasswordAuthentication yes 6、最后修改 /root/.ssh/authorized_keys , 删除 /root/.ssh/authorized_keys 中 ssh-rsa 前面内容 ( 没有则不修改 ) 7、重启 ssh: sudo service sshd restart 8、再次登录时即可使用 ssh root@host_ip,之后输入密码即可登入 若想使用普通用户登录, 需要切换到 root 下修改普通用户登录密码, 并且需要如上面一样修改 /home/用户名/.ssh/authorized_keys,重启 ssh 后退出再次登录即可使用普通用户 实操截屏 下载私钥到本地 本地切换到私钥目录 本地修改私钥权限为 600 登入远程服务器, sudo su 切换到 root 用户并修改 root 密码 PermitRootLogin yes PasswordAuthentication yes 修改 /root/.ssh/authorized_keys 重启 sshd 服务 ssh root@ip 登录 Xiechengqi            最新修订时间： 2019-12-07 09:48:27 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"VPS/GCP_VM实例创建和基本配置.html":{"url":"VPS/GCP_VM实例创建和基本配置.html","title":"GCP_VM实例创建和基本配置","keywords":"","body":"配置 root passwd登录 首先使用 Google Cloud SSH 连接上去 切换到 root：sudo -i 编辑 ssh 配置文件：vim /etc/ssh/sshd_config 修改以下内容即可PermitRootLogin yes PasswordAuthentication yes 重启 ssh：service sshd restart Xiechengqi            最新修订时间： 2019-12-06 21:20:59 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}